<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: Todo List</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<div class="contents">


<h1><a class="anchor" id="todo">Todo List </a></h1><p><a class="anchor" id="_todo000016"></a> </p>
<dl>
<dt>Namespace <a class="el" href="namespacelbann.html">lbann</a>  </dt>
<dd>- add support for save and restore </dd>
</dl>
<p><a class="anchor" id="_todo000007"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1convolutional__layer.html#a4a6beefd3b7c00b569fa739ee8db7f7a">lbann::convolutional_layer::bp_linearity</a> () </dt>
<dd>Write a more efficient implementation ///////////////////////////////////////////////////////// </dd>
</dl>
<p><a class="anchor" id="_todo000006"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1convolutional__layer.html#aa99c637d13fa84e83d660a000e10f80d">lbann::convolutional_layer::fp_linearity</a> (ElMat &amp;_WB, ElMat &amp;_X, ElMat &amp;_Z, ElMat &amp;_Y) </dt>
<dd>Write a more efficient implementation ///////////////////////////////////////////////////////// </dd>
</dl>
<p><a class="anchor" id="_todo000018"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1deep__neural__network.html#a4095db900926a90d40020b5598ca5215">lbann::deep_neural_network::check_gradient</a> (CircMat &amp;X, CircMat &amp;Y, double *gradient_errors) </dt>
<dd>This is very old and probably broken </dd>
</dl>
<p><a class="anchor" id="_todo000028"></a> </p>
<dl>
<dt>Member <a class="el" href="namespacelbann.html#a54b1de9dc25018b19916a9b93cc0cc4f">lbann::init_random</a> (int seed) </dt>
<dd>Support saving/restoring the generator's state. This is directly supported via the &gt;&gt; and &lt;&lt; operators on the generator (reading/writing from/to a stream). </dd>
</dl>
<p><a class="anchor" id="_todo000004"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1io__layer.html#abe71d3ff37e3a3ddbb470347458a07ec">lbann::io_layer::get_linearized_data_size</a> () </dt>
<dd>NumNeurons should be hidden inside of an accessor function </dd>
</dl>
<p><a class="anchor" id="_todo000005"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1io__layer.html#a3c39307b9bc8166e5034488344445d1e">lbann::io_layer::get_linearized_label_size</a> () </dt>
<dd>NumNeurons should be hidden inside of an accessor function </dd>
</dl>
<p><a class="anchor" id="_todo000003"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1io__layer.html#a73ebdd84af9e419d2f21013cf60da207">lbann::io_layer::set_testing_data_reader</a> (DataReader *data_reader) </dt>
<dd>put in a check to make sure that this is a data reader that matches what was already there </dd>
</dl>
<p><a class="anchor" id="_todo000001"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1io__layer.html#a2f041f30ef460bd2064be4c9988b6ffe">lbann::io_layer::set_training_data_reader</a> (DataReader *data_reader) </dt>
<dd>put in a check to make sure that this is a data reader that matches what was already there </dd>
</dl>
<p><a class="anchor" id="_todo000002"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1io__layer.html#a147126a1a4372a36a9a52e9632dd2bfc">lbann::io_layer::set_validation_data_reader</a> (DataReader *data_reader) </dt>
<dd>put in a check to make sure that this is a data reader that matches what was already there </dd>
</dl>
<p><a class="anchor" id="_todo000017"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1lbann__comm.html#a02a95cf2854e3750590da55c51ff91d8">lbann::lbann_comm::broadcast</a> (T *data, int count, std::vector&lt; int &gt; &amp;dests, int root) </dt>
<dd>Can probably optimize this. </dd>
</dl>
<p><a class="anchor" id="_todo000009"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1pooling__layer.html#a815ce57ebd3a84a2e256b24587b6e43d">lbann::pooling_layer::bp_linearity</a> () </dt>
<dd>Write a more efficient implementation ///////////////////////////////////////////////////////// </dd>
</dl>
<p><a class="anchor" id="_todo000008"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1pooling__layer.html#a3a607b23296a7c17d9f21fc9ee3e65c6">lbann::pooling_layer::fp_linearity</a> (ElMat &amp;_WB, ElMat &amp;_X, ElMat &amp;_Z, ElMat &amp;_Y) </dt>
<dd>Write a more efficient implementation ///////////////////////////////////////////////////////// </dd>
</dl>
<p><a class="anchor" id="_todo000025"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a2341499470419ffae075506df7983c93">lbann::sequential_model::add</a> (Layer *new_layer) </dt>
<dd>Consider removing this function. The destructor deallocates all layers, so we might run into problems if a layer is deallocated externally. </dd>
</dl>
<p><a class="anchor" id="_todo000027"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#ae992c83737819d406e1311ebe24e07f0">lbann::sequential_model::insert</a> (int index, Layer *new_layer) </dt>
<dd><p class="startdd">This will mess up layer indices. </p>
<p class="enddd">Consider removing this function. The destructor deallocates all layers, so we might run into problems if a layer is deallocated externally. </p>
</dd>
</dl>
<p><a class="anchor" id="_todo000022"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a66da0af31609146827c238fca77e194d">lbann::sequential_model::load_from_checkpoint</a> (int fd, const char *filename, uint64_t *bytes) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000024"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a763961718a00350e968c2d0dce86df01">lbann::sequential_model::load_from_checkpoint_shared</a> (const char *dir, uint64_t *bytes) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000020"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a7b841c06d54724caecbd2eee309af1c3">lbann::sequential_model::load_from_file</a> (const std::string file_dir) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000026"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a65505f140bd9ffa43af0ead3b911ae52">lbann::sequential_model::remove</a> (int index) </dt>
<dd>This will mess up layer indices </dd>
</dl>
<p><a class="anchor" id="_todo000021"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#aa249267bd3e129b480c4615f51bfaed5">lbann::sequential_model::save_to_checkpoint</a> (int fd, const char *filename, uint64_t *bytes) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000023"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#adb00301ca3ee08ce6882469382e8f54c">lbann::sequential_model::save_to_checkpoint_shared</a> (const char *dir, uint64_t *bytes) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000019"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1sequential__model.html#a10e9245e9c58c4b3c3c365f0b65e92b8">lbann::sequential_model::save_to_file</a> (const std::string file_dir) </dt>
<dd>This is old and likely broken </dd>
</dl>
<p><a class="anchor" id="_todo000011"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1target__layer__distributed__minibatch.html#ac65d7338c511d59e5f8e779bd7688919">lbann::target_layer_distributed_minibatch::forwardProp</a> (DataType prev_WBL2NormSum) </dt>
<dd><p class="startdd">update this to use the new fp_linearity framework </p>
<p class="enddd">this needs to be optimized so that it is done locally first then aggregated </p>
</dd>
</dl>
<p><a class="anchor" id="_todo000010"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1target__layer__distributed__minibatch.html#ae10872bc60397e7fbb658c4cd2682856">lbann::target_layer_distributed_minibatch::setup</a> (int num_prev_neurons) </dt>
<dd>put in warning about bad target size </dd>
</dl>
<p><a class="anchor" id="_todo000014"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a14c4106696d7ae83784b22de93a46e0a">lbann::target_layer_distributed_minibatch_parallel_io::forwardProp</a> (DataType prev_WBL2NormSum) </dt>
<dd>update this to use the new fp_linearity framework </dd>
</dl>
<p><a class="anchor" id="_todo000013"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ae3d33d5cbe949783e2ef489bc771a721">lbann::target_layer_distributed_minibatch_parallel_io::setup</a> (int num_prev_neurons) </dt>
<dd>put in warning about bad target size </dd>
</dl>
<p><a class="anchor" id="_todo000015"></a> </p>
<dl>
<dt>Member <a class="el" href="classlbann_1_1target__layer__unsupervised.html#ad1a0631a6653c48e140b1d7685215c42">lbann::target_layer_unsupervised::forwardProp</a> (DataType prev_WBL2NormSum) </dt>
<dd>update this to use the new fp_linearity framework </dd>
</dl>
</div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
