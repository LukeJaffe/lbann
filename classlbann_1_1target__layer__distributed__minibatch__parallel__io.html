<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: lbann::target_layer_distributed_minibatch_parallel_io Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
  <div class="navpath"><a class="el" href="namespacelbann.html">lbann</a>::<a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html">target_layer_distributed_minibatch_parallel_io</a>
  </div>
<div class="contents">
<h1>lbann::target_layer_distributed_minibatch_parallel_io Class Reference</h1><!-- doxytag: class="lbann::target_layer_distributed_minibatch_parallel_io" --><!-- doxytag: inherits="lbann::target_layer,lbann::distributed_minibatch_parallel_io" -->
<p><code>#include &lt;<a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for lbann::target_layer_distributed_minibatch_parallel_io:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io__inherit__graph.png" border="0" usemap="#lbann_1_1target__layer__distributed__minibatch__parallel__io_inherit__map" alt="Inheritance graph"/></div>
<map name="lbann_1_1target__layer__distributed__minibatch__parallel__io_inherit__map" id="lbann_1_1target__layer__distributed__minibatch__parallel__io_inherit__map">
<area shape="rect" id="node2" href="classlbann_1_1target__layer.html" title="lbann::target_layer" alt="" coords="5,160,133,189"/><area shape="rect" id="node4" href="classlbann_1_1io__layer.html" title="lbann::io_layer" alt="" coords="16,83,123,112"/><area shape="rect" id="node6" href="classlbann_1_1Layer.html" title="lbann::Layer" alt="" coords="23,5,116,35"/><area shape="rect" id="node8" href="classlbann_1_1distributed__minibatch__parallel__io.html" title="lbann::distributed_minibatch_parallel_io" alt="" coords="157,160,405,189"/></map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for lbann::target_layer_distributed_minibatch_parallel_io:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io__coll__graph.png" border="0" usemap="#lbann_1_1target__layer__distributed__minibatch__parallel__io_coll__map" alt="Collaboration graph"/></div>
<map name="lbann_1_1target__layer__distributed__minibatch__parallel__io_coll__map" id="lbann_1_1target__layer__distributed__minibatch__parallel__io_coll__map">
<area shape="rect" id="node2" href="classlbann_1_1target__layer.html" title="lbann::target_layer" alt="" coords="179,312,307,341"/><area shape="rect" id="node4" href="classlbann_1_1io__layer.html" title="lbann::io_layer" alt="" coords="221,232,328,261"/><area shape="rect" id="node6" href="classlbann_1_1Layer.html" title="lbann::Layer" alt="" coords="228,101,321,131"/><area shape="rect" id="node8" href="classlbann_1_1lbann__comm.html" title="lbann::lbann_comm" alt="" coords="59,5,192,35"/><area shape="rect" id="node18" href="classlbann_1_1distributed__minibatch__parallel__io.html" title="lbann::distributed_minibatch_parallel_io" alt="" coords="5,167,253,196"/><area shape="rect" id="node10" href="classlbann_1_1Optimizer.html" title="lbann::Optimizer" alt="" coords="216,5,333,35"/><area shape="rect" id="node12" href="classlbann_1_1Activation.html" title="lbann::Activation" alt="" coords="357,5,475,35"/><area shape="rect" id="node14" href="classlbann_1_1dataset.html" title="lbann::dataset" alt="" coords="428,101,532,131"/><area shape="rect" id="node16" href="classlbann_1_1DataReader.html" title="lbann::DataReader" alt="" coords="499,5,629,35"/></map>
<center><span class="legend">[<a target="top" href="graph_legend.html">legend</a>]</span></center></div>

<p><a href="classlbann_1_1target__layer__distributed__minibatch__parallel__io-members.html">List of all members.</a></p>
<table border="0" cellpadding="0" cellspacing="0">
<tr><td colspan="2"><h2>Public Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a782e74e22c34b7333f7813e3b5590406">target_layer_distributed_minibatch_parallel_io</a> (<a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *<a class="el" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>, int num_parallel_readers, <a class="el" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> mini_batch_size, std::map&lt; <a class="el" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8">execution_mode</a>, <a class="el" href="classlbann_1_1DataReader.html">DataReader</a> * &gt; data_readers, bool shared_data_reader)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ae3d33d5cbe949783e2ef489bc771a721">setup</a> (int num_prev_neurons)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a14c4106696d7ae83784b22de93a46e0a">forwardProp</a> (<a class="el" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> prev_WBL2NormSum)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a2ffccd98d1761568c39b998be7c70972">backProp</a> ()</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">bool&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a628b485db774f8a5a4e093edd8b73f3f">update</a> ()</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">int&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac848395e55b96cf53462d67efc42efb9">fetch_from_data_reader</a> (<a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> &amp;M_local)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#af0866c6c725c0938d388fea84f3ad398">preprocess_data_samples</a> (<a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> &amp;M_local, int num_samples_in_batch)</td></tr>
<tr><td class="memItemLeft" align="right" valign="top">bool&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a06800a7f630fef832057bd232911efb2">update_data_reader</a> ()</td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8">execution_mode</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a1656c9772680bc8d4ba8277274c6f27d">get_execution_mode</a> ()</td></tr>
<tr><td colspan="2"><h2>Public Attributes</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">Ys</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a6034e0823933305d0bd7b5ef860f5c50">ColSumMat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">YsColMax</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#ac1f107dfdc1d078904b4b666af5b6b86">StarMat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2">YsColMaxStar</a></td></tr>
<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Note that the column max matrix has the number of mini-batches on the rows instead of columns.  <a href="#a7f793891c78e2799bfa3ba8ca2490ca2"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a></td></tr>
<tr><td class="memItemLeft" align="right" valign="top"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd">m_reduced_max_indicies</a></td></tr>
<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Local array to hold max indicies.  <a href="#a20a14f648ce5e2778009a7154f1493bd"></a><br/></td></tr>
<tr><td colspan="2"><h2>Protected Member Functions</h2></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a8001220957e42369e550b54057542933">fp_linearity</a> (<a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;, <a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;, <a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;, <a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;)</td></tr>
<tr><td class="mdescLeft">&nbsp;</td><td class="mdescRight">Local array to build global view of maximum indicies.  <a href="#a8001220957e42369e550b54057542933"></a><br/></td></tr>
<tr><td class="memItemLeft" align="right" valign="top">void&nbsp;</td><td class="memItemRight" valign="bottom"><a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a25d3a49456e01d0486836f6319386cdb">bp_linearity</a> ()</td></tr>
</table>
<hr/><a name="_details"></a><h2>Detailed Description</h2>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00035">35</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>
<hr/><h2>Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="a782e74e22c34b7333f7813e3b5590406"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::target_layer_distributed_minibatch_parallel_io" ref="a782e74e22c34b7333f7813e3b5590406" args="(lbann_comm *comm, int num_parallel_readers, uint mini_batch_size, std::map&lt; execution_mode, DataReader * &gt; data_readers, bool shared_data_reader)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">lbann::target_layer_distributed_minibatch_parallel_io::target_layer_distributed_minibatch_parallel_io </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="classlbann_1_1lbann__comm.html">lbann_comm</a> *&nbsp;</td>
          <td class="paramname"> <em>comm</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>num_parallel_readers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a>&nbsp;</td>
          <td class="paramname"> <em>mini_batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::map&lt; <a class="el" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8">execution_mode</a>, <a class="el" href="classlbann_1_1DataReader.html">DataReader</a> * &gt;&nbsp;</td>
          <td class="paramname"> <em>data_readers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&nbsp;</td>
          <td class="paramname"> <em>shared_data_reader</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00038">38</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00039"></a>00039   : <a class="code" href="classlbann_1_1target__layer.html#aa14c73d9d7ba12f718cf7f8ed0137c93">target_layer</a>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>, mini_batch_size, data_readers, shared_data_reader), 
<a name="l00040"></a>00040     <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#aa35307f86d664e0fd3cc98a645f1589d">distributed_minibatch_parallel_io</a>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>, num_parallel_readers, mini_batch_size, data_readers),
<a name="l00041"></a>00041     <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">Ys</a>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>-&gt;get_model_grid()), <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">YsColMax</a>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>-&gt;get_model_grid()), <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2" title="Note that the column max matrix has the number of mini-batches on the rows instead...">YsColMaxStar</a>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a651f8eab68ea1ca97a9689b372d93293">comm</a>-&gt;get_model_grid())
<a name="l00042"></a>00042 {
<a name="l00043"></a>00043   <span class="comment">//  NumNeurons = m_training_data_reader-&gt;get_linearized_label_size(); /// @todo NumNeurons should be hidden inside of an accessor function</span>
<a name="l00044"></a>00044 }
</pre></div></p>

</div>
</div>
<hr/><h2>Member Function Documentation</h2>
<a class="anchor" id="a2ffccd98d1761568c39b998be7c70972"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::backProp" ref="a2ffccd98d1761568c39b998be7c70972" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lbann::target_layer_distributed_minibatch_parallel_io::backProp </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p><p>Copy the results to the Ds_Temp variable for access by the next lower layer </p>
</p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#a07f230d516c76f22ff42addb542424af">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00130">130</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00130"></a>00130                                                                    {
<a name="l00132"></a>00132   Copy(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">Ys</a>, *<a class="code" href="classlbann_1_1Layer.html#a34f5517610ada7dd06205cb97d97b369">Ds_Temp</a>);
<a name="l00133"></a>00133 }
</pre></div></p>

</div>
</div>
<a class="anchor" id="a25d3a49456e01d0486836f6319386cdb"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::bp_linearity" ref="a25d3a49456e01d0486836f6319386cdb" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lbann::target_layer_distributed_minibatch_parallel_io::bp_linearity </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [inline, protected, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Handle the layer's linearity in backward propagation. </p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#a3cadcd93ddac0f0231449181a72edf1b">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00059">59</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00059"></a>00059 {}
</pre></div></p>

</div>
</div>
<a class="anchor" id="ac848395e55b96cf53462d67efc42efb9"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::fetch_from_data_reader" ref="ac848395e55b96cf53462d67efc42efb9" args="(Mat &amp;M_local)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int lbann::target_layer_distributed_minibatch_parallel_io::fetch_from_data_reader </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>M_local</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Reimplemented from <a class="el" href="classlbann_1_1distributed__minibatch__parallel__io.html#aa62a8e46c053771fe20831f81aeb0a25">lbann::distributed_minibatch_parallel_io</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00142">142</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00142"></a>00142                                                                                             {
<a name="l00143"></a>00143   DataReader *data_reader = <a class="code" href="classlbann_1_1io__layer.html#ae400abb9ed5e3ad2c8df1efc0168bc0a">target_layer::select_data_reader</a>();
<a name="l00144"></a>00144   <span class="keywordflow">return</span> data_reader-&gt;fetch_label(M_local);
<a name="l00145"></a>00145 }
</pre></div></p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ac848395e55b96cf53462d67efc42efb9_cgraph.png" border="0" usemap="#classlbann_1_1target__layer__distributed__minibatch__parallel__io_ac848395e55b96cf53462d67efc42efb9_cgraph_map" alt=""></div>
<map name="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ac848395e55b96cf53462d67efc42efb9_cgraph_map" id="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ac848395e55b96cf53462d67efc42efb9_cgraph">
<area shape="rect" id="node3" href="classlbann_1_1DataReader.html#ab9f0bd6994c5f78b5ea89c9af00fefaf" title="lbann::DataReader::fetch_label" alt="" coords="533,5,736,35"/><area shape="rect" id="node5" href="classlbann_1_1io__layer.html#ae400abb9ed5e3ad2c8df1efc0168bc0a" title="lbann::io_layer::select_data_reader" alt="" coords="523,59,747,88"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a14c4106696d7ae83784b22de93a46e0a"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::forwardProp" ref="a14c4106696d7ae83784b22de93a46e0a" args="(DataType prev_WBL2NormSum)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> lbann::target_layer_distributed_minibatch_parallel_io::forwardProp </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>&nbsp;</td>
          <td class="paramname"> <em>prev_WBL2NormSum</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000014">Todo:</a></b></dt><dd>update this to use the new fp_linearity framework </dd></dl>

<p><p>Compute the error between the previous layers activations and the ground truth</p>
<p>For each minibatch (column) find the maximimum value</p>
<p>Give every rank a copy so that they can find the max index locally</p>
<p>Find which rank holds the index for the maxmimum value</p>
<p>For each sample in mini-batch that this rank has</p>
<p>For each feature</p>
<p>Merge all of the local index sets into a common buffer, if there are two potential maximum values, highest index wins</p>
<p>Check to see if the predicted results match the target results</p>
<p>Allow the current root to compute the errors, since it has the data locally</p>
<p>For each sample in mini-batch </p>
</p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#a9bc5072a0c4105cce6f3526845abd07f">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00079">79</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00079"></a>00079                                                                                                    {
<a name="l00080"></a>00080   <span class="keywordtype">int</span> num_samples_in_batch = <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#ad5cc95374bcb47c97105b387950ca8e1">fetch_to_local_matrix</a>(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>);
<a name="l00081"></a>00081   <a class="code" href="classlbann_1_1io__layer.html#abbf07dd592d714852090c12855983592">target_layer::update_num_samples_processed</a>(num_samples_in_batch);
<a name="l00082"></a>00082 
<a name="l00084"></a>00084   <a class="code" href="namespaceEl.html#ad2848728b1bd8927a4732de42d57a7ca">ColumnMax</a>((<a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>) *<a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>, <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">YsColMax</a>); 
<a name="l00085"></a>00085   Copy(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">YsColMax</a>, <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2" title="Note that the column max matrix has the number of mini-batches on the rows instead...">YsColMaxStar</a>); 
<a name="l00086"></a>00086 
<a name="l00087"></a>00087   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>, <a class="code" href="classlbann_1_1Layer.html#a30aaa195765788f649ce70e855a74081">Layer::m_mini_batch_size</a>, 1);
<a name="l00088"></a>00088 
<a name="l00090"></a>00090   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> mb_index= 0; mb_index &lt; <a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>-&gt;LocalWidth(); mb_index++) { 
<a name="l00091"></a>00091     <span class="keywordtype">int</span> mb_global_index = <a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>-&gt;GlobalCol(mb_index);
<a name="l00092"></a>00092     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sample_max = <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2" title="Note that the column max matrix has the number of mini-batches on the rows instead...">YsColMaxStar</a>.GetLocal(mb_global_index, 0);
<a name="l00093"></a>00093     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> f_index = 0; f_index &lt; <a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>-&gt;LocalHeight(); f_index++) { 
<a name="l00094"></a>00094       <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>-&gt;GetLocal(f_index, mb_index) == sample_max) {
<a name="l00095"></a>00095         <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>.Set(mb_global_index, 0, <a class="code" href="classlbann_1_1Layer.html#aa4f7b14ea6448703edc07ae4e43cb20a">fp_input</a>-&gt;GlobalRow(f_index));
<a name="l00096"></a>00096       }
<a name="l00097"></a>00097     }
<a name="l00098"></a>00098   }
<a name="l00099"></a>00099 
<a name="l00100"></a>00100   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd" title="Local array to hold max indicies.">m_reduced_max_indicies</a>, <a class="code" href="classlbann_1_1Layer.html#a30aaa195765788f649ce70e855a74081">Layer::m_mini_batch_size</a>, 1);
<a name="l00102"></a>00102   <a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;model_allreduce(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>.Buffer(), <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>.Height() * <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>.Width(), <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd" title="Local array to hold max indicies.">m_reduced_max_indicies</a>.Buffer(), mpi::MAX);
<a name="l00103"></a>00103 
<a name="l00105"></a>00105   <span class="keywordtype">int</span> num_errors = 0;
<a name="l00106"></a>00106 
<a name="l00108"></a>00108   <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a1a1c8e6038e112145fa6eaf37e6cb3d4" title="Is this rank the current root node for the Elemental Distribution.">is_current_root</a>()) {
<a name="l00109"></a>00109     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> mb_index= 0; mb_index &lt; <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>.Width(); mb_index++) { 
<a name="l00110"></a>00110       <span class="keywordtype">int</span> targetidx = -1;
<a name="l00111"></a>00111       <span class="keywordtype">float</span> targetmax = 0;
<a name="l00112"></a>00112       <span class="keywordflow">for</span> (<span class="keywordtype">int</span> f_index= 0; f_index &lt; <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>.Height(); f_index++) {
<a name="l00113"></a>00113         <span class="keywordflow">if</span> (targetmax &lt; <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>.Get(f_index, mb_index)) {
<a name="l00114"></a>00114           targetmax = <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>.Get(f_index, mb_index);
<a name="l00115"></a>00115           targetidx = f_index;
<a name="l00116"></a>00116         }
<a name="l00117"></a>00117       }
<a name="l00118"></a>00118       <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd" title="Local array to hold max indicies.">m_reduced_max_indicies</a>.Get(mb_index, 0) != targetidx) {
<a name="l00119"></a>00119         num_errors++;
<a name="l00120"></a>00120       }
<a name="l00121"></a>00121     }
<a name="l00122"></a>00122   }
<a name="l00123"></a>00123   num_errors = <a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;model_broadcast(<a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a3ccc275f90122c59f3eb966402f521fc">m_root</a>, num_errors);
<a name="l00124"></a>00124 
<a name="l00125"></a>00125   <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#ac5d6b3b6740f91ef083eeac3cc52c10a">distribute_from_local_matrix</a>(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>, <a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">Ys</a>);
<a name="l00126"></a>00126 
<a name="l00127"></a>00127   <span class="keywordflow">return</span> num_errors;
<a name="l00128"></a>00128 }
</pre></div></p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a14c4106696d7ae83784b22de93a46e0a_cgraph.png" border="0" usemap="#classlbann_1_1target__layer__distributed__minibatch__parallel__io_a14c4106696d7ae83784b22de93a46e0a_cgraph_map" alt=""></div>
<map name="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a14c4106696d7ae83784b22de93a46e0a_cgraph_map" id="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a14c4106696d7ae83784b22de93a46e0a_cgraph">
<area shape="rect" id="node3" href="namespaceEl.html#ad2848728b1bd8927a4732de42d57a7ca" title="El::ColumnMax" alt="" coords="611,5,723,35"/><area shape="rect" id="node5" href="classlbann_1_1distributed__minibatch__parallel__io.html#ac5d6b3b6740f91ef083eeac3cc52c10a" title="lbann::distributed_minibatch_parallel_io::distribute_from_local_matrix" alt="" coords="457,112,876,141"/><area shape="rect" id="node15" href="classlbann_1_1distributed__minibatch__parallel__io.html#ad5cc95374bcb47c97105b387950ca8e1" title="lbann::distributed_minibatch_parallel_io::fetch_to_local_matrix" alt="" coords="476,165,857,195"/><area shape="rect" id="node23" href="classlbann_1_1distributed__minibatch__parallel__io.html#a1a1c8e6038e112145fa6eaf37e6cb3d4" title="Is this rank the current root node for the Elemental Distribution." alt="" coords="496,59,837,88"/><area shape="rect" id="node26" href="classlbann_1_1lbann__comm.html#a735d6432d0a1ba7c5651355c6f24576b" title="lbann::lbann_comm::model_allreduce" alt="" coords="548,219,785,248"/><area shape="rect" id="node30" href="classlbann_1_1lbann__comm.html#ab6ee3cdfeeca2aebeb692a720f2dea51" title="lbann::lbann_comm::model_broadcast" alt="" coords="545,272,788,301"/><area shape="rect" id="node32" href="classlbann_1_1io__layer.html#abbf07dd592d714852090c12855983592" title="lbann::io_layer::update_num_samples_processed" alt="" coords="513,325,820,355"/><area shape="rect" id="node7" href="classlbann_1_1distributed__minibatch__parallel__io.html#ae63fb14ed9851fdebd6fde53a15b450d" title="lbann::distributed_minibatch_parallel_io::get_num_parallel_readers" alt="" coords="928,165,1333,195"/><area shape="rect" id="node11" href="classlbann_1_1lbann__comm.html#a206bafe522a0962c450f4fc69d030656" title="lbann::lbann_comm::get_rank_in_model" alt="" coords="1005,59,1256,88"/><area shape="rect" id="node13" href="classlbann_1_1lbann__comm.html#a6086ced12c3eefeea6e2a78eff286983" title="lbann::lbann_comm::model_barrier" alt="" coords="1020,112,1241,141"/><area shape="rect" id="node9" href="classlbann_1_1distributed__minibatch__parallel__io.html#a72a85b41372e22cba16dddda84983093" title="lbann::distributed_minibatch_parallel_io::get_execution_mode" alt="" coords="1385,165,1761,195"/><area shape="rect" id="node17" href="classlbann_1_1distributed__minibatch__parallel__io.html#aa62a8e46c053771fe20831f81aeb0a25" title="lbann::distributed_minibatch_parallel_io::fetch_from_data_reader" alt="" coords="933,219,1328,248"/><area shape="rect" id="node21" href="classlbann_1_1distributed__minibatch__parallel__io.html#acc0bb9e26d23850e19f00663bee86bcd" title="lbann::distributed_minibatch_parallel_io::preprocess_data_samples" alt="" coords="927,272,1335,301"/><area shape="rect" id="node28" href="classlbann_1_1lbann__comm.html#ad67668baa49b8713f3c74816d1aeb175" title="lbann::lbann_comm::get_procs_per_model" alt="" coords="997,325,1264,355"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a8001220957e42369e550b54057542933"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::fp_linearity" ref="a8001220957e42369e550b54057542933" args="(ElMat &amp;, ElMat &amp;, ElMat &amp;, ElMat &amp;)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lbann::target_layer_distributed_minibatch_parallel_io::fp_linearity </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;&nbsp;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;&nbsp;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;&nbsp;</td>
          <td class="paramname">, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a> &amp;&nbsp;</td>
          <td class="paramname"></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [inline, protected, virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Local array to build global view of maximum indicies. </p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#ae9e1c671ec408bdd539ec728ce1e8b28">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00058">58</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00058"></a>00058 {}
</pre></div></p>

</div>
</div>
<a class="anchor" id="a1656c9772680bc8d4ba8277274c6f27d"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::get_execution_mode" ref="a1656c9772680bc8d4ba8277274c6f27d" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8">execution_mode</a> lbann::target_layer_distributed_minibatch_parallel_io::get_execution_mode </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Reimplemented from <a class="el" href="classlbann_1_1distributed__minibatch__parallel__io.html#a72a85b41372e22cba16dddda84983093">lbann::distributed_minibatch_parallel_io</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00164">164</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00164"></a>00164                                                                                        {
<a name="l00165"></a>00165   <span class="keywordflow">return</span> <a class="code" href="classlbann_1_1Layer.html#af8b115cb89d6e8081de3f148a8ad2ef7">m_execution_mode</a>;
<a name="l00166"></a>00166 }
</pre></div></p>

</div>
</div>
<a class="anchor" id="af0866c6c725c0938d388fea84f3ad398"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::preprocess_data_samples" ref="af0866c6c725c0938d388fea84f3ad398" args="(Mat &amp;M_local, int num_samples_in_batch)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lbann::target_layer_distributed_minibatch_parallel_io::preprocess_data_samples </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> &amp;&nbsp;</td>
          <td class="paramname"> <em>M_local</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>num_samples_in_batch</em></td><td>&nbsp;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td><td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Reimplemented from <a class="el" href="classlbann_1_1distributed__minibatch__parallel__io.html#acc0bb9e26d23850e19f00663bee86bcd">lbann::distributed_minibatch_parallel_io</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00147">147</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00147"></a>00147                                                                                                                         {
<a name="l00148"></a>00148   <span class="keywordflow">return</span>;
<a name="l00149"></a>00149 }
</pre></div></p>

</div>
</div>
<a class="anchor" id="ae3d33d5cbe949783e2ef489bc771a721"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::setup" ref="ae3d33d5cbe949783e2ef489bc771a721" args="(int num_prev_neurons)" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void lbann::target_layer_distributed_minibatch_parallel_io::setup </td>
          <td>(</td>
          <td class="paramtype">int&nbsp;</td>
          <td class="paramname"> <em>num_prev_neurons</em></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p><p>If the target layer shares a data reader with an input layer, do not setup the data reader a second time</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000013">Todo:</a></b></dt><dd>put in warning about bad target size </dd></dl>
<p>Note that the column max matrix has the number of mini-batches on the rows instead of columns </p>
</p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#a20442464265da1cb2aeb1cf82640702f">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00046">46</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00046"></a>00046                                                                                     {
<a name="l00047"></a>00047   <span class="keywordflow">if</span>(!<a class="code" href="classlbann_1_1target__layer.html#a576266beaf97c614d8f5f3a3ae005b0d">m_shared_data_reader</a>) { 
<a name="l00048"></a>00048     <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1io__layer.html#a8ce9b172521bbcf55c1040a3c28719b1">io_layer::m_data_sets_span_models</a>) {
<a name="l00049"></a>00049       <span class="keywordtype">int</span> stride = <a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;get_num_models() * <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#afd4635e8e81acf72e9164d91fb3209ef">m_num_parallel_readers_training</a> * <a class="code" href="classlbann_1_1Layer.html#a30aaa195765788f649ce70e855a74081">Layer::m_mini_batch_size</a>;
<a name="l00050"></a>00050       cout &lt;&lt; <span class="stringliteral">&quot;Setting up input layer, with &quot;</span> &lt;&lt; <a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;get_num_models() &lt;&lt; <span class="stringliteral">&quot; models and &quot;</span> &lt;&lt; <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#afd4635e8e81acf72e9164d91fb3209ef">m_num_parallel_readers_training</a> &lt;&lt; <span class="stringliteral">&quot; parallel readers and &quot;</span> &lt;&lt; Layer::m_mini_batch_size &lt;&lt; <span class="stringliteral">&quot; mb size, which gives a stride of &quot;</span> &lt;&lt; stride &lt;&lt; endl;
<a name="l00051"></a>00051       <a class="code" href="classlbann_1_1io__layer.html#af28dac8d9a030b3554c460722236d067">io_layer::setup_data_readers</a>(<a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;get_rank_in_model() * Layer::m_mini_batch_size,
<a name="l00052"></a>00052                                    stride,
<a name="l00053"></a>00053                                    <a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;get_model_rank() * stride);
<a name="l00054"></a>00054     }<span class="keywordflow">else</span> {
<a name="l00055"></a>00055       <a class="code" href="classlbann_1_1io__layer.html#af28dac8d9a030b3554c460722236d067">io_layer::setup_data_readers</a>(<a class="code" href="classlbann_1_1Layer.html#ad20dd05617ed950162e0fdb95bc23096">Layer::comm</a>-&gt;get_rank_in_model() * Layer::m_mini_batch_size,
<a name="l00056"></a>00056                                    <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#afd4635e8e81acf72e9164d91fb3209ef">m_num_parallel_readers_training</a> * Layer::m_mini_batch_size);
<a name="l00057"></a>00057     }
<a name="l00058"></a>00058   }
<a name="l00059"></a>00059 
<a name="l00061"></a>00061   <span class="keywordflow">if</span>(num_prev_neurons != <a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>) {
<a name="l00062"></a>00062     <span class="keywordflow">throw</span> lbann_exception(<span class="stringliteral">&quot;lbann_target_layer_distributed_minibatch_parallel_io: number of neurons in previous layer does not match the number of neurons in the target layer.&quot;</span>);
<a name="l00063"></a>00063   }
<a name="l00064"></a>00064 
<a name="l00065"></a>00065   Zeros(*<a class="code" href="classlbann_1_1Layer.html#a34f5517610ada7dd06205cb97d97b369">Ds_Temp</a>, <a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>, Layer::m_mini_batch_size);
<a name="l00066"></a>00066   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">Y_local</a>, <a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>, Layer::m_mini_batch_size);
<a name="l00067"></a>00067   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">Ys</a>, <a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>, Layer::m_mini_batch_size);
<a name="l00068"></a>00068   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">YsColMax</a>, Layer::m_mini_batch_size, 1); 
<a name="l00069"></a>00069   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2" title="Note that the column max matrix has the number of mini-batches on the rows instead...">YsColMaxStar</a>, Layer::m_mini_batch_size, 1);
<a name="l00070"></a>00070   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">m_max_index</a>, Layer::m_mini_batch_size, 1);
<a name="l00071"></a>00071   Zeros(<a class="code" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd" title="Local array to hold max indicies.">m_reduced_max_indicies</a>, Layer::m_mini_batch_size, 1);
<a name="l00072"></a>00072 
<a name="l00073"></a>00073   <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a39cc10542de6a808b578460b2a76475c">m_local_data_valid</a> = <span class="keyword">false</span>;
<a name="l00074"></a>00074   <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a6be7e7aad366708899a949813dc2554f">m_local_reader_done</a> = <span class="keyword">false</span>;
<a name="l00075"></a>00075   <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#aa595846c85d451799e44d58b8203192d">m_num_data_per_epoch</a> = 0;
<a name="l00076"></a>00076 }
</pre></div></p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ae3d33d5cbe949783e2ef489bc771a721_cgraph.png" border="0" usemap="#classlbann_1_1target__layer__distributed__minibatch__parallel__io_ae3d33d5cbe949783e2ef489bc771a721_cgraph_map" alt=""></div>
<map name="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ae3d33d5cbe949783e2ef489bc771a721_cgraph_map" id="classlbann_1_1target__layer__distributed__minibatch__parallel__io_ae3d33d5cbe949783e2ef489bc771a721_cgraph">
<area shape="rect" id="node3" href="classlbann_1_1lbann__comm.html#a54842b679a3756cf79b43baf46caf637" title="lbann::lbann_comm::get_num_models" alt="" coords="1339,5,1581,35"/><area shape="rect" id="node5" href="classlbann_1_1io__layer.html#af28dac8d9a030b3554c460722236d067" title="lbann::io_layer::setup_data_readers" alt="" coords="420,72,647,101"/><area shape="rect" id="node7" href="classlbann_1_1DataReader.html#a85a3d25b8c7510565dec4e3346e676f6" title="lbann::DataReader::setup" alt="" coords="696,99,867,128"/><area shape="rect" id="node9" href="classlbann_1_1DataReader.html#a6ca8592b2271ceaac8cb1e29dbecbb82" title="lbann::DataReader::calculate_multi_model_data_distribution" alt="" coords="915,99,1285,128"/><area shape="rect" id="node24" href="namespacelbann.html#a4fea7ba21017b49d1e34394b4c20c764" title="lbann::get_generator" alt="" coords="1031,152,1169,181"/><area shape="rect" id="node11" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5" title="lbann::lbann_comm::am_world_master" alt="" coords="1337,59,1583,88"/><area shape="rect" id="node17" href="classlbann_1_1lbann__comm.html#a6c201108eb6b5a1e23021db29cef655b" title="lbann::lbann_comm::get_model_rank" alt="" coords="1343,112,1577,141"/><area shape="rect" id="node20" href="classlbann_1_1lbann__comm.html#a206bafe522a0962c450f4fc69d030656" title="lbann::lbann_comm::get_rank_in_model" alt="" coords="1335,165,1585,195"/><area shape="rect" id="node22" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028" title="lbann::DataReader::getNumData" alt="" coords="1353,219,1567,248"/><area shape="rect" id="node13" href="classlbann_1_1lbann__comm.html#a615265cd20ffb4863089bb94e4c82fe7" title="lbann::lbann_comm::get_rank_in_world" alt="" coords="1635,32,1883,61"/><area shape="rect" id="node15" href="classlbann_1_1lbann__comm.html#ac1bcd6a5e38ad3a7e86171435642bc9f" title="lbann::lbann_comm::get_world_master" alt="" coords="1636,85,1881,115"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a628b485db774f8a5a4e093edd8b73f3f"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::update" ref="a628b485db774f8a5a4e093edd8b73f3f" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool lbann::target_layer_distributed_minibatch_parallel_io::update </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">
<p>Once a mini-batch is processed, resuffle the data for the next batch if necessary </p>

<p>Reimplemented from <a class="el" href="classlbann_1_1Layer.html#a0fbb376cebdaa4692fdc92df34bb366c">lbann::Layer</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00138">138</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00138"></a>00138                                                                  {
<a name="l00139"></a>00139   <span class="keywordflow">return</span> <a class="code" href="classlbann_1_1distributed__minibatch__parallel__io.html#a17aa20ba6b971b6433da058be0d4545a">is_data_set_processed</a>();
<a name="l00140"></a>00140 }
</pre></div></p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a628b485db774f8a5a4e093edd8b73f3f_cgraph.png" border="0" usemap="#classlbann_1_1target__layer__distributed__minibatch__parallel__io_a628b485db774f8a5a4e093edd8b73f3f_cgraph_map" alt=""></div>
<map name="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a628b485db774f8a5a4e093edd8b73f3f_cgraph_map" id="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a628b485db774f8a5a4e093edd8b73f3f_cgraph">
<area shape="rect" id="node3" href="classlbann_1_1distributed__minibatch__parallel__io.html#a17aa20ba6b971b6433da058be0d4545a" title="lbann::distributed_minibatch_parallel_io::is_data_set_processed" alt="" coords="425,85,815,115"/><area shape="rect" id="node5" href="classlbann_1_1distributed__minibatch__parallel__io.html#ae63fb14ed9851fdebd6fde53a15b450d" title="lbann::distributed_minibatch_parallel_io::get_num_parallel_readers" alt="" coords="864,5,1269,35"/><area shape="rect" id="node9" href="classlbann_1_1lbann__comm.html#a206bafe522a0962c450f4fc69d030656" title="lbann::lbann_comm::get_rank_in_model" alt="" coords="941,59,1192,88"/><area shape="rect" id="node11" href="classlbann_1_1lbann__comm.html#a735d6432d0a1ba7c5651355c6f24576b" title="lbann::lbann_comm::model_allreduce" alt="" coords="948,112,1185,141"/><area shape="rect" id="node15" href="classlbann_1_1distributed__minibatch__parallel__io.html#a44e74967c30e4bc0faf54a1d50cab79d" title="lbann::distributed_minibatch_parallel_io::update_data_reader" alt="" coords="881,165,1252,195"/><area shape="rect" id="node7" href="classlbann_1_1distributed__minibatch__parallel__io.html#a72a85b41372e22cba16dddda84983093" title="lbann::distributed_minibatch_parallel_io::get_execution_mode" alt="" coords="1319,5,1695,35"/><area shape="rect" id="node13" href="classlbann_1_1lbann__comm.html#ad67668baa49b8713f3c74816d1aeb175" title="lbann::lbann_comm::get_procs_per_model" alt="" coords="1373,112,1640,141"/></map>
</div>
</p>

</div>
</div>
<a class="anchor" id="a06800a7f630fef832057bd232911efb2"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::update_data_reader" ref="a06800a7f630fef832057bd232911efb2" args="()" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool lbann::target_layer_distributed_minibatch_parallel_io::update_data_reader </td>
          <td>(</td>
          <td class="paramname"></td>
          <td>&nbsp;)&nbsp;</td>
          <td><code> [virtual]</code></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p><p>If the data reader is shared with an input layer, don't update the reader just check to see if the epoch is done or will be done on the next update of the input layer (which includes adding the stride). Note that target layers are always update before input layers, which is why the position is not up to date yet. </p>
</p>

<p>Reimplemented from <a class="el" href="classlbann_1_1distributed__minibatch__parallel__io.html#a44e74967c30e4bc0faf54a1d50cab79d">lbann::distributed_minibatch_parallel_io</a>.</p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html#l00151">151</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a>.</p>

<p><div class="fragment"><pre class="fragment"><a name="l00151"></a>00151                                                                              {
<a name="l00152"></a>00152   DataReader *data_reader = <a class="code" href="classlbann_1_1io__layer.html#ae400abb9ed5e3ad2c8df1efc0168bc0a">target_layer::select_data_reader</a>();
<a name="l00153"></a>00153   <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1target__layer.html#a576266beaf97c614d8f5f3a3ae005b0d">m_shared_data_reader</a>) { 
<a name="l00158"></a>00158     <span class="keywordflow">return</span> (data_reader-&gt;get_next_position() &lt; data_reader-&gt;getNumData());
<a name="l00159"></a>00159   }<span class="keywordflow">else</span> {
<a name="l00160"></a>00160     <span class="keywordflow">return</span> data_reader-&gt;update();
<a name="l00161"></a>00161   }
<a name="l00162"></a>00162 }
</pre></div></p>

<p><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dynsection">
<div class="center"><img src="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a06800a7f630fef832057bd232911efb2_cgraph.png" border="0" usemap="#classlbann_1_1target__layer__distributed__minibatch__parallel__io_a06800a7f630fef832057bd232911efb2_cgraph_map" alt=""></div>
<map name="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a06800a7f630fef832057bd232911efb2_cgraph_map" id="classlbann_1_1target__layer__distributed__minibatch__parallel__io_a06800a7f630fef832057bd232911efb2_cgraph">
<area shape="rect" id="node3" href="classlbann_1_1DataReader.html#a14f874d8f6f0dd96eab9cf2fd64774b1" title="lbann::DataReader::get_next_position" alt="" coords="503,5,743,35"/><area shape="rect" id="node5" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028" title="lbann::DataReader::getNumData" alt="" coords="516,59,729,88"/><area shape="rect" id="node7" href="classlbann_1_1io__layer.html#ae400abb9ed5e3ad2c8df1efc0168bc0a" title="lbann::io_layer::select_data_reader" alt="" coords="511,112,735,141"/><area shape="rect" id="node9" href="classlbann_1_1DataReader.html#a3918f2ec31f985ce49fa5778db2ad4ba" title="lbann::DataReader::update" alt="" coords="533,165,712,195"/><area shape="rect" id="node11" href="namespacelbann.html#a4fea7ba21017b49d1e34394b4c20c764" title="lbann::get_generator" alt="" coords="793,165,932,195"/></map>
</div>
</p>

</div>
</div>
<hr/><h2>Member Data Documentation</h2>
<a class="anchor" id="a688267387c8d8bbfee8507d228296133"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::m_max_index" ref="a688267387c8d8bbfee8507d228296133" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a688267387c8d8bbfee8507d228296133">lbann::target_layer_distributed_minibatch_parallel_io::m_max_index</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00054">54</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a20a14f648ce5e2778009a7154f1493bd"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::m_reduced_max_indicies" ref="a20a14f648ce5e2778009a7154f1493bd" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a20a14f648ce5e2778009a7154f1493bd">lbann::target_layer_distributed_minibatch_parallel_io::m_reduced_max_indicies</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Local array to hold max indicies. </p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00055">55</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="adb060d52e4e5241d9e1efb2e425647d2"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::Y_local" ref="adb060d52e4e5241d9e1efb2e425647d2" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#adb060d52e4e5241d9e1efb2e425647d2">lbann::target_layer_distributed_minibatch_parallel_io::Y_local</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00050">50</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a0186b22a8ba21f0b09b3baf8415bd1c5"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::Ys" ref="a0186b22a8ba21f0b09b3baf8415bd1c5" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a0186b22a8ba21f0b09b3baf8415bd1c5">lbann::target_layer_distributed_minibatch_parallel_io::Ys</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00051">51</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="ac924bdddbbacdf2f6fe89d407bace01d"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::YsColMax" ref="ac924bdddbbacdf2f6fe89d407bace01d" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#a6034e0823933305d0bd7b5ef860f5c50">ColSumMat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#ac924bdddbbacdf2f6fe89d407bace01d">lbann::target_layer_distributed_minibatch_parallel_io::YsColMax</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00052">52</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<a class="anchor" id="a7f793891c78e2799bfa3ba8ca2490ca2"></a><!-- doxytag: member="lbann::target_layer_distributed_minibatch_parallel_io::YsColMaxStar" ref="a7f793891c78e2799bfa3ba8ca2490ca2" args="" -->
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="lbann__base_8hpp.html#ac1f107dfdc1d078904b4b666af5b6b86">StarMat</a> <a class="el" href="classlbann_1_1target__layer__distributed__minibatch__parallel__io.html#a7f793891c78e2799bfa3ba8ca2490ca2">lbann::target_layer_distributed_minibatch_parallel_io::YsColMaxStar</a></td>
        </tr>
      </table>
</div>
<div class="memdoc">

<p>Note that the column max matrix has the number of mini-batches on the rows instead of columns. </p>

<p>Definition at line <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html#l00053">53</a> of file <a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/lbann/layers/<a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8hpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.hpp</a></li>
<li>src/layers/<a class="el" href="lbann__target__layer__distributed__minibatch__parallel__io_8cpp_source.html">lbann_target_layer_distributed_minibatch_parallel_io.cpp</a></li>
</ul>
</div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
