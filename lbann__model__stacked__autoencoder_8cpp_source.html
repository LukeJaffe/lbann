<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: src/models/lbann_model_stacked_autoencoder.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>src/models/lbann_model_stacked_autoencoder.cpp</h1><a href="lbann__model__stacked__autoencoder_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC.</span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory.</span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN.</span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00027"></a>00027 <span class="comment"></span>
<a name="l00028"></a>00028 <span class="preprocessor">#include &quot;<a class="code" href="lbann__model__stacked__autoencoder_8hpp.html">lbann/models/lbann_model_stacked_autoencoder.hpp</a>&quot;</span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__fully__connected_8hpp.html">lbann/layers/lbann_layer_fully_connected.hpp</a>&quot;</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer_8hpp.html">lbann/optimizers/lbann_optimizer.hpp</a>&quot;</span>
<a name="l00031"></a>00031 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__sgd_8hpp.html">lbann/optimizers/lbann_optimizer_sgd.hpp</a>&quot;</span>
<a name="l00032"></a>00032 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__adagrad_8hpp.html">lbann/optimizers/lbann_optimizer_adagrad.hpp</a>&quot;</span>
<a name="l00033"></a>00033 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__rmsprop_8hpp.html">lbann/optimizers/lbann_optimizer_rmsprop.hpp</a>&quot;</span>
<a name="l00034"></a>00034 
<a name="l00035"></a>00035 <span class="preprocessor">#include &lt;string&gt;</span>
<a name="l00036"></a>00036 <span class="preprocessor">#include &lt;chrono&gt;</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include &lt;random&gt;</span>
<a name="l00038"></a>00038 <span class="preprocessor">#include &lt;sys/types.h&gt;</span>
<a name="l00039"></a>00039 <span class="preprocessor">#include &lt;sys/stat.h&gt;</span>
<a name="l00040"></a>00040 <span class="preprocessor">#include &lt;fcntl.h&gt;</span>
<a name="l00041"></a>00041 <span class="preprocessor">#include &lt;unistd.h&gt;</span>
<a name="l00042"></a>00042 <span class="preprocessor">#include &lt;stdio.h&gt;</span>
<a name="l00043"></a>00043 <span class="preprocessor">#include &quot;mpi.h&quot;</span>
<a name="l00044"></a>00044 
<a name="l00045"></a>00045 <span class="keyword">using namespace </span>std;
<a name="l00046"></a>00046 <span class="keyword">using namespace </span>El;
<a name="l00047"></a>00047 
<a name="l00048"></a>00048 
<a name="l00050"></a>00050 <span class="comment">// stacked_autoencoder</span>
<a name="l00052"></a>00052 <span class="comment"></span>
<a name="l00053"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#acc05c503af60b60fc45be4e8f4475f3d">00053</a> <a class="code" href="classlbann_1_1stacked__autoencoder.html#acc05c503af60b60fc45be4e8f4475f3d" title="Constructor.">lbann::stacked_autoencoder::stacked_autoencoder</a>(<span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> mini_batch_size,
<a name="l00054"></a>00054                                                 <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>,
<a name="l00055"></a>00055                                                 <a class="code" href="classlbann_1_1layer__factory.html">layer_factory</a>* _layer_fac,
<a name="l00056"></a>00056                                                 <a class="code" href="classlbann_1_1Optimizer__factory.html">Optimizer_factory</a>* _optimizer_fac)
<a name="l00057"></a>00057   : <a class="code" href="classlbann_1_1sequential__model.html">sequential_model</a>(mini_batch_size, comm, _layer_fac, _optimizer_fac),
<a name="l00058"></a>00058     m_train_accuracy(0.0),
<a name="l00059"></a>00059     m_validation_accuracy(0.0),
<a name="l00060"></a>00060     m_test_accuracy(0.0),
<a name="l00061"></a>00061     m_reconstruction_accuracy(0.0){}
<a name="l00062"></a>00062 
<a name="l00063"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#a69a11143ad8fdb00004b38768b33add7">00063</a> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a69a11143ad8fdb00004b38768b33add7" title="Destructor.">lbann::stacked_autoencoder::~stacked_autoencoder</a>() {}
<a name="l00064"></a>00064 
<a name="l00065"></a>00065 
<a name="l00066"></a>00066 <span class="comment">//This add hidden layers and their mirrors, input layer is added in base class?</span>
<a name="l00067"></a>00067 <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a3396b940a47b10396b5b179f29870f71">lbann::stacked_autoencoder::begin_stack</a>(<span class="keyword">const</span> std::string layer_name,
<a name="l00068"></a>00068                                <span class="keyword">const</span> <span class="keywordtype">int</span> layer_dim,
<a name="l00069"></a>00069                                <span class="keyword">const</span> <a class="code" href="namespacelbann.html#ab00e153fabca7ab166e4d79d47c05c76">activation_type</a> activation,
<a name="l00070"></a>00070                                <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a7ab6aada4b2438de8ca3dd783775c2f5" title="Weight matrix initialization scheme.">weight_initialization</a> init,
<a name="l00071"></a>00071                                std::vector&lt;regularizer*&gt; regularizers){
<a name="l00072"></a>00072 
<a name="l00073"></a>00073 
<a name="l00074"></a>00074   <span class="comment">// get prev neurons</span>
<a name="l00075"></a>00075         <span class="comment">//int mid = (int)Layers.size() / 2;</span>
<a name="l00076"></a>00076   <span class="keywordtype">int</span> cur_size = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00077"></a>00077   <span class="keywordtype">int</span> mid = cur_size / 2;
<a name="l00078"></a>00078   <a class="code" href="classlbann_1_1Layer.html">Layer</a>* mid_layer = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[mid];
<a name="l00079"></a>00079         <span class="comment">//int mid_num_neurons = mid_layer-&gt;NumNeurons;</span>
<a name="l00080"></a>00080   <span class="keywordtype">int</span> prev_layer_dim = mid_layer-&gt;<a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>;
<a name="l00081"></a>00081 
<a name="l00082"></a>00082         <span class="keywordflow">if</span> (cur_size == 1) {
<a name="l00083"></a>00083                 <span class="comment">// create first hidden layer</span>
<a name="l00084"></a>00084     <span class="keywordflow">if</span>(layer_name == <span class="stringliteral">&quot;FullyConnected&quot;</span>){
<a name="l00085"></a>00085       <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> *new_optimizer = <a class="code" href="classlbann_1_1sequential__model.html#a592e67ddb0dc61bffcca628765effe7d" title="Optimizer factory.">optimizer_fac</a>-&gt;<a class="code" href="classlbann_1_1Optimizer__factory.html#a58ddf461ad10a337e4497653de512ca5">create_optimizer</a>();
<a name="l00086"></a>00086       <a class="code" href="classlbann_1_1Layer.html">Layer</a>* new_layer
<a name="l00087"></a>00087         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;<a class="code" href="classlbann_1_1layer__factory.html#a2800438a8c0e13df87ecfe64e708b438">create_layer</a>&lt;<a class="code" href="classlbann_1_1FullyConnectedLayer.html">FullyConnectedLayer</a>&gt;(<span class="stringliteral">&quot;FullyConnected&quot;</span>,cur_size,
<a name="l00088"></a>00088                                                        prev_layer_dim,layer_dim,
<a name="l00089"></a>00089                                                        <a class="code" href="classlbann_1_1sequential__model.html#ad4f27748b8cdf0da723f39b3aba9ef2d" title="Mini-batch size.">m_mini_batch_size</a>, activation, init,
<a name="l00090"></a>00090                                                        <a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>,new_optimizer, regularizers);
<a name="l00091"></a>00091       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.push_back(new_layer);
<a name="l00092"></a>00092       <span class="comment">// create output/mirror layer</span>
<a name="l00093"></a>00093       <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> *mirror_optimizer = <a class="code" href="classlbann_1_1sequential__model.html#a592e67ddb0dc61bffcca628765effe7d" title="Optimizer factory.">optimizer_fac</a>-&gt;<a class="code" href="classlbann_1_1Optimizer__factory.html#a58ddf461ad10a337e4497653de512ca5">create_optimizer</a>();
<a name="l00094"></a>00094       <a class="code" href="classlbann_1_1Layer.html">Layer</a>* mirror_layer
<a name="l00095"></a>00095         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;<a class="code" href="classlbann_1_1layer__factory.html#a2800438a8c0e13df87ecfe64e708b438">create_layer</a>&lt;<a class="code" href="classlbann_1_1FullyConnectedLayer.html">FullyConnectedLayer</a>&gt;(<span class="stringliteral">&quot;FullyConnected&quot;</span>,cur_size+1,
<a name="l00096"></a>00096                                                        layer_dim,prev_layer_dim,
<a name="l00097"></a>00097                                                        m_mini_batch_size,activation, init,
<a name="l00098"></a>00098                                                        comm,mirror_optimizer,regularizers);
<a name="l00099"></a>00099       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.push_back(mirror_layer);
<a name="l00100"></a>00100     }
<a name="l00101"></a>00101         }
<a name="l00102"></a>00102         <span class="keywordflow">else</span> {
<a name="l00103"></a>00103                 <span class="comment">// create hiden layer</span>
<a name="l00104"></a>00104     <span class="keywordflow">if</span>(layer_name == <span class="stringliteral">&quot;FullyConnected&quot;</span>){
<a name="l00105"></a>00105       Optimizer *hidden_optimizer = <a class="code" href="classlbann_1_1sequential__model.html#a592e67ddb0dc61bffcca628765effe7d" title="Optimizer factory.">optimizer_fac</a>-&gt;create_optimizer();
<a name="l00106"></a>00106       Layer* hidden_layer
<a name="l00107"></a>00107         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;create_layer&lt;FullyConnectedLayer&gt;(<span class="stringliteral">&quot;FullyConnected&quot;</span>,cur_size,
<a name="l00108"></a>00108                                                        prev_layer_dim,layer_dim,
<a name="l00109"></a>00109                                                        m_mini_batch_size, activation, init,
<a name="l00110"></a>00110                                                        comm,hidden_optimizer, regularizers);
<a name="l00111"></a>00111       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.insert(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.begin()+ mid + 1,hidden_layer);
<a name="l00112"></a>00112       <span class="comment">// create mirror layer</span>
<a name="l00113"></a>00113       Optimizer *mirror_hidden_optimizer = <a class="code" href="classlbann_1_1sequential__model.html#a592e67ddb0dc61bffcca628765effe7d" title="Optimizer factory.">optimizer_fac</a>-&gt;create_optimizer();
<a name="l00114"></a>00114       Layer* mirror_hidden_layer
<a name="l00115"></a>00115         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;create_layer&lt;FullyConnectedLayer&gt;(<span class="stringliteral">&quot;FullyConnected&quot;</span>,cur_size+1,
<a name="l00116"></a>00116                                                        layer_dim,prev_layer_dim,
<a name="l00117"></a>00117                                                        m_mini_batch_size,activation, init,
<a name="l00118"></a>00118                                                        comm,mirror_hidden_optimizer,regularizers);
<a name="l00119"></a>00119       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.insert(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.begin() + mid + 2, mirror_hidden_layer);
<a name="l00120"></a>00120 
<a name="l00121"></a>00121     }
<a name="l00122"></a>00122                 <span class="comment">// re-number layer index</span>
<a name="l00123"></a>00123                 <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> n = 0; n &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); n++) {
<a name="l00124"></a>00124                         Layer* layer = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[n];
<a name="l00125"></a>00125                         layer-&gt;Index = n;
<a name="l00126"></a>00126                 }
<a name="l00127"></a>00127         }
<a name="l00128"></a>00128 
<a name="l00129"></a>00129   <span class="comment">//sanity check</span>
<a name="l00130"></a>00130   <span class="keywordflow">if</span>(comm-&gt;am_world_master()){
<a name="l00131"></a>00131     <span class="comment">//cout &lt;&lt; &quot;#Layers &quot; &lt;&lt; m_layers.size() &lt;&lt; endl;</span>
<a name="l00132"></a>00132     <span class="comment">//cout &lt;&lt; &quot;Layer Index and Layer Dim: &quot; &lt;&lt; endl;</span>
<a name="l00133"></a>00133     <span class="keywordflow">for</span>(<span class="keyword">auto</span>&amp; layer:<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>) cout &lt;&lt; <span class="stringliteral">&quot;[ &quot;</span> &lt;&lt; layer-&gt;Index &lt;&lt; <span class="stringliteral">&quot;]&quot;</span> &lt;&lt; layer-&gt;NumNeurons &lt;&lt; endl;
<a name="l00134"></a>00134   }
<a name="l00135"></a>00135 
<a name="l00136"></a>00136   <a class="code" href="classlbann_1_1stacked__autoencoder.html#ad03569f0b42c97a5654fc13840be7cb0">m_num_layers</a> = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00137"></a>00137 }
<a name="l00138"></a>00138 
<a name="l00139"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#a6ca4c1b576554d3a55c2139b2ec32388">00139</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a6ca4c1b576554d3a55c2139b2ec32388" title="Compute layer summaries.">lbann::stacked_autoencoder::summarize</a>(<a class="code" href="classlbann_1_1lbann__summary.html">lbann_summary</a>&amp; summarizer) {
<a name="l00140"></a>00140   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); ++l) {
<a name="l00141"></a>00141     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;summarize(summarizer, <a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00142"></a>00142   }
<a name="l00143"></a>00143 }
<a name="l00144"></a>00144 
<a name="l00145"></a>00145 
<a name="l00146"></a>00146 <span class="comment">/* Half of the layers is pretrained</span>
<a name="l00147"></a>00147 <span class="comment">and the remaining ones are initialized with the transpose of the other layer W^1= W^k^T</span>
<a name="l00148"></a>00148 <span class="comment">*/</span>
<a name="l00149"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#ab0be82f2e4cf447e2bbc13d498518f9b">00149</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#ab0be82f2e4cf447e2bbc13d498518f9b" title="pre train stacked autoencoder neural network">lbann::stacked_autoencoder::train</a>(<span class="keywordtype">int</span> num_epochs, <span class="keywordtype">int</span> evaluation_frequency)
<a name="l00150"></a>00150 {
<a name="l00151"></a>00151   <span class="keywordtype">size_t</span> num_layers = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00152"></a>00152   <a class="code" href="classlbann_1_1model.html#a780395fa740102adda5537aa5d257698">do_train_begin_cbs</a>();
<a name="l00153"></a>00153 
<a name="l00154"></a>00154   <span class="comment">// Epoch main loop</span>
<a name="l00155"></a>00155   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> epoch = 0; epoch &lt; num_epochs; ++epoch) {
<a name="l00156"></a>00156 
<a name="l00157"></a>00157     <span class="comment">// Check if training has been terminated</span>
<a name="l00158"></a>00158     <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#a881a892be143090ad80f6d839fcf457b">get_terminate_training</a>()) <span class="keywordflow">break</span>;
<a name="l00159"></a>00159 
<a name="l00160"></a>00160     ++<a class="code" href="classlbann_1_1model.html#a824cceedcc9c1ee11af6e0c3445a675c">m_current_epoch</a>;
<a name="l00161"></a>00161     <a class="code" href="classlbann_1_1model.html#a6f975af3ff4921d78a9eb1aca12eaf5e">do_epoch_begin_cbs</a>();
<a name="l00162"></a>00162 
<a name="l00164"></a>00164     <a class="code" href="classlbann_1_1model.html#a2166e2aad256a335ace3bdcae5da2614">m_execution_mode</a> = <a class="code" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8aef839bdee87b9298d9be97d3f9c90469">execution_mode::training</a>;
<a name="l00165"></a>00165     <span class="comment">//for (size_t l = 0; l &lt; m_layers.size(); ++l) {</span>
<a name="l00166"></a>00166     <span class="comment">//pretrained half of layers</span>
<a name="l00167"></a>00167     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt;= <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size() / 2; ++l) {
<a name="l00168"></a>00168       <span class="comment">//cout &lt;&lt; &quot;Layer Index and neurons &quot; &lt;&lt; m_layers[l]-&gt;Index &lt;&lt; &quot; : &quot; &lt;&lt; m_layers[l]-&gt;NumNeurons &lt;&lt; endl;</span>
<a name="l00169"></a>00169       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;m_execution_mode = <a class="code" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8aef839bdee87b9298d9be97d3f9c90469">execution_mode::training</a>;
<a name="l00170"></a>00170     }
<a name="l00171"></a>00171 
<a name="l00172"></a>00172     <span class="comment">// Train on mini-batches until data set is traversed</span>
<a name="l00173"></a>00173     <span class="comment">// Note: The data reader shuffles the data after each epoch</span>
<a name="l00174"></a>00174     <span class="keywordtype">long</span> num_samples = 0;
<a name="l00175"></a>00175     <span class="keywordtype">long</span> num_errors = 0;
<a name="l00176"></a>00176     <span class="keywordtype">bool</span> finished_epoch;
<a name="l00177"></a>00177     <span class="keywordflow">do</span> {
<a name="l00178"></a>00178       finished_epoch = <a class="code" href="classlbann_1_1stacked__autoencoder.html#a06ecea50f852b4e493b714b9e2bcdea4" title="Training step on one mini-batch.">train_mini_batch</a>(&amp;num_samples, &amp;num_errors);
<a name="l00179"></a>00179     } <span class="keywordflow">while</span>(!finished_epoch);
<a name="l00180"></a>00180 
<a name="l00181"></a>00181     <span class="comment">// Compute train accuracy on current epoch</span>
<a name="l00182"></a>00182     <a class="code" href="classlbann_1_1stacked__autoencoder.html#a7cd3d1c3676b24960c1e6c34085a4c02" title="Train accuracy over last training epoch.">m_train_accuracy</a> = <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>(num_samples - num_errors) / num_samples * 100;
<a name="l00183"></a>00183 
<a name="l00184"></a>00184     <span class="comment">//cout &lt;&lt; &quot;acc &quot; &lt;&lt; m_train_accuracy &lt;&lt; endl;</span>
<a name="l00185"></a>00185 
<a name="l00186"></a>00186     <span class="comment">/*if(evaluation_frequency &gt; 0</span>
<a name="l00187"></a>00187 <span class="comment">       &amp;&amp; (epoch + 1) % evaluation_frequency == 0) {</span>
<a name="l00188"></a>00188 <span class="comment">      // Evaluate model on validation set</span>
<a name="l00189"></a>00189 <span class="comment">      // TODO: do we need validation callbacks here?</span>
<a name="l00190"></a>00190 <span class="comment">      // do_validation_begin_cbs();</span>
<a name="l00191"></a>00191 <span class="comment">      //m_validation_accuracy = evaluate(execution_mode::validation);</span>
<a name="l00192"></a>00192 <span class="comment">      m_reconstruction_accuracy = reconstruction();</span>
<a name="l00193"></a>00193 <span class="comment">      // do_validation_end_cbs();</span>
<a name="l00194"></a>00194 <span class="comment"></span>
<a name="l00195"></a>00195 <span class="comment">      // Set execution mode back to training</span>
<a name="l00196"></a>00196 <span class="comment">      m_execution_mode = execution_mode::training;</span>
<a name="l00197"></a>00197 <span class="comment">      for (size_t l = 0; l &lt; m_layers.size(); l++) {</span>
<a name="l00198"></a>00198 <span class="comment">        //cout &lt;&lt; &quot;B2B Layer Index and neurons &quot; &lt;&lt; m_layers[l]-&gt;Index &lt;&lt; &quot; : &quot; &lt;&lt; m_layers[l]-&gt;NumNeurons &lt;&lt; endl;</span>
<a name="l00199"></a>00199 <span class="comment">        m_layers[l]-&gt;m_execution_mode = execution_mode::training;</span>
<a name="l00200"></a>00200 <span class="comment">      }</span>
<a name="l00201"></a>00201 <span class="comment">    }*/</span>
<a name="l00202"></a>00202 
<a name="l00203"></a>00203     <span class="comment">//copy to mirror layers</span>
<a name="l00204"></a>00204     <span class="keywordflow">for</span>(<span class="keywordtype">size_t</span> l=1; l&lt;= <a class="code" href="classlbann_1_1stacked__autoencoder.html#ad03569f0b42c97a5654fc13840be7cb0">m_num_layers</a>/2; l++){
<a name="l00205"></a>00205       <span class="comment">//Copy(m_layers[l]-&gt;Acts, m_layers[m_num_layers-l]-&gt;fp_input)</span>
<a name="l00206"></a>00206       <span class="comment">//output of reciprocating layer == input to (activation of )its succesor (l+1)</span>
<a name="l00207"></a>00207       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[<a class="code" href="classlbann_1_1stacked__autoencoder.html#ad03569f0b42c97a5654fc13840be7cb0">m_num_layers</a>-l]-&gt;setup_fp_input(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l+1]-&gt;Acts);
<a name="l00208"></a>00208 
<a name="l00209"></a>00209       <span class="comment">//reconstruction here</span>
<a name="l00210"></a>00210       <span class="comment">//Add unsupervised target layer</span>
<a name="l00211"></a>00211       <span class="comment">//m_reconstruction_accuracy = reconstruction();</span>
<a name="l00212"></a>00212 
<a name="l00213"></a>00213     }
<a name="l00214"></a>00214 
<a name="l00215"></a>00215     <a class="code" href="classlbann_1_1model.html#a93e43a6c5aaf8ad890ef50ff97dfa176">do_epoch_end_cbs</a>();
<a name="l00216"></a>00216     <span class="keywordflow">for</span> (<a class="code" href="classlbann_1_1Layer.html">Layer</a>* layer : <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>) {
<a name="l00217"></a>00217       layer-&gt;epoch_reset();
<a name="l00218"></a>00218     }
<a name="l00219"></a>00219   }
<a name="l00220"></a>00220   <a class="code" href="classlbann_1_1model.html#a13bb6edae42c719b78454a8af9549122">do_train_end_cbs</a>();
<a name="l00221"></a>00221 }
<a name="l00222"></a>00222 
<a name="l00223"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#a06ecea50f852b4e493b714b9e2bcdea4">00223</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a06ecea50f852b4e493b714b9e2bcdea4" title="Training step on one mini-batch.">lbann::stacked_autoencoder::train_mini_batch</a>(<span class="keywordtype">long</span> *num_samples,
<a name="l00224"></a>00224                                                   <span class="keywordtype">long</span> *num_errors)
<a name="l00225"></a>00225 {
<a name="l00226"></a>00226   <a class="code" href="classlbann_1_1model.html#a717aa5b84ad1f779403a052848a8eb37">do_batch_begin_cbs</a>();
<a name="l00227"></a>00227 
<a name="l00228"></a>00228   <span class="comment">// Forward propagation</span>
<a name="l00229"></a>00229   <a class="code" href="classlbann_1_1model.html#a9f7390320a5519c4cff3130c69d1df2d">do_model_forward_prop_begin_cbs</a>();
<a name="l00230"></a>00230   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00231"></a>00231   <span class="comment">//pretrained half of layers</span>
<a name="l00232"></a>00232   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt;= <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()/2; ++l) {
<a name="l00233"></a>00233   <span class="comment">//for (size_t l = 0; l &lt; m_layers.size(); ++l) {</span>
<a name="l00234"></a>00234     <a class="code" href="classlbann_1_1model.html#aca9c91259fc49ab6a6ea55cda2c62c2d">do_layer_forward_prop_begin_cbs</a>(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]);
<a name="l00235"></a>00235     L2NormSum = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;forwardProp(L2NormSum);
<a name="l00236"></a>00236     <a class="code" href="classlbann_1_1model.html#ac87db62dd205da6d627fbcd617296559">do_layer_forward_prop_end_cbs</a>(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]);
<a name="l00237"></a>00237   }
<a name="l00238"></a>00238   *num_errors += (long) L2NormSum;
<a name="l00239"></a>00239   *num_samples += m_mini_batch_size;
<a name="l00240"></a>00240   <a class="code" href="classlbann_1_1model.html#a0f4fa75de20f7c3dccb73736bb6a64b2">do_model_forward_prop_end_cbs</a>();
<a name="l00241"></a>00241 
<a name="l00242"></a>00242   <span class="comment">// Update training accuracy</span>
<a name="l00243"></a>00243   <a class="code" href="classlbann_1_1stacked__autoencoder.html#a7cd3d1c3676b24960c1e6c34085a4c02" title="Train accuracy over last training epoch.">m_train_accuracy</a> = <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>(*num_samples - *num_errors) / *num_samples * 100;
<a name="l00244"></a>00244   ++<a class="code" href="classlbann_1_1model.html#acdae8d69df2aa452f341a0a458dbf021">m_current_step</a>;
<a name="l00245"></a>00245 
<a name="l00246"></a>00246   <span class="comment">// Backward propagation</span>
<a name="l00247"></a>00247   <a class="code" href="classlbann_1_1model.html#a8a60eee343381e657b2c042637e56751">do_model_backward_prop_begin_cbs</a>();
<a name="l00248"></a>00248   <span class="comment">//pretrained half of layers</span>
<a name="l00249"></a>00249   <span class="comment">//for (size_t l = (m_layers.size() / 2); l-- &gt; 0;) {</span>
<a name="l00250"></a>00250   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = round(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size() / 2); l &gt; 0; --l) {
<a name="l00251"></a>00251     <a class="code" href="classlbann_1_1model.html#a51dc59ea8dd4bc689854732269aaf001">do_layer_backward_prop_begin_cbs</a>(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]);
<a name="l00252"></a>00252     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;backProp();
<a name="l00253"></a>00253     <span class="comment">//Copy??</span>
<a name="l00254"></a>00254     <a class="code" href="classlbann_1_1model.html#ab0939d2668cca7efc2cc52355d34df3b">do_layer_backward_prop_end_cbs</a>(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]);
<a name="l00255"></a>00255   }
<a name="l00256"></a>00256   <a class="code" href="classlbann_1_1model.html#a737a0129eadf52be476034888b3eedc2">do_model_backward_prop_end_cbs</a>();
<a name="l00257"></a>00257 
<a name="l00259"></a>00259   <span class="comment">// Update pretrained layers</span>
<a name="l00260"></a>00260   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = round(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size() / 2); l &gt; 0; --l) {
<a name="l00261"></a>00261     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;update();
<a name="l00262"></a>00262   }
<a name="l00263"></a>00263   <span class="comment">//cout &lt;&lt; &quot;Samples : : &quot; &lt;&lt; *num_samples &lt;&lt; endl;</span>
<a name="l00264"></a>00264   <span class="keyword">const</span> <span class="keywordtype">bool</span> data_set_processed = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[0]-&gt;update();
<a name="l00265"></a>00265   <span class="comment">//cout &lt;&lt; &quot;data processed : &quot; &lt;&lt; data_set_processed &lt;&lt; endl;</span>
<a name="l00266"></a>00266   <a class="code" href="classlbann_1_1model.html#a1b925c322faaba8c9d9f78c224a31e89">do_batch_end_cbs</a>();
<a name="l00267"></a>00267   <span class="keywordflow">return</span> data_set_processed;
<a name="l00268"></a>00268 }
<a name="l00269"></a>00269 
<a name="l00270"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#a2d760a0faaf9887393c3f444ab616ee8">00270</a> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a2d760a0faaf9887393c3f444ab616ee8" title="Reconstruction uses unsupervised target layer.">lbann::stacked_autoencoder::reconstruction</a>()
<a name="l00271"></a>00271 {
<a name="l00272"></a>00272 
<a name="l00273"></a>00273   <span class="comment">/*do_validation_begin_cbs()</span>
<a name="l00274"></a>00274 <span class="comment">  // Set the execution mode</span>
<a name="l00275"></a>00275 <span class="comment">  m_execution_mode = mode;</span>
<a name="l00276"></a>00276 <span class="comment">  for (size_t l = 0; l &lt; m_layers.size(); ++l) {</span>
<a name="l00277"></a>00277 <span class="comment">    m_layers[l]-&gt;m_execution_mode = mode;</span>
<a name="l00278"></a>00278 <span class="comment">  }*/</span>
<a name="l00279"></a>00279 
<a name="l00280"></a>00280   <span class="comment">// Evaluate on mini-batches until data set is traversed</span>
<a name="l00281"></a>00281   <span class="comment">// Note: The data reader shuffles the data after each epoch</span>
<a name="l00282"></a>00282   <span class="keywordtype">long</span> num_samples = 0;
<a name="l00283"></a>00283   <span class="keywordtype">long</span> num_errors = 0;
<a name="l00284"></a>00284   <span class="keywordtype">bool</span> finished_epoch;
<a name="l00285"></a>00285   <span class="keywordflow">do</span> {
<a name="l00286"></a>00286     finished_epoch = <a class="code" href="classlbann_1_1stacked__autoencoder.html#a5f2aff4a19ee8188cfaa6bec3d3fb60f">reconstruction_mini_batch</a>(&amp;num_samples, &amp;num_errors);
<a name="l00287"></a>00287   } <span class="keywordflow">while</span>(!finished_epoch);
<a name="l00288"></a>00288 
<a name="l00289"></a>00289   <span class="comment">// Compute reconstruction accuracy</span>
<a name="l00290"></a>00290   <a class="code" href="classlbann_1_1stacked__autoencoder.html#af617596053da078261f7abd62ed16547" title="Reconstruction accuracy.">m_reconstruction_accuracy</a> = <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>(num_samples - num_errors) / num_samples * 100;
<a name="l00291"></a>00291 
<a name="l00292"></a>00292   <span class="comment">/*do_validation_end_cbs()</span>
<a name="l00293"></a>00293 <span class="comment">  // Reset after testing.</span>
<a name="l00294"></a>00294 <span class="comment">  for (Layer* layer : m_layers) {</span>
<a name="l00295"></a>00295 <span class="comment">    layer-&gt;epoch_reset();</span>
<a name="l00296"></a>00296 <span class="comment">  }*/</span>
<a name="l00297"></a>00297 
<a name="l00298"></a>00298 
<a name="l00299"></a>00299   <span class="keywordflow">return</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#af617596053da078261f7abd62ed16547" title="Reconstruction accuracy.">m_reconstruction_accuracy</a>;
<a name="l00300"></a>00300 }
<a name="l00301"></a>00301 
<a name="l00302"></a><a class="code" href="classlbann_1_1stacked__autoencoder.html#a5f2aff4a19ee8188cfaa6bec3d3fb60f">00302</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1stacked__autoencoder.html#a5f2aff4a19ee8188cfaa6bec3d3fb60f">lbann::stacked_autoencoder::reconstruction_mini_batch</a>(<span class="keywordtype">long</span> *num_samples,
<a name="l00303"></a>00303                                                      <span class="keywordtype">long</span> *num_errors)
<a name="l00304"></a>00304 {
<a name="l00305"></a>00305   <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00306"></a>00306   <span class="comment">// add unsupervised target layer for reconstruction</span>
<a name="l00307"></a>00307   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00308"></a>00308   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++) {
<a name="l00309"></a>00309     L2NormSum = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;forwardProp(L2NormSum);
<a name="l00310"></a>00310   }
<a name="l00311"></a>00311   *num_errors += (long) L2NormSum;
<a name="l00312"></a>00312   *num_samples += m_mini_batch_size;
<a name="l00313"></a>00313 
<a name="l00314"></a>00314   <span class="comment">// Update layers</span>
<a name="l00315"></a>00315   <span class="comment">// Note: should only affect the input and target layers</span>
<a name="l00316"></a>00316   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size() - 1; l &gt; 0; --l) {
<a name="l00317"></a>00317     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;update();
<a name="l00318"></a>00318   }
<a name="l00319"></a>00319   <span class="keyword">const</span> <span class="keywordtype">bool</span> data_set_processed = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[0]-&gt;update();
<a name="l00320"></a>00320   <span class="keywordflow">return</span> data_set_processed;
<a name="l00321"></a>00321 }
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
