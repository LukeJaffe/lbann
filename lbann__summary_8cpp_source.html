<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: src/utils/lbann_summary.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>src/utils/lbann_summary.cpp</h1><a href="lbann__summary_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC. </span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory. </span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN. </span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// lbann_summary .hpp .cpp - Write summary statistics to Tensorboard</span>
<a name="l00028"></a>00028 <span class="comment"></span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;<a class="code" href="lbann__summary_8hpp.html">lbann/utils/lbann_summary.hpp</a>&quot;</span>
<a name="l00030"></a>00030 
<a name="l00031"></a>00031 <span class="keyword">namespace </span>lbann {
<a name="l00032"></a>00032 
<a name="l00033"></a>00033 <span class="preprocessor">#if __HAVE_TBINF</span>
<a name="l00034"></a>00034 <span class="preprocessor"></span>
<a name="l00035"></a>00035 <a class="code" href="classlbann_1_1lbann__summary.html#a2891f67b732e92cc88e2c9849f911f57">lbann_summary::lbann_summary</a>(std::string logdir, lbann_comm* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>)
<a name="l00036"></a>00036   : comm(comm) {
<a name="l00037"></a>00037   <span class="keywordflow">if</span> (comm-&gt;am_world_master()) {
<a name="l00038"></a>00038     sw = <span class="keyword">new</span> TBinf::SummaryWriter(logdir);
<a name="l00039"></a>00039   } <span class="keywordflow">else</span> {
<a name="l00040"></a>00040     sw = <span class="keyword">nullptr</span>;
<a name="l00041"></a>00041   }
<a name="l00042"></a>00042 }
<a name="l00043"></a>00043 
<a name="l00044"></a>00044 lbann_summary::~lbann_summary() {
<a name="l00045"></a>00045   flush();
<a name="l00046"></a>00046   <span class="keywordflow">if</span> (sw != <span class="keyword">nullptr</span>) {
<a name="l00047"></a>00047     <span class="keyword">delete</span> sw;
<a name="l00048"></a>00048   }
<a name="l00049"></a>00049 }
<a name="l00050"></a>00050 
<a name="l00051"></a>00051 <span class="keywordtype">void</span> lbann_summary::reduce_mean(<span class="keyword">const</span> std::string tag, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; mat,
<a name="l00052"></a>00052                                 int64_t step) {
<a name="l00053"></a>00053   <span class="comment">// Local sum</span>
<a name="l00054"></a>00054   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sum = 0.0;
<a name="l00055"></a>00055 
<a name="l00056"></a>00056   <span class="comment">// Check distributed matrix format</span>
<a name="l00057"></a>00057   El::DistData mat_format(mat);
<a name="l00058"></a>00058   <span class="keywordflow">if</span>(mat_format.colDist == El::STAR &amp;&amp; mat_format.rowDist == El::STAR) {
<a name="l00059"></a>00059     <span class="comment">// Compute local sum on master process if matrix is Star,Star</span>
<a name="l00060"></a>00060     <span class="keywordflow">if</span>(comm-&gt;am_model_master()) {
<a name="l00061"></a>00061       sum = local_sum(mat.LockedMatrix());
<a name="l00062"></a>00062     }
<a name="l00063"></a>00063   }
<a name="l00064"></a>00064   <span class="keywordflow">else</span> {
<a name="l00065"></a>00065     <span class="comment">// Compute local sum on all processes if matrix is in MC,MR;</span>
<a name="l00066"></a>00066     <span class="comment">// Star,VC; or similar format</span>
<a name="l00067"></a>00067     <span class="comment">// TODO: implement for matrices in Circ,Circ; MC,Star; or similar</span>
<a name="l00068"></a>00068     <span class="comment">// formats</span>
<a name="l00069"></a>00069     sum = local_sum(mat.LockedMatrix());
<a name="l00070"></a>00070   }
<a name="l00071"></a>00071 
<a name="l00072"></a>00072   <span class="comment">// Add local sum to list of pending means</span>
<a name="l00073"></a>00073   pending_means.emplace_back(tag, step, sum, 0.0f, mat.Height() * mat.Width());
<a name="l00074"></a>00074 }
<a name="l00075"></a>00075 
<a name="l00076"></a>00076 <span class="keywordtype">void</span> lbann_summary::reduce_min(<span class="keyword">const</span> std::string tag, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; mat,
<a name="l00077"></a>00077                                int64_t step) {
<a name="l00078"></a>00078   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> local_min = El::Min(mat.LockedMatrix());
<a name="l00079"></a>00079   pending_mins.emplace_back(tag, step, local_min);
<a name="l00080"></a>00080 }
<a name="l00081"></a>00081 
<a name="l00082"></a>00082 <span class="keywordtype">void</span> lbann_summary::reduce_max(<span class="keyword">const</span> std::string tag, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; mat,
<a name="l00083"></a>00083                                       int64_t step) {
<a name="l00084"></a>00084   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> local_max = El::Max(mat.LockedMatrix());
<a name="l00085"></a>00085   pending_maxes.emplace_back(tag, step, local_max);
<a name="l00086"></a>00086 }
<a name="l00087"></a>00087 
<a name="l00088"></a>00088 <span class="keywordtype">void</span> lbann_summary::reduce_stdev(<span class="keyword">const</span> std::string tag, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; mat,
<a name="l00089"></a>00089                                  int64_t step) {
<a name="l00090"></a>00090   <span class="comment">// Local sum and squared sum</span>
<a name="l00091"></a>00091   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sum = 0.0;
<a name="l00092"></a>00092   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sqsum = 0.0;
<a name="l00093"></a>00093 
<a name="l00094"></a>00094   <span class="comment">// Check distributed matrix format</span>
<a name="l00095"></a>00095   El::DistData mat_format(mat);
<a name="l00096"></a>00096   <span class="keywordflow">if</span>(mat_format.colDist == El::STAR &amp;&amp; mat_format.rowDist == El::STAR) {
<a name="l00097"></a>00097     <span class="comment">// Compute local sums on master process if matrix is Star,Star</span>
<a name="l00098"></a>00098     <span class="keywordflow">if</span>(comm-&gt;am_model_master()) {
<a name="l00099"></a>00099       sum = local_sum(mat.LockedMatrix());
<a name="l00100"></a>00100       sqsum = local_sqsum(mat.LockedMatrix());
<a name="l00101"></a>00101     }
<a name="l00102"></a>00102   }
<a name="l00103"></a>00103   <span class="keywordflow">else</span> {
<a name="l00104"></a>00104     <span class="comment">// Compute local sums on all processes if matrix is in MC,MR;</span>
<a name="l00105"></a>00105     <span class="comment">// Star,VC; or similar format</span>
<a name="l00106"></a>00106     <span class="comment">// TODO: implement for matrices in Circ,Circ; MC,Star; or similar</span>
<a name="l00107"></a>00107     <span class="comment">// formats</span>
<a name="l00108"></a>00108     sum = local_sum(mat.LockedMatrix());
<a name="l00109"></a>00109     sqsum = local_sqsum(mat.LockedMatrix());
<a name="l00110"></a>00110   }
<a name="l00111"></a>00111 
<a name="l00112"></a>00112   <span class="comment">// Add local sums to list of pending means</span>
<a name="l00113"></a>00113   pending_stdevs.emplace_back(tag, step, sum, sqsum, mat.Height() * mat.Width());
<a name="l00114"></a>00114 }
<a name="l00115"></a>00115 
<a name="l00116"></a>00116 <span class="keywordtype">void</span> lbann_summary::reduce_scalar(<span class="keyword">const</span> std::string tag, <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> s,
<a name="l00117"></a>00117                                   int64_t step) {
<a name="l00118"></a>00118   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00119"></a>00119     pending_scalars.emplace_back(tag, step, s);
<a name="l00120"></a>00120   }
<a name="l00121"></a>00121 }
<a name="l00122"></a>00122 
<a name="l00123"></a>00123 <span class="keywordtype">void</span> lbann_summary::sum_reduce_scalar(<span class="keyword">const</span> std::string tag, <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> s,
<a name="l00124"></a>00124                                       int64_t step) {
<a name="l00125"></a>00125   pending_sum_scalars.emplace_back(tag, step, s);
<a name="l00126"></a>00126 }
<a name="l00127"></a>00127 
<a name="l00128"></a>00128 <span class="keywordtype">void</span> lbann_summary::reduce_histogram(<span class="keyword">const</span> std::string tag, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; mat,
<a name="l00129"></a>00129                                      int64_t step) {
<a name="l00130"></a>00130   
<a name="l00131"></a>00131 }
<a name="l00132"></a>00132 
<a name="l00133"></a>00133 <span class="keywordtype">void</span> lbann_summary::flush() {
<a name="l00134"></a>00134   flush_means();
<a name="l00135"></a>00135   flush_mins();
<a name="l00136"></a>00136   flush_maxes();
<a name="l00137"></a>00137   flush_stdevs();
<a name="l00138"></a>00138   flush_scalars();
<a name="l00139"></a>00139   flush_sum_scalars();
<a name="l00140"></a>00140   <span class="keywordflow">if</span> (sw != <span class="keyword">nullptr</span>) {
<a name="l00141"></a>00141     sw-&gt;flush();
<a name="l00142"></a>00142   }
<a name="l00143"></a>00143 }
<a name="l00144"></a>00144 
<a name="l00145"></a>00145 <span class="keywordtype">void</span> lbann_summary::flush_means() {
<a name="l00146"></a>00146   std::vector&lt;DataType&gt; local_sums;
<a name="l00147"></a>00147   <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_means) {
<a name="l00148"></a>00148     local_sums.push_back(op.local);
<a name="l00149"></a>00149   }
<a name="l00150"></a>00150   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00151"></a>00151     std::vector&lt;DataType&gt; global_sums(pending_means.size());
<a name="l00152"></a>00152     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00153"></a>00153                        global_sums.data());
<a name="l00154"></a>00154     <span class="comment">// Compute the means in-place.</span>
<a name="l00155"></a>00155     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; global_sums.size(); ++i) {
<a name="l00156"></a>00156       global_sums[i] /= pending_means[i].num;
<a name="l00157"></a>00157     }
<a name="l00158"></a>00158     gather_scalar_summary(pending_means, global_sums);
<a name="l00159"></a>00159   } <span class="keywordflow">else</span> {
<a name="l00160"></a>00160     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00161"></a>00161                        comm-&gt;get_model_master());
<a name="l00162"></a>00162   }
<a name="l00163"></a>00163   pending_means.clear();
<a name="l00164"></a>00164 }
<a name="l00165"></a>00165 
<a name="l00166"></a>00166 <span class="keywordtype">void</span> lbann_summary::flush_mins() {
<a name="l00167"></a>00167   std::vector&lt;DataType&gt; local_mins;
<a name="l00168"></a>00168   <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_mins) {
<a name="l00169"></a>00169     local_mins.push_back(op.local);
<a name="l00170"></a>00170   }
<a name="l00171"></a>00171   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00172"></a>00172     std::vector&lt;DataType&gt; global_mins(pending_mins.size());
<a name="l00173"></a>00173     comm-&gt;model_reduce(local_mins.data(), local_mins.size(),
<a name="l00174"></a>00174                        global_mins.data(), El::mpi::MIN);
<a name="l00175"></a>00175     gather_scalar_summary(pending_mins, global_mins);
<a name="l00176"></a>00176   } <span class="keywordflow">else</span> {
<a name="l00177"></a>00177     comm-&gt;model_reduce(local_mins.data(), local_mins.size(),
<a name="l00178"></a>00178                        comm-&gt;get_model_master(), El::mpi::MIN);
<a name="l00179"></a>00179   }
<a name="l00180"></a>00180   pending_mins.clear();
<a name="l00181"></a>00181 }
<a name="l00182"></a>00182 
<a name="l00183"></a>00183 <span class="keywordtype">void</span> lbann_summary::flush_maxes() {
<a name="l00184"></a>00184   std::vector&lt;DataType&gt; local_maxes;
<a name="l00185"></a>00185   <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_maxes) {
<a name="l00186"></a>00186     local_maxes.push_back(op.local);
<a name="l00187"></a>00187   }
<a name="l00188"></a>00188   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00189"></a>00189     std::vector&lt;DataType&gt; global_maxes(pending_maxes.size());
<a name="l00190"></a>00190     comm-&gt;model_reduce(local_maxes.data(), local_maxes.size(),
<a name="l00191"></a>00191                        global_maxes.data(), El::mpi::MAX);
<a name="l00192"></a>00192     gather_scalar_summary(pending_maxes, global_maxes);
<a name="l00193"></a>00193   } <span class="keywordflow">else</span> {
<a name="l00194"></a>00194     comm-&gt;model_reduce(local_maxes.data(), local_maxes.size(),
<a name="l00195"></a>00195                        comm-&gt;get_model_master(), El::mpi::MAX);
<a name="l00196"></a>00196   }
<a name="l00197"></a>00197   pending_maxes.clear();
<a name="l00198"></a>00198 }
<a name="l00199"></a>00199 
<a name="l00200"></a>00200 <span class="keywordtype">void</span> lbann_summary::flush_stdevs() {
<a name="l00201"></a>00201   std::vector&lt;DataType&gt; local_sums;
<a name="l00202"></a>00202   std::vector&lt;DataType&gt; local_sqsums;
<a name="l00203"></a>00203   <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_stdevs) {
<a name="l00204"></a>00204     local_sums.push_back(op.local);
<a name="l00205"></a>00205     local_sqsums.push_back(op.local2);
<a name="l00206"></a>00206   }
<a name="l00207"></a>00207   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00208"></a>00208     <span class="comment">// Compute the model sample standard deviation as:</span>
<a name="l00209"></a>00209     <span class="comment">// sqrt[1/(n-1) (sqsum - (1/n)*sum^2)]</span>
<a name="l00210"></a>00210     <span class="comment">// The n-1 is to use an unbiased variance estimate.</span>
<a name="l00211"></a>00211     <span class="comment">// This unrolls the usual formulation of standard deviation some, to avoid</span>
<a name="l00212"></a>00212     <span class="comment">// global operations when pushing the operation.</span>
<a name="l00213"></a>00213     std::vector&lt;DataType&gt; global_sums(pending_stdevs.size());
<a name="l00214"></a>00214     std::vector&lt;DataType&gt; global_sqsums(pending_stdevs.size());
<a name="l00215"></a>00215     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00216"></a>00216                        global_sums.data());
<a name="l00217"></a>00217     comm-&gt;model_reduce(local_sqsums.data(), local_sqsums.size(),
<a name="l00218"></a>00218                        global_sqsums.data());
<a name="l00219"></a>00219     <span class="comment">// Re-use the global_sums vector for the standard deviation.</span>
<a name="l00220"></a>00220     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; global_sums.size(); ++i) {
<a name="l00221"></a>00221       global_sums[i] = std::sqrt(
<a name="l00222"></a>00222         (global_sqsums[i] -
<a name="l00223"></a>00223          global_sums[i] * global_sums[i] / pending_stdevs[i].num) /
<a name="l00224"></a>00224         (pending_stdevs[i].num - 1));
<a name="l00225"></a>00225     }
<a name="l00226"></a>00226     gather_scalar_summary(pending_stdevs, global_sums);
<a name="l00227"></a>00227   } <span class="keywordflow">else</span> {
<a name="l00228"></a>00228     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00229"></a>00229                        comm-&gt;get_model_master());
<a name="l00230"></a>00230     comm-&gt;model_reduce(local_sqsums.data(), local_sqsums.size(),
<a name="l00231"></a>00231                        comm-&gt;get_model_master());
<a name="l00232"></a>00232   }
<a name="l00233"></a>00233   pending_stdevs.clear();
<a name="l00234"></a>00234 }
<a name="l00235"></a>00235 
<a name="l00236"></a>00236 <span class="keywordtype">void</span> lbann_summary::flush_scalars() {
<a name="l00237"></a>00237   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00238"></a>00238     std::vector&lt;DataType&gt; local_scalars;
<a name="l00239"></a>00239     <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_scalars) {
<a name="l00240"></a>00240       local_scalars.push_back(op.local);
<a name="l00241"></a>00241     }
<a name="l00242"></a>00242     gather_scalar_summary(pending_scalars, local_scalars);
<a name="l00243"></a>00243   }
<a name="l00244"></a>00244   pending_scalars.clear();
<a name="l00245"></a>00245 }
<a name="l00246"></a>00246 
<a name="l00247"></a>00247 <span class="keywordtype">void</span> lbann_summary::flush_sum_scalars() {
<a name="l00248"></a>00248   std::vector&lt;DataType&gt; local_sums;
<a name="l00249"></a>00249   <span class="keywordflow">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; op : pending_sum_scalars) {
<a name="l00250"></a>00250     local_sums.push_back(op.local);
<a name="l00251"></a>00251   }
<a name="l00252"></a>00252   <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00253"></a>00253     std::vector&lt;DataType&gt; global_sums(pending_sum_scalars.size());
<a name="l00254"></a>00254     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00255"></a>00255                        global_sums.data());
<a name="l00256"></a>00256     gather_scalar_summary(pending_sum_scalars, global_sums);
<a name="l00257"></a>00257   } <span class="keywordflow">else</span> {
<a name="l00258"></a>00258     comm-&gt;model_reduce(local_sums.data(), local_sums.size(),
<a name="l00259"></a>00259                        comm-&gt;get_model_master());
<a name="l00260"></a>00260   }
<a name="l00261"></a>00261   pending_sum_scalars.clear();
<a name="l00262"></a>00262 }
<a name="l00263"></a>00263 
<a name="l00264"></a>00264 <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> lbann_summary::local_sum(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; mat)<span class="keyword"> const </span>{
<a name="l00265"></a>00265   <span class="comment">// Note there are more numerically stable ways to compute a sum.</span>
<a name="l00266"></a>00266   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sum = 0.0;
<a name="l00267"></a>00267   <span class="keyword">const</span> Int height = mat.Height();
<a name="l00268"></a>00268   <span class="keyword">const</span> Int width = mat.Width();
<a name="l00269"></a>00269   <span class="keyword">const</span> Int ldim = mat.LDim();
<a name="l00270"></a>00270   <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>* __restrict__ mat_buf = mat.LockedBuffer();
<a name="l00271"></a>00271   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> row = 0; row &lt; height; ++row) {
<a name="l00272"></a>00272     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> col = 0; col &lt; width; ++col) {
<a name="l00273"></a>00273       sum += mat_buf[row + col * ldim];
<a name="l00274"></a>00274     }
<a name="l00275"></a>00275   }
<a name="l00276"></a>00276   <span class="keywordflow">return</span> sum;
<a name="l00277"></a>00277 }
<a name="l00278"></a>00278 
<a name="l00279"></a>00279 <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> lbann_summary::local_sqsum(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; mat)<span class="keyword"> const </span>{
<a name="l00280"></a>00280   <span class="comment">// Note there are more numerically stable ways to compute a sum.</span>
<a name="l00281"></a>00281   <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> sqsum = 0.0;
<a name="l00282"></a>00282   <span class="keyword">const</span> Int height = mat.Height();
<a name="l00283"></a>00283   <span class="keyword">const</span> Int width = mat.Width();
<a name="l00284"></a>00284   <span class="keyword">const</span> Int ldim = mat.LDim();
<a name="l00285"></a>00285   <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>* __restrict__ mat_buf = mat.LockedBuffer();
<a name="l00286"></a>00286   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> row = 0; row &lt; height; ++row) {
<a name="l00287"></a>00287     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> col = 0; col &lt; width; ++col) {
<a name="l00288"></a>00288       <span class="keyword">const</span> <span class="keywordtype">int</span> pos = row + col * ldim;
<a name="l00289"></a>00289       sqsum += mat_buf[pos] * mat_buf[pos];
<a name="l00290"></a>00290     }
<a name="l00291"></a>00291   }
<a name="l00292"></a>00292   <span class="keywordflow">return</span> sqsum;
<a name="l00293"></a>00293 }
<a name="l00294"></a>00294 
<a name="l00295"></a>00295 std::string lbann_summary::prepend_model(<span class="keyword">const</span> std::string tag,
<a name="l00296"></a>00296                                          <span class="keywordtype">int</span> model)<span class="keyword"> const </span>{
<a name="l00297"></a>00297   <span class="keywordflow">return</span> <span class="stringliteral">&quot;model&quot;</span> + std::to_string(model) + <span class="stringliteral">&quot;/&quot;</span> + tag;
<a name="l00298"></a>00298 }
<a name="l00299"></a>00299 
<a name="l00300"></a>00300 <span class="keywordtype">void</span> lbann_summary::gather_scalar_summary(
<a name="l00301"></a>00301   <span class="keyword">const</span> std::vector&lt;pending_op&gt;&amp; ops, std::vector&lt;DataType&gt;&amp; scalars) {
<a name="l00302"></a>00302   <span class="keywordflow">if</span> (comm-&gt;am_world_master()) {
<a name="l00303"></a>00303     std::vector&lt;DataType&gt; data(comm-&gt;get_num_models() * scalars.size());
<a name="l00304"></a>00304     comm-&gt;intermodel_gather(scalars.data(), scalars.size(), data.data());
<a name="l00305"></a>00305     <span class="keywordflow">for</span> (<span class="keywordtype">unsigned</span> i = 0; i &lt; data.size(); ++i) {
<a name="l00306"></a>00306       <span class="keywordtype">int</span> model = i / ops.size();
<a name="l00307"></a>00307       <span class="keywordtype">unsigned</span> ops_pos = i % ops.size();
<a name="l00308"></a>00308       sw-&gt;add_scalar(prepend_model(ops[ops_pos].tag, model),
<a name="l00309"></a>00309                      data[i], ops[ops_pos].step);
<a name="l00310"></a>00310     }
<a name="l00311"></a>00311   } <span class="keywordflow">else</span> {
<a name="l00312"></a>00312     comm-&gt;intermodel_gather(scalars.data(), scalars.size(),
<a name="l00313"></a>00313                             comm-&gt;get_intermodel_master());
<a name="l00314"></a>00314   }
<a name="l00315"></a>00315 }
<a name="l00316"></a>00316 
<a name="l00317"></a>00317 <span class="keywordtype">void</span> lbann_summary::gather_scalar_summary(<span class="keyword">const</span> std::string tag, <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> s,
<a name="l00318"></a>00318                                           int64_t step) {
<a name="l00319"></a>00319   <span class="keywordflow">if</span> (comm-&gt;am_world_master()) {
<a name="l00320"></a>00320     std::vector&lt;DataType&gt; data(comm-&gt;get_num_models());
<a name="l00321"></a>00321     comm-&gt;intermodel_gather(s, data);
<a name="l00322"></a>00322     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> model = 0; model &lt; data.size(); ++model) {
<a name="l00323"></a>00323       sw-&gt;add_scalar(prepend_model(tag, model), data[model], step);
<a name="l00324"></a>00324     }
<a name="l00325"></a>00325   } <span class="keywordflow">else</span> {
<a name="l00326"></a>00326     comm-&gt;intermodel_gather(s, comm-&gt;get_intermodel_master());
<a name="l00327"></a>00327   }
<a name="l00328"></a>00328 }
<a name="l00329"></a>00329 
<a name="l00330"></a>00330 <span class="preprocessor">#endif  // __HAVE_TBINF</span>
<a name="l00331"></a>00331 <span class="preprocessor"></span>
<a name="l00332"></a>00332 }  <span class="comment">// namespace lbann</span>
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
