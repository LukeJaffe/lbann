<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: include/lbann/optimizers/lbann_optimizer_adagrad.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>include/lbann/optimizers/lbann_optimizer_adagrad.hpp</h1><a href="lbann__optimizer__adagrad_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC. </span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory. </span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN. </span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// lbann_optimizer_adagrad .hpp .cpp - Stochastic gradient descent optimizer with Adagrad</span>
<a name="l00027"></a>00027 <span class="comment">//</span>
<a name="l00028"></a>00028 <span class="comment">// Inspired by Kera.io implementation</span>
<a name="l00029"></a>00029 <span class="comment">//</span>
<a name="l00034"></a>00034 <span class="comment"></span>
<a name="l00035"></a>00035 <span class="preprocessor">#ifndef LBANN_OPTIMIZER_ADAGRAD_HPP</span>
<a name="l00036"></a>00036 <span class="preprocessor"></span><span class="preprocessor">#define LBANN_OPTIMIZER_ADAGRAD_HPP</span>
<a name="l00037"></a>00037 <span class="preprocessor"></span>
<a name="l00038"></a>00038 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer_8hpp.html">lbann/optimizers/lbann_optimizer.hpp</a>&quot;</span>
<a name="l00039"></a>00039 <span class="preprocessor">#include &lt;sys/stat.h&gt;</span>
<a name="l00040"></a>00040 
<a name="l00041"></a>00041 <span class="keyword">namespace </span>lbann
<a name="l00042"></a>00042 {
<a name="l00043"></a>00043   <span class="keyword">template</span>&lt;<span class="keyword">class</span> _DistMat&gt;
<a name="l00044"></a><a class="code" href="classlbann_1_1Adagrad.html">00044</a>   <span class="keyword">class </span><a class="code" href="classlbann_1_1Adagrad.html">Adagrad</a> : <span class="keyword">public</span> <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> {
<a name="l00045"></a>00045 
<a name="l00046"></a>00046   <span class="keyword">public</span>:
<a name="l00047"></a><a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">00047</a>     <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">lr</a>;
<a name="l00048"></a>00048 
<a name="l00049"></a><a class="code" href="classlbann_1_1Adagrad.html#a18fea4f857fd5ba3dc13c0b4325028c5">00049</a>     <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad.html#a18fea4f857fd5ba3dc13c0b4325028c5">epsilon</a>;
<a name="l00050"></a>00050 
<a name="l00051"></a><a class="code" href="classlbann_1_1Adagrad.html#a573de8c86d2b295aabaa8e07358e975c">00051</a>     <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="classlbann_1_1Adagrad.html#a573de8c86d2b295aabaa8e07358e975c">comm</a>;
<a name="l00052"></a><a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">00052</a>     _DistMat     <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>;     <span class="comment">// Cache of Weights and Bias Gradient (current time t - 1)</span>
<a name="l00053"></a><a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">00053</a>     _DistMat     <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>;      <span class="comment">// Temporary for Weights and Bias Gradient computation</span>
<a name="l00054"></a><a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">00054</a>     _DistMat     <a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>;     <span class="comment">// Temporary for Weights and Bias Gradient computation</span>
<a name="l00055"></a>00055 
<a name="l00056"></a>00056   <span class="keyword">private</span>:
<a name="l00057"></a><a class="code" href="classlbann_1_1Adagrad.html#a9ff50f8fdf4dbb8e50a7048e5d74542f">00057</a>     <span class="keyword">static</span> <span class="keyword">inline</span> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> <a class="code" href="classlbann_1_1Adagrad.html#a9ff50f8fdf4dbb8e50a7048e5d74542f">_sq</a>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> x) { <span class="keywordflow">return</span> (x * x); }
<a name="l00058"></a><a class="code" href="classlbann_1_1Adagrad.html#a463ba472a7f2cbbb4164fb94dfce28fb">00058</a>     <span class="keyword">static</span> <span class="keyword">inline</span> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> <a class="code" href="classlbann_1_1Adagrad.html#a463ba472a7f2cbbb4164fb94dfce28fb">_sqrt</a>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> x) { <span class="keywordflow">return</span> (1 / sqrt(x + 1e-8)); }
<a name="l00059"></a>00059 
<a name="l00060"></a>00060   <span class="keyword">public</span>:
<a name="l00061"></a>00061 
<a name="l00063"></a><a class="code" href="classlbann_1_1Adagrad.html#ad8c0a137a72b44271a53df30581acda9">00063</a>     <a class="code" href="classlbann_1_1Adagrad.html#ad8c0a137a72b44271a53df30581acda9" title="Constructor.">Adagrad</a>(<a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="classlbann_1_1Adagrad.html#a573de8c86d2b295aabaa8e07358e975c">comm</a>, <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">lr</a>, <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad.html#a18fea4f857fd5ba3dc13c0b4325028c5">epsilon</a>)
<a name="l00064"></a>00064       : lr(lr), epsilon(epsilon), comm(comm),
<a name="l00065"></a>00065         <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>(comm-&gt;get_model_grid()),
<a name="l00066"></a>00066         <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>(comm-&gt;get_model_grid()),
<a name="l00067"></a>00067         <a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>(comm-&gt;get_model_grid()) {
<a name="l00068"></a>00068       <span class="keywordflow">if</span> (comm-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a06a31f9df1860358ef0ef68d9e165cac">am_model_master</a>()) {
<a name="l00069"></a>00069         printf(<span class="stringliteral">&quot;Initializing Adagrad optimizer with lr=%f and epsilon=%f\n&quot;</span>, lr, epsilon);
<a name="l00070"></a>00070       }
<a name="l00071"></a>00071     }
<a name="l00072"></a>00072 
<a name="l00074"></a><a class="code" href="classlbann_1_1Adagrad.html#aa69660f35a03f5181211f8b761b25d0a">00074</a>     <a class="code" href="classlbann_1_1Adagrad.html#aa69660f35a03f5181211f8b761b25d0a" title="Destructor.">~Adagrad</a>() {
<a name="l00075"></a>00075       <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Empty();
<a name="l00076"></a>00076       <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>.Empty();
<a name="l00077"></a>00077       <a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>.Empty();
<a name="l00078"></a>00078     }
<a name="l00079"></a>00079 
<a name="l00081"></a><a class="code" href="classlbann_1_1Adagrad.html#aa2a53383b4b520018bdd07e359da7e60">00081</a>     <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1Adagrad.html#aa2a53383b4b520018bdd07e359da7e60" title="Setup optimizer.">setup</a>(<span class="keywordtype">int</span> input_dim, <span class="keywordtype">int</span> num_neurons) {
<a name="l00082"></a>00082       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1Adagrad.html#a573de8c86d2b295aabaa8e07358e975c">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a06a31f9df1860358ef0ef68d9e165cac">am_model_master</a>()) {
<a name="l00083"></a>00083         printf(<span class="stringliteral">&quot;Setting up Adagrad optimizer with cache size %d x %d\n&quot;</span>, num_neurons, input_dim);
<a name="l00084"></a>00084       }
<a name="l00085"></a>00085       Zeros(<a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>, num_neurons, input_dim);
<a name="l00086"></a>00086       Zeros(<a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>, num_neurons, input_dim);
<a name="l00087"></a>00087       Zeros(<a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>, num_neurons, input_dim);  
<a name="l00088"></a>00088       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1Adagrad.html#a573de8c86d2b295aabaa8e07358e975c">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a06a31f9df1860358ef0ef68d9e165cac">am_model_master</a>()) {
<a name="l00089"></a>00089         printf(<span class="stringliteral">&quot;Setting up Adagrad optimizer with WB_D_Cache size %d x %d\n&quot;</span>, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Height(), <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Width());  
<a name="l00090"></a>00090       }
<a name="l00091"></a>00091     }
<a name="l00092"></a>00092     
<a name="l00093"></a><a class="code" href="classlbann_1_1Adagrad.html#aff3cdabac05cb2ee74135e06ad5bf96d">00093</a>     <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1Adagrad.html#aff3cdabac05cb2ee74135e06ad5bf96d">update_weight_bias_matrix</a>(<a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; WB_D, <a class="code" href="lbann__base_8hpp.html#afad88fb587c304caea8a36ee5a5c1df8">ElMat</a>&amp; WB) {
<a name="l00094"></a>00094       Copy(WB_D, <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>);
<a name="l00095"></a>00095       <span class="comment">// Square each entry of the WB_D matrix</span>
<a name="l00096"></a>00096       EntrywiseMap(<a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>, std::function&lt;<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>)&gt;(<a class="code" href="classlbann_1_1Adagrad.html#a9ff50f8fdf4dbb8e50a7048e5d74542f">_sq</a>));
<a name="l00097"></a>00097       <span class="comment">// Add squared value to WB_D_Cache</span>
<a name="l00098"></a>00098       Axpy(1., <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>);
<a name="l00099"></a>00099 
<a name="l00100"></a>00100       Copy(<a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>, <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>);
<a name="l00101"></a>00101       <span class="comment">// Compute the inverse of the square root of the historical gradient (with a small perturbation)</span>
<a name="l00102"></a>00102       EntrywiseMap(<a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>, std::function&lt;<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>)&gt;(<a class="code" href="classlbann_1_1Adagrad.html#a463ba472a7f2cbbb4164fb94dfce28fb">_sqrt</a>));
<a name="l00103"></a>00103       Copy(WB_D, <a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>);
<a name="l00104"></a>00104       Hadamard(<a class="code" href="classlbann_1_1Adagrad.html#aad82fdc5608bc2eff7b7092bd8d2c1ff">WB_D_Temp2</a>, <a class="code" href="classlbann_1_1Adagrad.html#ab47a5e86daaec06cb1638d6223ddfedc">WB_D_Temp</a>, WB_D);
<a name="l00105"></a>00105 
<a name="l00106"></a>00106       <span class="comment">//    WBL2NormSum = 0.0;</span>
<a name="l00107"></a>00107       Axpy((<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>)-<a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">lr</a>, WB_D, WB);
<a name="l00108"></a>00108     }
<a name="l00109"></a>00109 
<a name="l00110"></a><a class="code" href="classlbann_1_1Adagrad.html#a0662c4920e83401a3ae6c5a5525c427f">00110</a>     <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad.html#a0662c4920e83401a3ae6c5a5525c427f">get_learning_rate</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">lr</a>; }
<a name="l00111"></a>00111 
<a name="l00112"></a><a class="code" href="classlbann_1_1Adagrad.html#a1cdfbaadd7cfc94c129bd3688709e5da">00112</a>     <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1Adagrad.html#a1cdfbaadd7cfc94c129bd3688709e5da">set_learning_rate</a>(<span class="keywordtype">float</span> _lr) { <a class="code" href="classlbann_1_1Adagrad.html#ac95a02f7f992694bf3453e77f0c62309">lr</a> = _lr; }
<a name="l00113"></a>00113 
<a name="l00114"></a><a class="code" href="classlbann_1_1Adagrad.html#a3d3124958cbe09f531927ce839c696aa">00114</a>     <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1Adagrad.html#a3d3124958cbe09f531927ce839c696aa">saveToCheckpoint</a>(<span class="keywordtype">int</span> fd, <span class="keyword">const</span> <span class="keywordtype">char</span>* filename, uint64_t* bytes) {
<a name="l00115"></a>00115       <span class="comment">//    writeDist(fd, filename, WB_D_Cache, bytes);</span>
<a name="l00116"></a>00116       <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00117"></a>00117     }
<a name="l00118"></a>00118 
<a name="l00119"></a><a class="code" href="classlbann_1_1Adagrad.html#a7bec801ad63ca4333d7e7f04574a06d3">00119</a>     <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1Adagrad.html#a7bec801ad63ca4333d7e7f04574a06d3">loadFromCheckpoint</a>(<span class="keywordtype">int</span> fd, <span class="keyword">const</span> <span class="keywordtype">char</span>* filename, uint64_t* bytes) {
<a name="l00120"></a>00120       <span class="comment">//    readDist(fd, filename, WB_D_Cache, bytes);</span>
<a name="l00121"></a>00121       <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00122"></a>00122     }
<a name="l00123"></a>00123 
<a name="l00124"></a><a class="code" href="classlbann_1_1Adagrad.html#acb44da7f30efa8178e06caa43bd02082">00124</a>     <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1Adagrad.html#acb44da7f30efa8178e06caa43bd02082">saveToCheckpointShared</a>(<span class="keyword">const</span> <span class="keywordtype">char</span>* dir, <span class="keywordtype">int</span> Index, uint64_t* bytes) {
<a name="l00125"></a>00125       <span class="keywordtype">int</span> rank = <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Grid().Rank();
<a name="l00126"></a>00126 
<a name="l00127"></a>00127       <span class="keywordtype">char</span> path[512];
<a name="l00128"></a>00128       sprintf(path, <span class="stringliteral">&quot;%s/WB_D_CACHE_L%d_%03dx%03d&quot;</span>, dir, Index, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Height()-1, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Width()-1);
<a name="l00129"></a>00129       <span class="keywordflow">if</span>(rank == 0) {
<a name="l00130"></a>00130         cout &lt;&lt; <span class="stringliteral">&quot;Saving layer &quot;</span> &lt;&lt; Index &lt;&lt; <span class="stringliteral">&quot; to file &quot;</span> &lt;&lt; path &lt;&lt; endl;
<a name="l00131"></a>00131       }
<a name="l00132"></a>00132       Write(<a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>, path, BINARY, <span class="stringliteral">&quot;&quot;</span>);
<a name="l00133"></a>00133       <span class="comment">//Write_MPI(WB_D_Cache, path, BINARY, &quot;&quot;);</span>
<a name="l00134"></a>00134 
<a name="l00135"></a>00135       <span class="keywordflow">if</span> (rank == 0) {
<a name="l00136"></a>00136         *bytes += 2 * <span class="keyword">sizeof</span>(int) + <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Height() * <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Width() * <span class="keyword">sizeof</span>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>);
<a name="l00137"></a>00137       }
<a name="l00138"></a>00138 
<a name="l00139"></a>00139       <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00140"></a>00140     }
<a name="l00141"></a>00141 
<a name="l00142"></a><a class="code" href="classlbann_1_1Adagrad.html#aa9df7c310c7271f20abb8fb2b9a6f68a">00142</a>     <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1Adagrad.html#aa9df7c310c7271f20abb8fb2b9a6f68a">loadFromCheckpointShared</a>(<span class="keyword">const</span> <span class="keywordtype">char</span>* dir, <span class="keywordtype">int</span> Index, uint64_t* bytes) {
<a name="l00143"></a>00143       <span class="keywordtype">int</span> rank = <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Grid().Rank();
<a name="l00144"></a>00144 
<a name="l00145"></a>00145       <span class="keywordtype">char</span> path[512];
<a name="l00146"></a>00146       <span class="keyword">struct </span>stat buffer;
<a name="l00147"></a>00147 
<a name="l00148"></a>00148       <span class="comment">// read in the cache of gradients for WB</span>
<a name="l00149"></a>00149       sprintf(path, <span class="stringliteral">&quot;%s/WB_D_CACHE_L%d_%03dx%03d.bin&quot;</span>, dir, Index, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Height()-1, <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Width()-1);
<a name="l00150"></a>00150 
<a name="l00151"></a>00151       <span class="comment">// check whether file exists</span>
<a name="l00152"></a>00152       <span class="keywordtype">int</span> exists = 0;
<a name="l00153"></a>00153       <span class="keywordflow">if</span> (rank == 0 &amp;&amp; stat(path, &amp;buffer) == 0) {
<a name="l00154"></a>00154         exists = 1;
<a name="l00155"></a>00155       }
<a name="l00156"></a>00156       MPI_Bcast(&amp;exists, 1, MPI_INT, 0, MPI_COMM_WORLD);
<a name="l00157"></a>00157 
<a name="l00158"></a>00158       <span class="comment">// read WB_D_Cache file</span>
<a name="l00159"></a>00159       <span class="keywordflow">if</span> (rank == 0) {
<a name="l00160"></a>00160         cout &lt;&lt; <span class="stringliteral">&quot;Restoring layer &quot;</span> &lt;&lt; Index &lt;&lt; <span class="stringliteral">&quot; from file &quot;</span> &lt;&lt; path &lt;&lt; endl;
<a name="l00161"></a>00161       }
<a name="l00162"></a>00162       Read(<a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>, path, BINARY, 1);
<a name="l00163"></a>00163       <span class="comment">//Read_MPI(WB_D_Cache, path, BINARY, 1);</span>
<a name="l00164"></a>00164 
<a name="l00165"></a>00165       <span class="keywordflow">if</span> (rank == 0) {
<a name="l00166"></a>00166         *bytes += 2 * <span class="keyword">sizeof</span>(int) + <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Height() * <a class="code" href="classlbann_1_1Adagrad.html#a27f7525d1a6ba69542c529b05c2e6718">WB_D_Cache</a>.Width() * <span class="keyword">sizeof</span>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>);
<a name="l00167"></a>00167       }
<a name="l00168"></a>00168 
<a name="l00169"></a>00169       <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00170"></a>00170    }
<a name="l00171"></a>00171     
<a name="l00172"></a>00172   };
<a name="l00173"></a>00173 
<a name="l00174"></a><a class="code" href="classlbann_1_1Adagrad__factory.html">00174</a>   <span class="keyword">class </span><a class="code" href="classlbann_1_1Adagrad__factory.html">Adagrad_factory</a> : <span class="keyword">public</span> <a class="code" href="classlbann_1_1Optimizer__factory.html">Optimizer_factory</a> {
<a name="l00175"></a>00175   <span class="keyword">public</span>:
<a name="l00176"></a>00176     <a class="code" href="classlbann_1_1Adagrad__factory.html#a3d6f638f5f45490b613e3a370cb5e234">Adagrad_factory</a>(<a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="classlbann_1_1Adagrad__factory.html#aa82d021b13b586ade4dce135159ecae9">comm</a>, <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad__factory.html#aa1a44658205056b1db8ab1fddbcf581f">lr</a>=0.01, <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad__factory.html#ad659e2179e72cd3ceee6edc99fb74c62">epsilon</a>=1e-6);
<a name="l00177"></a>00177     <a class="code" href="classlbann_1_1Adagrad__factory.html#a74fe999ac04f36cf2153da3d9d2fc461">~Adagrad_factory</a>();
<a name="l00178"></a>00178     <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> *<a class="code" href="classlbann_1_1Adagrad__factory.html#a9f0a8e270743b46069953d1c7f9ca8fc">create_optimizer</a>(<a class="code" href="lbann__base_8hpp.html#af76c86c7b2798091bc0864a0b81f1e0d" title="Distributed matrix format.">matrix_format</a> format=<a class="code" href="lbann__base_8hpp.html#af76c86c7b2798091bc0864a0b81f1e0da54235575a81d148e1647d626e7d16348">matrix_format::MC_MR</a>);
<a name="l00179"></a>00179 
<a name="l00180"></a>00180   <span class="keyword">public</span>:
<a name="l00181"></a><a class="code" href="classlbann_1_1Adagrad__factory.html#aa82d021b13b586ade4dce135159ecae9">00181</a>     <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* comm;
<a name="l00182"></a><a class="code" href="classlbann_1_1Adagrad__factory.html#aa1a44658205056b1db8ab1fddbcf581f">00182</a>     <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad__factory.html#aa1a44658205056b1db8ab1fddbcf581f">lr</a>;
<a name="l00183"></a><a class="code" href="classlbann_1_1Adagrad__factory.html#ad659e2179e72cd3ceee6edc99fb74c62">00183</a>     <span class="keywordtype">float</span> <a class="code" href="classlbann_1_1Adagrad__factory.html#ad659e2179e72cd3ceee6edc99fb74c62">epsilon</a>;
<a name="l00184"></a>00184   };
<a name="l00185"></a>00185 
<a name="l00186"></a>00186 }
<a name="l00187"></a>00187 
<a name="l00188"></a>00188 <span class="preprocessor">#endif // LBANN_OPTIMIZER_ADAGRAD_HPP</span>
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
