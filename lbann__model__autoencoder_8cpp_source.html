<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: src/models/lbann_model_autoencoder.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>src/models/lbann_model_autoencoder.cpp</h1><a href="lbann__model__autoencoder_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC. </span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory. </span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN. </span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// lbann_model_autoencoder .hpp .cpp - Autoencoder for sequential neural network models</span>
<a name="l00028"></a>00028 <span class="comment"></span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;<a class="code" href="lbann__model__autoencoder_8hpp.html">lbann/models/lbann_model_autoencoder.hpp</a>&quot;</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include &quot;<a class="code" href="lbann__model__dnn_8hpp.html">lbann/models/lbann_model_dnn.hpp</a>&quot;</span>
<a name="l00031"></a>00031 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__fully__connected_8hpp.html">lbann/layers/lbann_layer_fully_connected.hpp</a>&quot;</span>
<a name="l00032"></a>00032 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__softmax_8hpp.html">lbann/layers/lbann_layer_softmax.hpp</a>&quot;</span>
<a name="l00033"></a>00033 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer_8hpp.html">lbann/optimizers/lbann_optimizer.hpp</a>&quot;</span>
<a name="l00034"></a>00034 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__sgd_8hpp.html">lbann/optimizers/lbann_optimizer_sgd.hpp</a>&quot;</span>
<a name="l00035"></a>00035 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__adagrad_8hpp.html">lbann/optimizers/lbann_optimizer_adagrad.hpp</a>&quot;</span>
<a name="l00036"></a>00036 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__rmsprop_8hpp.html">lbann/optimizers/lbann_optimizer_rmsprop.hpp</a>&quot;</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include &lt;string&gt;</span>
<a name="l00038"></a>00038 
<a name="l00039"></a>00039 <span class="keyword">using namespace </span>std;
<a name="l00040"></a>00040 <span class="keyword">using namespace </span>El;
<a name="l00041"></a>00041 
<a name="l00042"></a>00042 
<a name="l00044"></a>00044 <span class="comment">// stacked_autoencoder : main auto encoder class</span>
<a name="l00046"></a>00046 <span class="comment"></span>
<a name="l00047"></a><a class="code" href="classlbann_1_1AutoEncoder.html#acb8f7c7d09e6c41c745273b8ae9e7786">00047</a> <a class="code" href="classlbann_1_1AutoEncoder.html#acb8f7c7d09e6c41c745273b8ae9e7786">lbann::AutoEncoder::AutoEncoder</a>(<a class="code" href="classlbann_1_1Optimizer__factory.html">Optimizer_factory</a> *optimizer_factory, <span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> MiniBatchSize, <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>)
<a name="l00048"></a>00048         : Sequential(optimizer_factory, MiniBatchSize, comm)
<a name="l00049"></a>00049 {
<a name="l00050"></a>00050 }
<a name="l00051"></a>00051 
<a name="l00052"></a><a class="code" href="classlbann_1_1AutoEncoder.html#a214632ea4d19946b490051924f5ea04f">00052</a> <a class="code" href="classlbann_1_1AutoEncoder.html#acb8f7c7d09e6c41c745273b8ae9e7786">lbann::AutoEncoder::AutoEncoder</a>(<a class="code" href="classlbann_1_1Optimizer__factory.html">Optimizer_factory</a> *optimizer_factory, <span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> MiniBatchSize, <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>,
<a name="l00053"></a>00053                                 <span class="keyword">const</span> std::vector&lt;int&gt;&amp; EncoderLayerDim, <span class="keyword">const</span> std::vector&lt;int&gt;&amp; DecoderLayerDim,
<a name="l00054"></a>00054                                 <span class="keyword">const</span> <span class="keywordtype">bool</span> LayerMirror, <span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> ActivationType,
<a name="l00055"></a>00055                                 <span class="keyword">const</span> <span class="keywordtype">float</span> DropOut, <span class="keyword">const</span> <span class="keywordtype">double</span> lambda)
<a name="l00056"></a>00056   : Sequential(optimizer_factory, MiniBatchSize, comm)
<a name="l00057"></a>00057 {
<a name="l00058"></a>00058   <span class="comment">// initalize layers</span>
<a name="l00059"></a>00059   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l = 0; l &lt; (int)EncoderLayerDim.size(); l++) {
<a name="l00060"></a>00060     Layers.push_back(<span class="keyword">new</span> <a class="code" href="classlbann_1_1FullyConnectedLayer.html">FullyConnectedLayer</a>(Layers.size(), ((l == 0) ? -1 : EncoderLayerDim[l-1]),
<a name="l00061"></a>00061                      EncoderLayerDim[l], MiniBatchSize, ActivationType, DropOut, lambda, <a class="code" href="datatype_8hpp.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>, comm));
<a name="l00062"></a>00062   }
<a name="l00063"></a>00063 
<a name="l00064"></a>00064   <span class="keywordflow">if</span> (LayerMirror) {
<a name="l00065"></a>00065     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l = (<span class="keywordtype">int</span>)EncoderLayerDim.size() - 2; l &gt;= 0; l--) {
<a name="l00066"></a>00066       <a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>.push_back(<span class="keyword">new</span> <a class="code" href="classlbann_1_1FullyConnectedLayer.html">FullyConnectedLayer</a>(<a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>.size(), EncoderLayerDim[l+1], EncoderLayerDim[l],
<a name="l00067"></a>00067                               MiniBatchSize, ActivationType, DropOut, lambda, <a class="code" href="datatype_8hpp.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>, comm));
<a name="l00068"></a>00068     }
<a name="l00069"></a>00069   }
<a name="l00070"></a>00070   <span class="keywordflow">else</span> {
<a name="l00071"></a>00071     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l = 0; l &lt; (int)DecoderLayerDim.size(); l++) {
<a name="l00072"></a>00072       <a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>.push_back(<span class="keyword">new</span> <a class="code" href="classlbann_1_1FullyConnectedLayer.html">FullyConnectedLayer</a>(<a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>.size(), ((l == 0) ? -1 : DecoderLayerDim[l-1]),
<a name="l00073"></a>00073                               DecoderLayerDim[l], MiniBatchSize, ActivationType, DropOut,
<a name="l00074"></a>00074                               lambda, <a class="code" href="datatype_8hpp.html#a070d2ce7b6bb7e5c05602aa8c308d0c4">NULL</a>, comm));
<a name="l00075"></a>00075     }
<a name="l00076"></a>00076   }
<a name="l00077"></a>00077 }
<a name="l00078"></a>00078 
<a name="l00079"></a><a class="code" href="classlbann_1_1AutoEncoder.html#a62efa190c17dd530ffe1cd67738fd63d">00079</a> <a class="code" href="classlbann_1_1AutoEncoder.html#a62efa190c17dd530ffe1cd67738fd63d">lbann::AutoEncoder::~AutoEncoder</a>()
<a name="l00080"></a>00080 {
<a name="l00081"></a>00081     <span class="comment">// free decoder layers</span>
<a name="l00082"></a>00082     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt; <a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>.size(); l++)
<a name="l00083"></a>00083          <span class="keyword">delete</span> <a class="code" href="classlbann_1_1AutoEncoder.html#afe8ef0d8cb7c6ca84771a00931a70c7b">DecoderLayers</a>[l];
<a name="l00084"></a>00084 }
<a name="l00085"></a>00085 
<a name="l00086"></a>00086 <span class="preprocessor">#if 0</span>
<a name="l00087"></a>00087 <span class="preprocessor"></span><span class="keywordtype">void</span> <a class="code" href="classlbann_1_1sequential__model.html#a553795d7e56f9b8f24dd59634be4958c" title="Add layer to sequential model.">lbann::AutoEncoder::add</a>(<span class="keywordtype">string</span> layerName, <span class="keywordtype">int</span> LayerDim, <span class="keywordtype">int</span> ActivationType, <span class="keywordtype">int</span> DropOut, <span class="keywordtype">double</span> lambda)
<a name="l00088"></a>00088 {
<a name="l00089"></a>00089   <span class="keywordtype">int</span> prevLayerDim = -1;
<a name="l00090"></a>00090   <span class="keywordtype">int</span> layerIndex = Layers.size();
<a name="l00091"></a>00091   <span class="keywordtype">int</span> prevLayerIndex = -1;
<a name="l00092"></a>00092   <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> *optimizer = optimizer_factory-&gt;create_optimizer();
<a name="l00093"></a>00093 
<a name="l00094"></a>00094   <span class="keywordflow">if</span>(Layers.size() != 0) {
<a name="l00095"></a>00095     <a class="code" href="classlbann_1_1Layer.html">Layer</a> *prev = Layers.back();
<a name="l00096"></a>00096     prevLayerDim = prev-&gt;<a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>;
<a name="l00097"></a>00097     prevLayerIndex = prev-&gt;<a class="code" href="classlbann_1_1Layer.html#a5d76fcdf50d7ac4fb2fe757fb0cc23d8">Index</a>;
<a name="l00098"></a>00098   }
<a name="l00099"></a>00099 
<a name="l00100"></a>00100   cout &lt;&lt; <span class="stringliteral">&quot;Adding a layer with input &quot;</span> &lt;&lt; prevLayerDim &lt;&lt; <span class="stringliteral">&quot; and index &quot;</span> &lt;&lt; layerIndex &lt;&lt; <span class="stringliteral">&quot; preve layer index &quot;</span> &lt;&lt; prevLayerIndex &lt;&lt; endl;
<a name="l00101"></a>00101 
<a name="l00102"></a>00102   <span class="keywordflow">if</span>(layerName.compare(<span class="stringliteral">&quot;FullyConnected&quot;</span>) == 0) {
<a name="l00103"></a>00103     <span class="comment">// initalize neural network (layers)</span>
<a name="l00104"></a>00104     Layers.push_back(<span class="keyword">new</span> FullyConnectedLayer(layerIndex, prevLayerDim, LayerDim, MiniBatchSize, ActivationType, DropOut, lambda, optimizer, <a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>));
<a name="l00105"></a>00105   }<span class="keywordflow">else</span> <span class="keywordflow">if</span>(layerName.compare(<span class="stringliteral">&quot;SoftMax&quot;</span>) == 0) {
<a name="l00106"></a>00106     Layers.push_back(<span class="keyword">new</span> SoftmaxLayer(layerIndex, prevLayerDim, LayerDim, MiniBatchSize, lambda, optimizer, <a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>));
<a name="l00107"></a>00107   }<span class="keywordflow">else</span> {
<a name="l00108"></a>00108     std::cout &lt;&lt; <span class="stringliteral">&quot;Unknown layer type &quot;</span> &lt;&lt; layerName &lt;&lt; std::endl;
<a name="l00109"></a>00109   }
<a name="l00110"></a>00110   <span class="keywordflow">return</span>;
<a name="l00111"></a>00111 }
<a name="l00112"></a>00112 <span class="preprocessor">#endif</span>
<a name="l00113"></a>00113 <span class="preprocessor"></span>
<a name="l00114"></a><a class="code" href="classlbann_1_1AutoEncoder.html#aeaab6088118c1da3df17f4fb126d0e1b">00114</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1AutoEncoder.html#aeaab6088118c1da3df17f4fb126d0e1b">lbann::AutoEncoder::train</a>(<a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; X, <span class="keyword">const</span> <span class="keywordtype">float</span> LearnRate)
<a name="l00115"></a>00115 {
<a name="l00116"></a>00116     <span class="comment">// setup input (last/additional row should always be 1)</span>
<a name="l00117"></a>00117     Copy(X, Layers[0]-&gt;Acts);
<a name="l00118"></a>00118 
<a name="l00119"></a>00119     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00120"></a>00120     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00121"></a>00121     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++)
<a name="l00122"></a>00122       L2NormSum = Layers[l]-&gt;forwardProp(L2NormSum);
<a name="l00123"></a>00123 
<a name="l00124"></a>00124     <span class="comment">// backward propagation (mini-batch)</span>
<a name="l00125"></a>00125     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = Layers.size() - 1; l &gt;= 1; l--) {
<a name="l00126"></a>00126       Layers[l]-&gt;backProp();
<a name="l00127"></a>00127     }
<a name="l00128"></a>00128 
<a name="l00129"></a>00129     <span class="comment">// update weights, biases</span>
<a name="l00130"></a>00130     <a class="code" href="classlbann_1_1AutoEncoder.html#ab9b3d0d2feac82a65058771ae6524271">global_update</a>();
<a name="l00131"></a>00131     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++)
<a name="l00132"></a>00132         Layers[l]-&gt;update(LearnRate);
<a name="l00133"></a>00133 }
<a name="l00134"></a>00134 
<a name="l00135"></a><a class="code" href="classlbann_1_1AutoEncoder.html#a005efc4d29e23b77d48785e6cf8b564e">00135</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1AutoEncoder.html#a005efc4d29e23b77d48785e6cf8b564e">lbann::AutoEncoder::test</a>(<a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; X, <a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; XP)
<a name="l00136"></a>00136 {
<a name="l00137"></a>00137     <span class="comment">// setup input (last/additional row should always be 1)</span>
<a name="l00138"></a>00138     Copy(X, Layers[0]-&gt;Acts);
<a name="l00139"></a>00139 
<a name="l00140"></a>00140     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00141"></a>00141     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00142"></a>00142     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++)
<a name="l00143"></a>00143       L2NormSum = Layers[l]-&gt;forwardProp(L2NormSum);
<a name="l00144"></a>00144 
<a name="l00145"></a>00145     <span class="comment">// get output</span>
<a name="l00146"></a>00146     Copy(Layers[Layers.size()-1]-&gt;Acts, XP);
<a name="l00147"></a>00147 }
<a name="l00148"></a>00148 
<a name="l00149"></a><a class="code" href="classlbann_1_1AutoEncoder.html#afa0d1eb756cdd7043c6eaab700edd461">00149</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1AutoEncoder.html#a005efc4d29e23b77d48785e6cf8b564e">lbann::AutoEncoder::test</a>(<a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; X, <a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; YP, <a class="code" href="lbann__base_8hpp.html#aaf89a79f1476644edba844c4937abbcc">CircMat</a>&amp; XP)
<a name="l00150"></a>00150 {
<a name="l00151"></a>00151     <span class="comment">// setup input (last/additional row should always be 1)</span>
<a name="l00152"></a>00152     Copy(X, Layers[0]-&gt;Acts);
<a name="l00153"></a>00153 
<a name="l00154"></a>00154     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00155"></a>00155     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00156"></a>00156     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++)
<a name="l00157"></a>00157       L2NormSum = Layers[l]-&gt;forwardProp(L2NormSum);
<a name="l00158"></a>00158 
<a name="l00159"></a>00159     <span class="comment">// get output</span>
<a name="l00160"></a>00160     Copy(Layers[Layers.size()/2]-&gt;Acts, YP);
<a name="l00161"></a>00161     Copy(Layers[Layers.size()-1]-&gt;Acts, XP);
<a name="l00162"></a>00162 
<a name="l00163"></a>00163 }
<a name="l00164"></a>00164 
<a name="l00165"></a><a class="code" href="classlbann_1_1AutoEncoder.html#ab9b3d0d2feac82a65058771ae6524271">00165</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1AutoEncoder.html#ab9b3d0d2feac82a65058771ae6524271">lbann::AutoEncoder::global_update</a>() {
<a name="l00166"></a>00166   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); ++l) {
<a name="l00167"></a>00167     Layers[l]-&gt;global_update();
<a name="l00168"></a>00168   }
<a name="l00169"></a>00169 }
<a name="l00170"></a>00170 
<a name="l00171"></a><a class="code" href="classlbann_1_1AutoEncoder.html#adbe7f4436833988df2f170be8bb7fe35">00171</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1AutoEncoder.html#aeaab6088118c1da3df17f4fb126d0e1b">lbann::AutoEncoder::train</a>(<a class="code" href="classlbann_1_1DataReader.html">DataReader</a>* Dataset, <span class="keywordtype">int</span> NumEpoch)
<a name="l00172"></a>00172 {
<a name="l00173"></a>00173         <span class="keywordflow">if</span> (!Dataset || Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>() == 0)
<a name="l00174"></a>00174         <span class="keywordflow">return</span>;
<a name="l00175"></a>00175 
<a name="l00176"></a>00176         <span class="comment">// setup input for forward, backward pass (last/additional row should always be 1)</span>
<a name="l00177"></a>00177   <span class="comment">//    this-&gt;setup(Dataset-&gt;getX(), Dataset-&gt;getX());</span>
<a name="l00178"></a>00178 
<a name="l00179"></a>00179         <span class="comment">// do main loop for epoch</span>
<a name="l00180"></a>00180     <span class="keywordflow">for</span> (<span class="keywordtype">int</span> epoch = 0; epoch &lt; NumEpoch; epoch++) {
<a name="l00181"></a>00181         <span class="comment">// notify epoch begin to event handler</span>
<a name="l00182"></a>00182         <span class="comment">//...</span>
<a name="l00183"></a>00183       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5">am_world_master</a>())
<a name="l00184"></a>00184             printf(<span class="stringliteral">&quot;[%d] Epoch begin ..........................\n&quot;</span>, epoch);
<a name="l00185"></a>00185 
<a name="l00186"></a>00186         <span class="comment">// generate a seed number &lt;- need to change later</span>
<a name="l00187"></a>00187         <span class="keywordtype">unsigned</span> seed = std::chrono::system_clock::now().time_since_epoch().count();
<a name="l00188"></a>00188 
<a name="l00189"></a>00189         <span class="comment">// restart dataset position</span>
<a name="l00190"></a>00190         Dataset-&gt;begin(<span class="keyword">true</span>, (<span class="keywordtype">int</span>)seed);
<a name="l00191"></a>00191 
<a name="l00192"></a>00192         <span class="comment">// train</span>
<a name="l00193"></a>00193         <span class="keywordflow">while</span> (Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a061085bb340a919ff6d5b832a2fe3a74">getPosition</a>() &lt; Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>()) {
<a name="l00194"></a>00194             <span class="comment">// notify mini-batch begin to event handler</span>
<a name="l00195"></a>00195             <span class="comment">// ...</span>
<a name="l00196"></a>00196           <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5">am_world_master</a>())
<a name="l00197"></a>00197                 printf(<span class="stringliteral">&quot;\t[%d] Mini-batch ...\n&quot;</span>, Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a061085bb340a919ff6d5b832a2fe3a74">getPosition</a>());
<a name="l00198"></a>00198 
<a name="l00199"></a>00199             this-&gt;trainBatch(Dataset);
<a name="l00200"></a>00200 
<a name="l00201"></a>00201             <span class="comment">// notify mini-batch end to event handler</span>
<a name="l00202"></a>00202             <span class="comment">// ...</span>
<a name="l00203"></a>00203 
<a name="l00204"></a>00204             <span class="keywordflow">if</span> (!Dataset-&gt;next())
<a name="l00205"></a>00205                 <span class="keywordflow">break</span>;
<a name="l00206"></a>00206         }
<a name="l00207"></a>00207 
<a name="l00208"></a>00208         <span class="comment">// notify epoch end to event handler</span>
<a name="l00209"></a>00209         <span class="comment">//...</span>
<a name="l00210"></a>00210         <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5">am_world_master</a>())
<a name="l00211"></a>00211             printf(<span class="stringliteral">&quot;[%d] Epoch end !\n&quot;</span>, epoch);
<a name="l00212"></a>00212     }
<a name="l00213"></a>00213 }
<a name="l00214"></a>00214 
<a name="l00215"></a>00215 <span class="keywordtype">void</span> lbann::AutoEncoder::trainBatch(<a class="code" href="classlbann_1_1DataReader.html">DataReader</a>* Dataset)
<a name="l00216"></a>00216 {
<a name="l00217"></a>00217         <span class="keywordflow">if</span> (!Dataset || Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>() == 0)
<a name="l00218"></a>00218         <span class="keywordflow">return</span>;
<a name="l00219"></a>00219 
<a name="l00220"></a>00220         <span class="comment">// setup input for forward, backward pass (last/additional row should always be 1)</span>
<a name="l00221"></a>00221   <span class="comment">//    this-&gt;setup(Dataset-&gt;getX(), Dataset-&gt;getX());</span>
<a name="l00222"></a>00222 
<a name="l00223"></a>00223     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00224"></a>00224     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00225"></a>00225     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++) {
<a name="l00226"></a>00226         L2NormSum = Layers[l]-&gt;forwardProp(L2NormSum);
<a name="l00227"></a>00227     }
<a name="l00228"></a>00228 
<a name="l00229"></a>00229     <span class="comment">// backward propagation (mini-batch)</span>
<a name="l00230"></a>00230     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = Layers.size() - 1; l &gt;= 1; l--) {
<a name="l00231"></a>00231         Layers[l]-&gt;backProp();
<a name="l00232"></a>00232     }
<a name="l00233"></a>00233 
<a name="l00234"></a>00234     <span class="comment">// Make sure that the output error is periodically reported in backpropagation</span>
<a name="l00235"></a>00235 
<a name="l00236"></a>00236     <span class="comment">// update weights, biases</span>
<a name="l00237"></a>00237     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++)
<a name="l00238"></a>00238         Layers[l]-&gt;update(0, 0, 0);
<a name="l00239"></a>00239 }
<a name="l00240"></a>00240 
<a name="l00241"></a><a class="code" href="classlbann_1_1AutoEncoder.html#a57080e88f34bd9b8e3b9f61023b35f3a">00241</a> <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> <a class="code" href="classlbann_1_1AutoEncoder.html#a57080e88f34bd9b8e3b9f61023b35f3a">lbann::AutoEncoder::evaluate</a>(<a class="code" href="classlbann_1_1DataReader.html">DataReader</a>* Dataset, <span class="keywordtype">int</span> ErrorType)
<a name="l00242"></a>00242 {
<a name="l00243"></a>00243         <span class="keywordflow">if</span> (!Dataset || Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>() == 0)
<a name="l00244"></a>00244         <span class="keywordflow">return</span> -1;
<a name="l00245"></a>00245 
<a name="l00246"></a>00246     <span class="comment">// setup input for forward, backward pass (last/additional row should always be 1)</span>
<a name="l00247"></a>00247   <span class="comment">//    this-&gt;setup(Dataset-&gt;getX(), NULL);</span>
<a name="l00248"></a>00248 
<a name="l00249"></a>00249     <span class="comment">// restart dataset position</span>
<a name="l00250"></a>00250         Dataset-&gt;begin(<span class="keyword">false</span>, 0);
<a name="l00251"></a>00251 
<a name="l00252"></a>00252     <span class="comment">// test</span>
<a name="l00253"></a>00253         <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5">am_world_master</a>())
<a name="l00254"></a>00254         printf(<span class="stringliteral">&quot;Evaluate .........................\n&quot;</span>);
<a name="l00255"></a>00255 
<a name="l00256"></a>00256     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> error = 0;
<a name="l00257"></a>00257     <span class="keywordflow">while</span> (Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a061085bb340a919ff6d5b832a2fe3a74">getPosition</a>() &lt; Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>()) {
<a name="l00258"></a>00258         <span class="comment">// notify mini-batch begin to event handler</span>
<a name="l00259"></a>00259         <span class="comment">// ...</span>
<a name="l00260"></a>00260       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#adb87fdc17095efd8e4dcb343357a6ba5">am_world_master</a>())
<a name="l00261"></a>00261             printf(<span class="stringliteral">&quot;\t[%d] Mini-batch ...\n&quot;</span>, Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a061085bb340a919ff6d5b832a2fe3a74">getPosition</a>());
<a name="l00262"></a>00262 
<a name="l00263"></a>00263         error += this-&gt;evaluateBatch(Dataset, ErrorType); <span class="comment">// need to change!</span>
<a name="l00264"></a>00264 
<a name="l00265"></a>00265         <span class="comment">// notify mini-batch end to event handler</span>
<a name="l00266"></a>00266         <span class="comment">// ...</span>
<a name="l00267"></a>00267 
<a name="l00268"></a>00268         <span class="keywordflow">if</span> (!Dataset-&gt;next())
<a name="l00269"></a>00269             <span class="keywordflow">break</span>;
<a name="l00270"></a>00270     }
<a name="l00271"></a>00271 
<a name="l00272"></a>00272     <span class="keywordflow">return</span> error;
<a name="l00273"></a>00273 }
<a name="l00274"></a>00274 
<a name="l00275"></a>00275 <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> lbann::AutoEncoder::evaluateBatch(<a class="code" href="classlbann_1_1DataReader.html">DataReader</a>* Dataset, <span class="keywordtype">int</span> ErrorType)
<a name="l00276"></a>00276 {
<a name="l00277"></a>00277         <span class="keywordflow">if</span> (!Dataset || Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a78d3f20a5ab7628011068127ea8b4028">getNumData</a>() == 0)
<a name="l00278"></a>00278         <span class="keywordflow">return</span> -1;
<a name="l00279"></a>00279 
<a name="l00280"></a>00280     <span class="comment">// setup input for forward, backward pass (last/additional row should always be 1)</span>
<a name="l00281"></a>00281   <span class="comment">//    this-&gt;setup(Dataset-&gt;getX(), NULL);</span>
<a name="l00282"></a>00282 
<a name="l00283"></a>00283     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00284"></a>00284     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00285"></a>00285     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; Layers.size(); l++) {
<a name="l00286"></a>00286         L2NormSum = Layers[l]-&gt;forwardProp(L2NormSum);
<a name="l00287"></a>00287     }
<a name="l00288"></a>00288 
<a name="l00289"></a>00289     Copy(*(Layers[Layers.size()-1]-&gt;fp_output()), *(Dataset-&gt;getYP()));
<a name="l00290"></a>00290 
<a name="l00291"></a>00291     <span class="comment">// temporary: need to fix later, depending on error type</span>
<a name="l00292"></a>00292     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> error = 0;
<a name="l00293"></a>00293     <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;am_world_master()) {
<a name="l00294"></a>00294         <span class="keywordflow">for</span> (<span class="keywordtype">int</span> n = 0; n &lt; Dataset-&gt;<a class="code" href="classlbann_1_1DataReader.html#a1efcfbbdca579fc0b356e49ef181d416">getBatchSize</a>(); n++) {
<a name="l00295"></a>00295 
<a name="l00296"></a>00296         }
<a name="l00297"></a>00297     }
<a name="l00298"></a>00298 
<a name="l00299"></a>00299     <span class="keywordflow">return</span> error;
<a name="l00300"></a>00300 }
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
