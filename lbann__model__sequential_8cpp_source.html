<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: src/models/lbann_model_sequential.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>src/models/lbann_model_sequential.cpp</h1><a href="lbann__model__sequential_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC.</span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory.</span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN.</span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// lbann_model_sequential .hpp .cpp - Sequential neural network models</span>
<a name="l00028"></a>00028 <span class="comment"></span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;<a class="code" href="lbann__model__sequential_8hpp.html">lbann/models/lbann_model_sequential.hpp</a>&quot;</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__convolutional_8hpp.html">lbann/layers/lbann_layer_convolutional.hpp</a>&quot;</span>
<a name="l00031"></a>00031 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__pooling_8hpp.html">lbann/layers/lbann_layer_pooling.hpp</a>&quot;</span>
<a name="l00032"></a>00032 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__fully__connected_8hpp.html">lbann/layers/lbann_layer_fully_connected.hpp</a>&quot;</span>
<a name="l00033"></a>00033 <span class="preprocessor">#include &quot;<a class="code" href="lbann__layer__softmax_8hpp.html">lbann/layers/lbann_layer_softmax.hpp</a>&quot;</span>
<a name="l00034"></a>00034 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer_8hpp.html">lbann/optimizers/lbann_optimizer.hpp</a>&quot;</span>
<a name="l00035"></a>00035 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__sgd_8hpp.html">lbann/optimizers/lbann_optimizer_sgd.hpp</a>&quot;</span>
<a name="l00036"></a>00036 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__adagrad_8hpp.html">lbann/optimizers/lbann_optimizer_adagrad.hpp</a>&quot;</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include &quot;<a class="code" href="lbann__optimizer__rmsprop_8hpp.html">lbann/optimizers/lbann_optimizer_rmsprop.hpp</a>&quot;</span>
<a name="l00038"></a>00038 
<a name="l00039"></a>00039 <span class="preprocessor">#include &lt;sys/types.h&gt;</span>
<a name="l00040"></a>00040 <span class="preprocessor">#include &lt;sys/stat.h&gt;</span>
<a name="l00041"></a>00041 <span class="preprocessor">#include &lt;fcntl.h&gt;</span>
<a name="l00042"></a>00042 <span class="preprocessor">#include &lt;unistd.h&gt;</span>
<a name="l00043"></a>00043 
<a name="l00044"></a>00044 <span class="preprocessor">#include &quot;mpi.h&quot;</span>
<a name="l00045"></a>00045 
<a name="l00046"></a>00046 <span class="keyword">using namespace </span>std;
<a name="l00047"></a>00047 <span class="keyword">using namespace </span>El;
<a name="l00048"></a>00048 
<a name="l00049"></a><a class="code" href="classlbann_1_1sequential__model.html#ac091ba088a70b86c127870b2bdb83d17">00049</a> <a class="code" href="classlbann_1_1sequential__model.html#ac091ba088a70b86c127870b2bdb83d17" title="Constructor.">lbann::sequential_model::sequential_model</a>(<span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> mini_batch_size,
<a name="l00050"></a>00050                                           <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>,
<a name="l00051"></a>00051                                           <a class="code" href="classlbann_1_1layer__factory.html">layer_factory</a>* _layer_fac,
<a name="l00052"></a>00052                                           <a class="code" href="classlbann_1_1Optimizer__factory.html">Optimizer_factory</a>* _optimizer_fac)
<a name="l00053"></a>00053   : <a class="code" href="classlbann_1_1model.html">model</a>(comm),
<a name="l00054"></a>00054     m_mini_batch_size(mini_batch_size),
<a name="l00055"></a>00055     layer_fac(_layer_fac),
<a name="l00056"></a>00056     optimizer_fac(_optimizer_fac) {}
<a name="l00057"></a>00057 
<a name="l00058"></a><a class="code" href="classlbann_1_1sequential__model.html#a05ec812bf7db0dc1b29b61aeb197c587">00058</a> <a class="code" href="classlbann_1_1sequential__model.html#a05ec812bf7db0dc1b29b61aeb197c587" title="Destructor.">lbann::sequential_model::~sequential_model</a>()
<a name="l00059"></a>00059 {
<a name="l00060"></a>00060   <span class="comment">// Free layers</span>
<a name="l00061"></a>00061   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); ++l) {
<a name="l00062"></a>00062     <span class="keyword">delete</span> <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l];
<a name="l00063"></a>00063   }
<a name="l00064"></a>00064 }
<a name="l00065"></a>00065 
<a name="l00066"></a>00066 <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#a10e9245e9c58c4b3c3c365f0b65e92b8" title="Save model to file.">lbann::sequential_model::save_to_file</a>(<span class="keyword">const</span> <span class="keywordtype">string</span> file_dir)
<a name="l00067"></a>00067 {
<a name="l00068"></a>00068     <span class="comment">// get our directory name</span>
<a name="l00069"></a>00069     <span class="keyword">const</span> <span class="keywordtype">char</span>* dir = file_dir.c_str();
<a name="l00070"></a>00070 
<a name="l00071"></a>00071     <span class="comment">// get our rank and the number of ranks</span>
<a name="l00072"></a>00072     <span class="keywordtype">int</span> rank, ranks;
<a name="l00073"></a>00073     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
<a name="l00074"></a>00074     MPI_Comm_size(MPI_COMM_WORLD, &amp;ranks);
<a name="l00075"></a>00075 
<a name="l00076"></a>00076     <span class="comment">// report how long this takes</span>
<a name="l00077"></a>00077     Timer timer;
<a name="l00078"></a>00078 
<a name="l00079"></a>00079     <span class="comment">// start timer</span>
<a name="l00080"></a>00080     MPI_Barrier(MPI_COMM_WORLD);
<a name="l00081"></a>00081     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00082"></a>00082         timer.Start();
<a name="l00083"></a>00083         printf(<span class="stringliteral">&quot;Saving parameters to %s ...\n&quot;</span>, dir);
<a name="l00084"></a>00084         fflush(stdout);
<a name="l00085"></a>00085     }
<a name="l00086"></a>00086 
<a name="l00087"></a>00087     <span class="comment">// create directory to hold files</span>
<a name="l00088"></a>00088     <span class="keywordtype">int</span> mkdir_success = <a class="code" href="namespacelbann.html#a8830dea8eef0ab5b93d68e2358ceeb1a">lbann::makedir</a>(dir);
<a name="l00089"></a>00089     <span class="keywordflow">if</span> (! mkdir_success) {
<a name="l00090"></a>00090         <span class="comment">// failed to create the directory</span>
<a name="l00091"></a>00091         <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00092"></a>00092     }
<a name="l00093"></a>00093 
<a name="l00094"></a>00094     <span class="comment">// write out details for each layer</span>
<a name="l00095"></a>00095     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00096"></a>00096         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;saveToFile(-1, dir))
<a name="l00097"></a>00097             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00098"></a>00098 
<a name="l00099"></a>00099 <span class="preprocessor">#if 0</span>
<a name="l00100"></a>00100 <span class="preprocessor"></span>    <span class="comment">// define filename for this rank</span>
<a name="l00101"></a>00101     <span class="keywordtype">char</span> filename[256];
<a name="l00102"></a>00102     sprintf(filename, <span class="stringliteral">&quot;%s/params.%d&quot;</span>, dir, rank);
<a name="l00103"></a>00103 
<a name="l00104"></a>00104     <span class="comment">// open the file for writing</span>
<a name="l00105"></a>00105     mode_t mode = S_IWUSR | S_IRUSR | S_IWGRP | S_IRGRP;
<a name="l00106"></a>00106     <span class="keywordtype">int</span> fd = open(filename, O_WRONLY | O_CREAT | O_TRUNC, mode);
<a name="l00107"></a>00107     <span class="keywordtype">int</span> open_success = (fd != -1);
<a name="l00108"></a>00108     <span class="keywordflow">if</span> (! open_success) {
<a name="l00109"></a>00109         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to create file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00110"></a>00110                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00111"></a>00111         );
<a name="l00112"></a>00112         fflush(stderr);
<a name="l00113"></a>00113     }
<a name="l00114"></a>00114 
<a name="l00115"></a>00115     <span class="comment">// determine whether everyone opened their file</span>
<a name="l00116"></a>00116     <span class="keywordtype">int</span> all_success;
<a name="l00117"></a>00117     MPI_Allreduce(&amp;open_success, &amp;all_success, 1, MPI_INT, MPI_LAND, MPI_COMM_WORLD);
<a name="l00118"></a>00118     <span class="keywordflow">if</span> (! all_success) {
<a name="l00119"></a>00119         <span class="comment">// someone failed to create their file</span>
<a name="l00120"></a>00120         <span class="comment">// TODO: delete our file if we created one?</span>
<a name="l00121"></a>00121         <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00122"></a>00122     }
<a name="l00123"></a>00123 
<a name="l00124"></a>00124     <span class="comment">// write number of ranks (we&apos;ll check this on read)</span>
<a name="l00125"></a>00125     ssize_t write_rc = write(fd, &amp;ranks, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00126"></a>00126     <span class="keywordflow">if</span> (write_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00127"></a>00127         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to write number of ranks to file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00128"></a>00128                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00129"></a>00129         );
<a name="l00130"></a>00130         fflush(stderr);
<a name="l00131"></a>00131     }
<a name="l00132"></a>00132 
<a name="l00133"></a>00133     <span class="comment">// write number of layers (we&apos;ll check this on read)</span>
<a name="l00134"></a>00134     <span class="keywordtype">int</span> layers = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00135"></a>00135     write_rc = write(fd, &amp;layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00136"></a>00136     <span class="keywordflow">if</span> (write_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00137"></a>00137         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to write number of layers to file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00138"></a>00138                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00139"></a>00139         );
<a name="l00140"></a>00140         fflush(stderr);
<a name="l00141"></a>00141     }
<a name="l00142"></a>00142 
<a name="l00143"></a>00143     <span class="comment">// write out details for each layer</span>
<a name="l00144"></a>00144     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00145"></a>00145         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;saveToFile(fd, filename))
<a name="l00146"></a>00146             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00147"></a>00147 
<a name="l00148"></a>00148     <span class="comment">// fsync file</span>
<a name="l00149"></a>00149     <span class="keywordtype">int</span> fsync_rc = fsync(fd);
<a name="l00150"></a>00150     <span class="keywordflow">if</span> (fsync_rc == -1) {
<a name="l00151"></a>00151         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to fsync file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00152"></a>00152                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00153"></a>00153         );
<a name="l00154"></a>00154         fflush(stderr);
<a name="l00155"></a>00155     }
<a name="l00156"></a>00156 
<a name="l00157"></a>00157     <span class="comment">// close our file</span>
<a name="l00158"></a>00158     <span class="keywordtype">int</span> close_rc = close(fd);
<a name="l00159"></a>00159     <span class="keywordflow">if</span> (close_rc == -1) {
<a name="l00160"></a>00160         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to close file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00161"></a>00161                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00162"></a>00162         );
<a name="l00163"></a>00163         fflush(stderr);
<a name="l00164"></a>00164     }
<a name="l00165"></a>00165 <span class="preprocessor">#endif</span>
<a name="l00166"></a>00166 <span class="preprocessor"></span>
<a name="l00167"></a>00167     <span class="comment">// stop timer</span>
<a name="l00168"></a>00168     MPI_Barrier(MPI_COMM_WORLD);
<a name="l00169"></a>00169     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00170"></a>00170         <span class="keywordtype">double</span> secs = timer.Stop();
<a name="l00171"></a>00171         printf(<span class="stringliteral">&quot;Saved parameters to %s (%f secs)\n&quot;</span>, dir, secs);
<a name="l00172"></a>00172         fflush(stdout);
<a name="l00173"></a>00173     }
<a name="l00174"></a>00174 
<a name="l00175"></a>00175     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00176"></a>00176 }
<a name="l00177"></a>00177 
<a name="l00178"></a>00178 <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#a7b841c06d54724caecbd2eee309af1c3" title="Load model from file.">lbann::sequential_model::load_from_file</a>(<span class="keyword">const</span> <span class="keywordtype">string</span> file_dir)
<a name="l00179"></a>00179 {
<a name="l00180"></a>00180     <span class="comment">// get our directory name</span>
<a name="l00181"></a>00181     <span class="keyword">const</span> <span class="keywordtype">char</span>* dir = file_dir.c_str();
<a name="l00182"></a>00182 
<a name="l00183"></a>00183     <span class="comment">// get our rank and the number of ranks</span>
<a name="l00184"></a>00184     <span class="keywordtype">int</span> rank, ranks;
<a name="l00185"></a>00185     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
<a name="l00186"></a>00186     MPI_Comm_size(MPI_COMM_WORLD, &amp;ranks);
<a name="l00187"></a>00187 
<a name="l00188"></a>00188     <span class="comment">// report how long this takes</span>
<a name="l00189"></a>00189     Timer timer;
<a name="l00190"></a>00190 
<a name="l00191"></a>00191     <span class="comment">// start timer</span>
<a name="l00192"></a>00192     MPI_Barrier(MPI_COMM_WORLD);
<a name="l00193"></a>00193     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00194"></a>00194         timer.Start();
<a name="l00195"></a>00195         printf(<span class="stringliteral">&quot;Loading parameters from %s ...\n&quot;</span>, dir);
<a name="l00196"></a>00196         fflush(stdout);
<a name="l00197"></a>00197     }
<a name="l00198"></a>00198 
<a name="l00199"></a>00199     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00200"></a>00200         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;loadFromFile(-1, dir))
<a name="l00201"></a>00201             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00202"></a>00202 
<a name="l00203"></a>00203 <span class="preprocessor">#if 0</span>
<a name="l00204"></a>00204 <span class="preprocessor"></span>    <span class="comment">// get our rank and the number of ranks</span>
<a name="l00205"></a>00205     <span class="keywordtype">int</span> rank, ranks;
<a name="l00206"></a>00206     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
<a name="l00207"></a>00207     MPI_Comm_size(MPI_COMM_WORLD, &amp;ranks);
<a name="l00208"></a>00208 
<a name="l00209"></a>00209     <span class="comment">// define filename for this rank</span>
<a name="l00210"></a>00210     <span class="keywordtype">char</span> filename[256];
<a name="l00211"></a>00211     sprintf(filename, <span class="stringliteral">&quot;%s/params.%d&quot;</span>, dir, rank);
<a name="l00212"></a>00212 
<a name="l00213"></a>00213     <span class="comment">// open the file for reading</span>
<a name="l00214"></a>00214     <span class="keywordtype">int</span> fd = open(filename, O_RDONLY);
<a name="l00215"></a>00215     <span class="keywordtype">int</span> open_success = (fd != -1);
<a name="l00216"></a>00216     <span class="keywordflow">if</span> (! open_success) {
<a name="l00217"></a>00217         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to open file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00218"></a>00218                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00219"></a>00219         );
<a name="l00220"></a>00220         fflush(stderr);
<a name="l00221"></a>00221     }
<a name="l00222"></a>00222 
<a name="l00223"></a>00223     <span class="comment">// determine whether everyone opened their file</span>
<a name="l00224"></a>00224     <span class="keywordtype">int</span> all_success;
<a name="l00225"></a>00225     MPI_Allreduce(&amp;open_success, &amp;all_success, 1, MPI_INT, MPI_LAND, MPI_COMM_WORLD);
<a name="l00226"></a>00226     <span class="keywordflow">if</span> (! all_success) {
<a name="l00227"></a>00227         <span class="comment">// someone failed to open their file</span>
<a name="l00228"></a>00228         <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00229"></a>00229     }
<a name="l00230"></a>00230 
<a name="l00231"></a>00231     <span class="comment">// read number of ranks</span>
<a name="l00232"></a>00232     <span class="keywordtype">int</span> file_ranks;
<a name="l00233"></a>00233     ssize_t read_rc = read(fd, &amp;file_ranks, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00234"></a>00234     <span class="keywordflow">if</span> (read_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00235"></a>00235         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to read number of ranks from file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00236"></a>00236                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00237"></a>00237         );
<a name="l00238"></a>00238         fflush(stderr);
<a name="l00239"></a>00239     }
<a name="l00240"></a>00240 
<a name="l00241"></a>00241     <span class="keywordflow">if</span> (file_ranks != ranks) {
<a name="l00242"></a>00242     }
<a name="l00243"></a>00243 
<a name="l00244"></a>00244     <span class="comment">// read number of layers</span>
<a name="l00245"></a>00245     <span class="keywordtype">int</span> file_layers;
<a name="l00246"></a>00246     read_rc = read(fd, &amp;file_layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00247"></a>00247     <span class="keywordflow">if</span> (read_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00248"></a>00248         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to read number of layers from file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00249"></a>00249                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00250"></a>00250         );
<a name="l00251"></a>00251         fflush(stderr);
<a name="l00252"></a>00252     }
<a name="l00253"></a>00253 
<a name="l00254"></a>00254     <span class="keywordflow">if</span> (file_layers != <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()) {
<a name="l00255"></a>00255     }
<a name="l00256"></a>00256 
<a name="l00257"></a>00257     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00258"></a>00258         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;loadFromFile(fd, filename))
<a name="l00259"></a>00259             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00260"></a>00260 
<a name="l00261"></a>00261     <span class="comment">// close our file</span>
<a name="l00262"></a>00262     <span class="keywordtype">int</span> close_rc = close(fd);
<a name="l00263"></a>00263     <span class="keywordflow">if</span> (close_rc == -1) {
<a name="l00264"></a>00264         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to close file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00265"></a>00265                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00266"></a>00266         );
<a name="l00267"></a>00267         fflush(stderr);
<a name="l00268"></a>00268     }
<a name="l00269"></a>00269 <span class="preprocessor">#endif</span>
<a name="l00270"></a>00270 <span class="preprocessor"></span>
<a name="l00271"></a>00271     <span class="comment">// stop timer</span>
<a name="l00272"></a>00272     MPI_Barrier(MPI_COMM_WORLD);
<a name="l00273"></a>00273     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00274"></a>00274         <span class="keywordtype">double</span> secs = timer.Stop();
<a name="l00275"></a>00275         printf(<span class="stringliteral">&quot;Loaded parameters from %s (%f secs)\n&quot;</span>, dir, secs);
<a name="l00276"></a>00276         fflush(stdout);
<a name="l00277"></a>00277     }
<a name="l00278"></a>00278 
<a name="l00279"></a>00279     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00280"></a>00280 }
<a name="l00281"></a>00281 
<a name="l00282"></a><a class="code" href="classlbann_1_1sequential__model.html#aa249267bd3e129b480c4615f51bfaed5">00282</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#aa249267bd3e129b480c4615f51bfaed5" title="Save model to checkpoint.">lbann::sequential_model::save_to_checkpoint</a>(<span class="keywordtype">int</span> fd, <span class="keyword">const</span> <span class="keywordtype">char</span>* filename, uint64_t* bytes)
<a name="l00283"></a>00283 {
<a name="l00284"></a>00284     <span class="comment">// write number of layers (we&apos;ll check this on read)</span>
<a name="l00285"></a>00285     <span class="keywordtype">int</span> layers = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00286"></a>00286     <span class="keywordtype">int</span> write_rc = write(fd, &amp;layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00287"></a>00287     <span class="keywordflow">if</span> (write_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00288"></a>00288         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to write number of layers to file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00289"></a>00289                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00290"></a>00290         );
<a name="l00291"></a>00291         fflush(stderr);
<a name="l00292"></a>00292     }
<a name="l00293"></a>00293     *bytes += write_rc;
<a name="l00294"></a>00294 
<a name="l00295"></a>00295     <span class="comment">// write out details for each layer</span>
<a name="l00296"></a>00296     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00297"></a>00297         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;saveToCheckpoint(fd, filename, bytes))
<a name="l00298"></a>00298             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00299"></a>00299 
<a name="l00300"></a>00300     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00301"></a>00301 }
<a name="l00302"></a>00302 
<a name="l00303"></a><a class="code" href="classlbann_1_1sequential__model.html#a66da0af31609146827c238fca77e194d">00303</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#a66da0af31609146827c238fca77e194d" title="Load model from checkpoint.">lbann::sequential_model::load_from_checkpoint</a>(<span class="keywordtype">int</span> fd, <span class="keyword">const</span> <span class="keywordtype">char</span>* filename, uint64_t* bytes)
<a name="l00304"></a>00304 {
<a name="l00305"></a>00305     <span class="comment">// read number of layers</span>
<a name="l00306"></a>00306     <span class="keywordtype">int</span> file_layers;
<a name="l00307"></a>00307     <span class="keywordtype">int</span> read_rc = read(fd, &amp;file_layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00308"></a>00308     <span class="keywordflow">if</span> (read_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00309"></a>00309         fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to read number of layers from file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00310"></a>00310                 filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00311"></a>00311         );
<a name="l00312"></a>00312         fflush(stderr);
<a name="l00313"></a>00313     }
<a name="l00314"></a>00314     *bytes += read_rc;
<a name="l00315"></a>00315 
<a name="l00316"></a>00316     <span class="keywordflow">if</span> (file_layers != <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()) {
<a name="l00317"></a>00317         <span class="comment">// error!</span>
<a name="l00318"></a>00318     }
<a name="l00319"></a>00319 
<a name="l00320"></a>00320     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00321"></a>00321         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;loadFromCheckpoint(fd, filename, bytes))
<a name="l00322"></a>00322             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00323"></a>00323 
<a name="l00324"></a>00324     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00325"></a>00325 }
<a name="l00326"></a>00326 
<a name="l00327"></a><a class="code" href="classlbann_1_1sequential__model.html#adb00301ca3ee08ce6882469382e8f54c">00327</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#adb00301ca3ee08ce6882469382e8f54c">lbann::sequential_model::save_to_checkpoint_shared</a>(<span class="keyword">const</span> <span class="keywordtype">char</span>* dir, uint64_t* bytes)
<a name="l00328"></a>00328 {
<a name="l00329"></a>00329     <span class="comment">// write a single header describing layers and sizes?</span>
<a name="l00330"></a>00330 
<a name="l00331"></a>00331     <span class="comment">// get our rank</span>
<a name="l00332"></a>00332     <span class="keywordtype">int</span> rank;
<a name="l00333"></a>00333     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
<a name="l00334"></a>00334 
<a name="l00335"></a>00335     <span class="comment">// have rank 0 write the network file</span>
<a name="l00336"></a>00336     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00337"></a>00337         <span class="comment">// define filename for training state</span>
<a name="l00338"></a>00338         <span class="keywordtype">char</span> filename[1024];
<a name="l00339"></a>00339         sprintf(filename, <span class="stringliteral">&quot;%s/network&quot;</span>, dir);
<a name="l00340"></a>00340 
<a name="l00341"></a>00341         <span class="comment">// open the file for writing</span>
<a name="l00342"></a>00342         <span class="keywordtype">int</span> fd = <a class="code" href="namespacelbann.html#af596e6d2be603e9cf808c98f5412490a">lbann::openwrite</a>(filename);
<a name="l00343"></a>00343 
<a name="l00344"></a>00344         <span class="comment">// write number of layers (we&apos;ll check this on read)</span>
<a name="l00345"></a>00345         <span class="keywordtype">int</span> layers = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00346"></a>00346         <span class="keywordtype">int</span> write_rc = write(fd, &amp;layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00347"></a>00347         <span class="keywordflow">if</span> (write_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00348"></a>00348             fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to write number of layers to file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00349"></a>00349                     filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00350"></a>00350             );
<a name="l00351"></a>00351             fflush(stderr);
<a name="l00352"></a>00352         }
<a name="l00353"></a>00353         *bytes += write_rc;
<a name="l00354"></a>00354 
<a name="l00355"></a>00355         <span class="comment">// close our file</span>
<a name="l00356"></a>00356         <a class="code" href="namespacelbann.html#aceeccedbbafccfa071b21ee99be794a5">lbann::closewrite</a>(fd, filename);
<a name="l00357"></a>00357     }
<a name="l00358"></a>00358 
<a name="l00359"></a>00359     <span class="comment">// write out details for each layer</span>
<a name="l00360"></a>00360     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00361"></a>00361         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;saveToCheckpointShared(dir, bytes))
<a name="l00362"></a>00362             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00363"></a>00363 
<a name="l00364"></a>00364     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00365"></a>00365 }
<a name="l00366"></a>00366 
<a name="l00367"></a><a class="code" href="classlbann_1_1sequential__model.html#a763961718a00350e968c2d0dce86df01">00367</a> <span class="keywordtype">bool</span> <a class="code" href="classlbann_1_1sequential__model.html#a763961718a00350e968c2d0dce86df01">lbann::sequential_model::load_from_checkpoint_shared</a>(<span class="keyword">const</span> <span class="keywordtype">char</span>* dir, uint64_t* bytes)
<a name="l00368"></a>00368 {
<a name="l00369"></a>00369     <span class="comment">// get our rank</span>
<a name="l00370"></a>00370     <span class="keywordtype">int</span> rank;
<a name="l00371"></a>00371     MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank);
<a name="l00372"></a>00372 
<a name="l00373"></a>00373     <span class="comment">// have rank 0 read the network file</span>
<a name="l00374"></a>00374     <span class="keywordtype">int</span> file_layers = -1;
<a name="l00375"></a>00375     <span class="keywordflow">if</span> (rank == 0) {
<a name="l00376"></a>00376         <span class="comment">// define filename for training state</span>
<a name="l00377"></a>00377         <span class="keywordtype">char</span> filename[1024];
<a name="l00378"></a>00378         sprintf(filename, <span class="stringliteral">&quot;%s/network&quot;</span>, dir);
<a name="l00379"></a>00379 
<a name="l00380"></a>00380         <span class="comment">// open the file for writing</span>
<a name="l00381"></a>00381         <span class="keywordtype">int</span> fd = <a class="code" href="namespacelbann.html#a6084b9319eea1997f8446fa3e6879532">lbann::openread</a>(filename);
<a name="l00382"></a>00382         <span class="keywordflow">if</span> (fd != -1) {
<a name="l00383"></a>00383             <span class="comment">// read number of layers</span>
<a name="l00384"></a>00384             <span class="keywordtype">int</span> read_rc = read(fd, &amp;file_layers, <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>));
<a name="l00385"></a>00385             <span class="keywordflow">if</span> (read_rc != <span class="keyword">sizeof</span>(<span class="keywordtype">int</span>)) {
<a name="l00386"></a>00386                 fprintf(stderr, <span class="stringliteral">&quot;ERROR: Failed to read number of layers from file `%s&apos; (%d: %s) @ %s:%d\n&quot;</span>,
<a name="l00387"></a>00387                         filename, errno, strerror(errno), __FILE__, __LINE__
<a name="l00388"></a>00388                 );
<a name="l00389"></a>00389                 fflush(stderr);
<a name="l00390"></a>00390             }
<a name="l00391"></a>00391             *bytes += read_rc;
<a name="l00392"></a>00392 
<a name="l00393"></a>00393             <span class="comment">// close our file</span>
<a name="l00394"></a>00394             <a class="code" href="namespacelbann.html#a38dd30b2ae8214f6595708264369ddb8">lbann::closeread</a>(fd, filename);
<a name="l00395"></a>00395         }
<a name="l00396"></a>00396     }
<a name="l00397"></a>00397     MPI_Bcast(&amp;file_layers, 1, MPI_INT, 0, MPI_COMM_WORLD);
<a name="l00398"></a>00398 
<a name="l00399"></a>00399     <span class="keywordflow">if</span> (file_layers != <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()) {
<a name="l00400"></a>00400         <span class="comment">// error!</span>
<a name="l00401"></a>00401     }
<a name="l00402"></a>00402 
<a name="l00403"></a>00403     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++)
<a name="l00404"></a>00404         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;loadFromCheckpointShared(dir, bytes))
<a name="l00405"></a>00405             <span class="keywordflow">return</span> <span class="keyword">false</span>;
<a name="l00406"></a>00406 
<a name="l00407"></a>00407     <span class="keywordflow">return</span> <span class="keyword">true</span>;
<a name="l00408"></a>00408 }
<a name="l00409"></a>00409 
<a name="l00410"></a>00410 <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> <a class="code" href="classlbann_1_1sequential__model.html#a553795d7e56f9b8f24dd59634be4958c" title="Add layer to sequential model.">lbann::sequential_model::add</a>(<span class="keyword">const</span> std::string layer_name,
<a name="l00411"></a>00411                                   <span class="keyword">const</span> <span class="keywordtype">int</span> layer_dim,
<a name="l00412"></a>00412                                   <span class="keyword">const</span> <a class="code" href="namespacelbann.html#ab00e153fabca7ab166e4d79d47c05c76">activation_type</a> activation,
<a name="l00413"></a>00413                                   <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a7ab6aada4b2438de8ca3dd783775c2f5" title="Weight matrix initialization scheme.">weight_initialization</a> init,
<a name="l00414"></a>00414                                   std::vector&lt;regularizer*&gt; regularizers)
<a name="l00415"></a>00415 {
<a name="l00416"></a>00416     <span class="keyword">const</span> <span class="keywordtype">int</span> layer_index = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00417"></a>00417     <a class="code" href="classlbann_1_1Optimizer.html">Optimizer</a> *optimizer = <a class="code" href="classlbann_1_1sequential__model.html#a592e67ddb0dc61bffcca628765effe7d" title="Optimizer factory.">optimizer_fac</a>-&gt;<a class="code" href="classlbann_1_1Optimizer__factory.html#a58ddf461ad10a337e4497653de512ca5">create_optimizer</a>();
<a name="l00418"></a>00418 
<a name="l00419"></a>00419     <span class="comment">// Get properties of previous layer</span>
<a name="l00420"></a>00420     <span class="keywordtype">int</span> prev_layer_dim = -1;
<a name="l00421"></a>00421     <span class="keywordtype">int</span> prev_layer_index = -1;
<a name="l00422"></a>00422     <span class="keywordflow">if</span>(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size() != 0) {
<a name="l00423"></a>00423       <a class="code" href="classlbann_1_1Layer.html">Layer</a>* prev_layer = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.back();
<a name="l00424"></a>00424       prev_layer_dim = prev_layer-&gt;<a class="code" href="classlbann_1_1Layer.html#a9d4a379d5c9e1102e63b48c53dd8ed44">NumNeurons</a>;
<a name="l00425"></a>00425       prev_layer_index = prev_layer-&gt;<a class="code" href="classlbann_1_1Layer.html#a5d76fcdf50d7ac4fb2fe757fb0cc23d8">Index</a>;
<a name="l00426"></a>00426     }
<a name="l00427"></a>00427 
<a name="l00428"></a>00428     <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>-&gt;am_model_master()) {
<a name="l00429"></a>00429       std::cout &lt;&lt; <span class="stringliteral">&quot;Adding a layer with input &quot;</span> &lt;&lt; prev_layer_dim
<a name="l00430"></a>00430                 &lt;&lt; <span class="stringliteral">&quot; and index &quot;</span> &lt;&lt; layer_index
<a name="l00431"></a>00431                 &lt;&lt; <span class="stringliteral">&quot; prev layer index &quot;</span> &lt;&lt; prev_layer_index &lt;&lt; std::endl;
<a name="l00432"></a>00432     }
<a name="l00433"></a>00433 
<a name="l00434"></a>00434     <span class="keywordflow">if</span>(layer_name.compare(<span class="stringliteral">&quot;FullyConnected&quot;</span>) == 0) {
<a name="l00435"></a>00435       Layer* new_layer
<a name="l00436"></a>00436         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;create_layer&lt;FullyConnectedLayer&gt;(<span class="stringliteral">&quot;FullyConnected&quot;</span>,
<a name="l00437"></a>00437                                                        layer_index,
<a name="l00438"></a>00438                                                        prev_layer_dim,
<a name="l00439"></a>00439                                                        layer_dim,
<a name="l00440"></a>00440                                                        <a class="code" href="classlbann_1_1sequential__model.html#ad4f27748b8cdf0da723f39b3aba9ef2d" title="Mini-batch size.">m_mini_batch_size</a>,
<a name="l00441"></a>00441                                                        activation, init,
<a name="l00442"></a>00442                                                        <a class="code" href="classlbann_1_1model.html#ae5a400e2f0a044c33383975298719cc2">comm</a>,
<a name="l00443"></a>00443                                                        optimizer,
<a name="l00444"></a>00444                                                        regularizers);
<a name="l00445"></a>00445       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.push_back(new_layer);
<a name="l00446"></a>00446     } <span class="keywordflow">else</span> <span class="keywordflow">if</span>(layer_name.compare(<span class="stringliteral">&quot;Softmax&quot;</span>) == 0) {
<a name="l00447"></a>00447       Layer* new_layer
<a name="l00448"></a>00448         = <a class="code" href="classlbann_1_1sequential__model.html#a539722d26abf5a9b6cd748da8e9fa930" title="Layer factory.">layer_fac</a>-&gt;create_layer&lt;SoftmaxLayer&gt;(<span class="stringliteral">&quot;Softmax&quot;</span>,
<a name="l00449"></a>00449                                                 layer_index,
<a name="l00450"></a>00450                                                 prev_layer_dim,
<a name="l00451"></a>00451                                                 layer_dim,
<a name="l00452"></a>00452                                                 m_mini_batch_size,
<a name="l00453"></a>00453                                                 init,
<a name="l00454"></a>00454                                                 comm,
<a name="l00455"></a>00455                                                 optimizer);
<a name="l00456"></a>00456       <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.push_back(new_layer);
<a name="l00457"></a>00457     } <span class="keywordflow">else</span> {
<a name="l00458"></a>00458       std::cout &lt;&lt; <span class="stringliteral">&quot;Unknown layer type &quot;</span> &lt;&lt; layer_name &lt;&lt; std::endl;
<a name="l00459"></a>00459     }
<a name="l00460"></a>00460 
<a name="l00461"></a>00461     <span class="keywordflow">return</span> layer_index;
<a name="l00462"></a>00462 }
<a name="l00463"></a>00463 
<a name="l00464"></a><a class="code" href="classlbann_1_1sequential__model.html#a2341499470419ffae075506df7983c93">00464</a> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> <a class="code" href="classlbann_1_1sequential__model.html#a553795d7e56f9b8f24dd59634be4958c" title="Add layer to sequential model.">lbann::sequential_model::add</a>(<a class="code" href="classlbann_1_1Layer.html">Layer</a> *new_layer)
<a name="l00465"></a>00465 {
<a name="l00466"></a>00466   <span class="keyword">const</span> <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> layer_index = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size();
<a name="l00467"></a>00467   new_layer-&gt;<a class="code" href="classlbann_1_1Layer.html#a5d76fcdf50d7ac4fb2fe757fb0cc23d8">Index</a> = layer_index;
<a name="l00468"></a>00468   <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.push_back(new_layer);
<a name="l00469"></a>00469   <span class="keywordflow">return</span> layer_index;
<a name="l00470"></a>00470 }
<a name="l00471"></a>00471 
<a name="l00472"></a><a class="code" href="classlbann_1_1sequential__model.html#a65505f140bd9ffa43af0ead3b911ae52">00472</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1sequential__model.html#a65505f140bd9ffa43af0ead3b911ae52" title="Remove layer from sequential model.">lbann::sequential_model::remove</a>(<span class="keywordtype">int</span> index)
<a name="l00473"></a>00473 {
<a name="l00474"></a>00474   <span class="keyword">delete</span> <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[index];
<a name="l00475"></a>00475   <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.erase(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.begin()+index);
<a name="l00476"></a>00476 }
<a name="l00477"></a>00477 
<a name="l00478"></a><a class="code" href="classlbann_1_1sequential__model.html#ae992c83737819d406e1311ebe24e07f0">00478</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1sequential__model.html#ae992c83737819d406e1311ebe24e07f0" title="Insert layer in sequential model.">lbann::sequential_model::insert</a>(<span class="keywordtype">int</span> index, <a class="code" href="classlbann_1_1Layer.html">Layer</a> *new_layer)
<a name="l00479"></a>00479 {
<a name="l00480"></a>00480   <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.insert(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.begin()+index, new_layer);
<a name="l00481"></a>00481 }
<a name="l00482"></a>00482 
<a name="l00483"></a><a class="code" href="classlbann_1_1sequential__model.html#a8aa4ddbd6efa79896749838e442b6168">00483</a> <a class="code" href="classlbann_1_1Layer.html">lbann::Layer</a>* <a class="code" href="classlbann_1_1sequential__model.html#a8aa4ddbd6efa79896749838e442b6168" title="Replace layer in sequential model.">lbann::sequential_model::swap</a>(<span class="keywordtype">int</span> index, <a class="code" href="classlbann_1_1Layer.html">Layer</a> *new_layer) {
<a name="l00484"></a>00484   <a class="code" href="classlbann_1_1Layer.html">Layer</a>* tmp = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[index];
<a name="l00485"></a>00485   <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[index] = new_layer;
<a name="l00486"></a>00486   <span class="keywordflow">return</span> tmp;
<a name="l00487"></a>00487 }
<a name="l00488"></a>00488 
<a name="l00489"></a>00489 <span class="comment">/*void lbann::sequential_model::setup()</span>
<a name="l00490"></a>00490 <span class="comment">{</span>
<a name="l00491"></a>00491 <span class="comment">  // Setup each layer</span>
<a name="l00492"></a>00492 <span class="comment">  int prev_layer_dim = -1;</span>
<a name="l00493"></a>00493 <span class="comment">  for (size_t l = 0; l &lt; m_layers.size(); ++l) {</span>
<a name="l00494"></a>00494 <span class="comment">    if (comm-&gt;am_model_master()) {</span>
<a name="l00495"></a>00495 <span class="comment">      cout &lt;&lt; &quot;Setting up a layer with input &quot; &lt;&lt; prev_layer_dim &lt;&lt; &quot; and index &quot; &lt;&lt; m_layers[l]-&gt;Index &lt;&lt; endl;</span>
<a name="l00496"></a>00496 <span class="comment">    }</span>
<a name="l00497"></a>00497 <span class="comment">    m_layers[l]-&gt;setup(prev_layer_dim);</span>
<a name="l00498"></a>00498 <span class="comment">    prev_layer_dim = m_layers[l]-&gt;NumNeurons;</span>
<a name="l00499"></a>00499 <span class="comment">  }</span>
<a name="l00500"></a>00500 <span class="comment"></span>
<a name="l00501"></a>00501 <span class="comment">  // Establish the forward pass input pointers</span>
<a name="l00502"></a>00502 <span class="comment">  // Note: the first layer doesn&apos;t require input</span>
<a name="l00503"></a>00503 <span class="comment">  for (size_t l = 1; l &lt; m_layers.size(); ++l) {</span>
<a name="l00504"></a>00504 <span class="comment">    m_layers[l]-&gt;setup_fp_input(m_layers[l-1]-&gt;fp_output());</span>
<a name="l00505"></a>00505 <span class="comment">  }</span>
<a name="l00506"></a>00506 <span class="comment"></span>
<a name="l00507"></a>00507 <span class="comment">  // Establish the backward pass input pointers</span>
<a name="l00508"></a>00508 <span class="comment">  // Note: the last layer doens&apos;t require input</span>
<a name="l00509"></a>00509 <span class="comment">  for (int l = m_layers.size()-2; l &gt;= 0; --l) {</span>
<a name="l00510"></a>00510 <span class="comment">    m_layers[l]-&gt;setup_bp_input(m_layers[l+1]-&gt;bp_output());</span>
<a name="l00511"></a>00511 <span class="comment">  }</span>
<a name="l00512"></a>00512 <span class="comment"></span>
<a name="l00513"></a>00513 <span class="comment">  // Set up callbacks</span>
<a name="l00514"></a>00514 <span class="comment">  setup_callbacks();</span>
<a name="l00515"></a>00515 <span class="comment">}*/</span>
<a name="l00516"></a>00516 
<a name="l00517"></a><a class="code" href="classlbann_1_1sequential__model.html#aae08481ed20694da7bd096d091cb75c9">00517</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1model.html#a0d278ffa94dd6749e017c2af5c78178d">lbann::sequential_model::setup</a>(<span class="keywordtype">size_t</span> start_index)
<a name="l00518"></a>00518 {
<a name="l00519"></a>00519   <span class="comment">// Setup each layer</span>
<a name="l00520"></a>00520   <span class="keywordtype">int</span> prev_layer_dim, fp_index,bp_index;
<a name="l00521"></a>00521   <span class="keywordflow">if</span>(start_index &gt; 0) {
<a name="l00522"></a>00522     prev_layer_dim = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[start_index-1]-&gt;NumNeurons;
<a name="l00523"></a>00523     fp_index = start_index;
<a name="l00524"></a>00524     bp_index = start_index-1;
<a name="l00525"></a>00525   }<span class="keywordflow">else</span> {
<a name="l00526"></a>00526     prev_layer_dim = -1;
<a name="l00527"></a>00527     fp_index = 1;
<a name="l00528"></a>00528     bp_index = 0;
<a name="l00529"></a>00529   }
<a name="l00530"></a>00530 
<a name="l00531"></a>00531   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = start_index; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); ++l) {
<a name="l00532"></a>00532     <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00533"></a>00533       cout &lt;&lt; <span class="stringliteral">&quot;Setting up a layer with input &quot;</span> &lt;&lt; prev_layer_dim &lt;&lt; <span class="stringliteral">&quot; and index &quot;</span> &lt;&lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;Index &lt;&lt; endl;
<a name="l00534"></a>00534     }
<a name="l00535"></a>00535     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;setup(prev_layer_dim);
<a name="l00536"></a>00536     prev_layer_dim = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;NumNeurons;
<a name="l00537"></a>00537   }
<a name="l00538"></a>00538 
<a name="l00539"></a>00539   <span class="comment">// Establish the forward pass input pointers</span>
<a name="l00540"></a>00540   <span class="comment">// Note: the first layer doesn&apos;t require input</span>
<a name="l00541"></a>00541   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = fp_index; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); ++l) {
<a name="l00542"></a>00542     <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00543"></a>00543       <span class="comment">//cout &lt;&lt; &quot;Setting up a fp input of layer &quot; &lt;&lt; l &lt;&lt; &quot;as layer &quot; &lt;&lt; l-1 &lt;&lt; endl;</span>
<a name="l00544"></a>00544     }
<a name="l00545"></a>00545     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;setup_fp_input(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l-1]-&gt;fp_output());
<a name="l00546"></a>00546   }
<a name="l00547"></a>00547 
<a name="l00548"></a>00548   <span class="comment">// Establish the backward pass input pointers</span>
<a name="l00549"></a>00549   <span class="comment">// Note: the last layer doens&apos;t require input</span>
<a name="l00550"></a>00550   <span class="keywordflow">for</span> (<span class="keywordtype">int</span> l = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()-2; l &gt;= bp_index; --l) {
<a name="l00551"></a>00551     <span class="keywordflow">if</span> (comm-&gt;am_model_master()) {
<a name="l00552"></a>00552       <span class="comment">//cout &lt;&lt; &quot;Setting up a bp input of layer &quot; &lt;&lt; l &lt;&lt; &quot;as layer &quot; &lt;&lt; l+1 &lt;&lt; endl;</span>
<a name="l00553"></a>00553     }
<a name="l00554"></a>00554     <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;setup_bp_input(<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l+1]-&gt;bp_output());
<a name="l00555"></a>00555   }
<a name="l00556"></a>00556 
<a name="l00557"></a>00557   <span class="comment">// Set up callbacks</span>
<a name="l00558"></a>00558   <a class="code" href="classlbann_1_1model.html#af61c38d8d5ce7dad5a74dcf459758dea">setup_callbacks</a>();
<a name="l00559"></a>00559 }
<a name="l00560"></a>00560 
<a name="l00561"></a>00561 
<a name="l00562"></a>00562 
<a name="l00563"></a>00563 <span class="preprocessor">#if 0</span>
<a name="l00564"></a>00564 <span class="preprocessor"></span><a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>* lbann::sequential_model::predict_mini_batch(<a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>* X)
<a name="l00565"></a>00565 {
<a name="l00566"></a>00566     <span class="comment">// setup input for forward, backward pass (last/additional row should always be 1)</span>
<a name="l00567"></a>00567   <span class="comment">//    this-&gt;setup(X, NULL);</span>
<a name="l00568"></a>00568 
<a name="l00569"></a>00569     <span class="comment">// forward propagation (mini-batch)</span>
<a name="l00570"></a>00570     <a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a> L2NormSum = 0;
<a name="l00571"></a>00571     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 1; l &lt; <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size(); l++) {
<a name="l00572"></a>00572         L2NormSum = <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[l]-&gt;forwardProp(L2NormSum);
<a name="l00573"></a>00573     }
<a name="l00574"></a>00574 
<a name="l00575"></a>00575     <span class="keywordflow">return</span> <a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>[<a class="code" href="classlbann_1_1sequential__model.html#a33d0763e07a97def5a6b9b57a6db4c9a" title="List of layers.">m_layers</a>.size()-1]-&gt;fp_output();
<a name="l00576"></a>00576 }
<a name="l00577"></a>00577 <span class="preprocessor">#endif</span>
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
