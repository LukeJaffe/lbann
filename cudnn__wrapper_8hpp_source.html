<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: include/lbann/utils/cudnn_wrapper.hpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>include/lbann/utils/cudnn_wrapper.hpp</h1><a href="cudnn__wrapper_8hpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC. </span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory. </span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN. </span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// cudnn_wrapper .hpp .cpp - cuDNN support - wrapper classes, utility functions</span>
<a name="l00028"></a>00028 <span class="comment"></span>
<a name="l00029"></a>00029 <span class="preprocessor">#ifndef CUDNN_WRAPPER_HPP_INCLUDED</span>
<a name="l00030"></a>00030 <span class="preprocessor"></span><span class="preprocessor">#define CUDNN_WRAPPER_HPP_INCLUDED</span>
<a name="l00031"></a>00031 <span class="preprocessor"></span>
<a name="l00032"></a>00032 <span class="preprocessor">#ifdef __LIB_CUDNN</span>
<a name="l00033"></a>00033 <span class="preprocessor"></span>
<a name="l00034"></a>00034 <span class="preprocessor">#include &lt;vector&gt;</span>
<a name="l00035"></a>00035 <span class="preprocessor">#include &lt;cuda.h&gt;</span>
<a name="l00036"></a>00036 <span class="preprocessor">#include &lt;cudnn.h&gt;</span>
<a name="l00037"></a>00037 <span class="preprocessor">#include &lt;cub/util_allocator.cuh&gt;</span>
<a name="l00038"></a>00038 <span class="preprocessor">#include &quot;<a class="code" href="lbann__base_8hpp.html">lbann/lbann_base.hpp</a>&quot;</span>
<a name="l00039"></a>00039 <span class="preprocessor">#include &quot;<a class="code" href="lbann__comm_8hpp.html">lbann/lbann_comm.hpp</a>&quot;</span>
<a name="l00040"></a>00040 
<a name="l00041"></a>00041 <span class="keyword">namespace </span>cudnn
<a name="l00042"></a>00042 {
<a name="l00043"></a>00043 
<a name="l00045"></a>00045   <span class="keyword">class </span>cudnn_manager
<a name="l00046"></a>00046   {
<a name="l00047"></a>00047 
<a name="l00048"></a>00048   <span class="keyword">public</span>:
<a name="l00054"></a>00054     cudnn_manager(<a class="code" href="classlbann_1_1lbann__comm.html">lbann::lbann_comm</a>* _comm, <span class="keywordtype">int</span> max_num_gpus = -1);
<a name="l00055"></a>00055 
<a name="l00057"></a>00057     ~cudnn_manager();
<a name="l00058"></a>00058 
<a name="l00060"></a>00060     <span class="keywordtype">void</span> print_version() <span class="keyword">const</span>;
<a name="l00061"></a>00061 
<a name="l00062"></a>00062   <span class="keyword">public</span>:
<a name="l00063"></a>00063 
<a name="l00065"></a>00065     <a class="code" href="classlbann_1_1lbann__comm.html">lbann::lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a>;
<a name="l00066"></a>00066 
<a name="l00068"></a>00068     <span class="keywordtype">int</span> m_num_gpus;
<a name="l00070"></a>00070     <span class="keywordtype">int</span> m_num_total_gpus;
<a name="l00071"></a>00071 
<a name="l00074"></a>00074     cub::CachingDeviceAllocator* m_gpu_memory;
<a name="l00075"></a>00075 
<a name="l00077"></a>00077     std::vector&lt;int&gt; m_gpus;
<a name="l00079"></a>00079     std::vector&lt;cudaStream_t&gt; m_streams;
<a name="l00081"></a>00081     std::vector&lt;cudnnHandle_t&gt; m_handles;
<a name="l00082"></a>00082 
<a name="l00083"></a>00083   };
<a name="l00084"></a>00084 
<a name="l00086"></a>00086   <span class="keyword">class </span>cudnn_convolutional_layer
<a name="l00087"></a>00087   {
<a name="l00088"></a>00088   <span class="keyword">public</span>:
<a name="l00089"></a>00089 
<a name="l00091"></a>00091     cudnn_convolutional_layer(<span class="keywordtype">int</span> num_dims,
<a name="l00092"></a>00092                               <span class="keywordtype">int</span> src_channels,
<a name="l00093"></a>00093                               <span class="keywordtype">int</span> dst_channels,
<a name="l00094"></a>00094                               <span class="keyword">const</span> <span class="keywordtype">int</span>* src_dims,
<a name="l00095"></a>00095                               <span class="keyword">const</span> <span class="keywordtype">int</span>* filter_dims,
<a name="l00096"></a>00096                               <span class="keyword">const</span> <span class="keywordtype">int</span>* conv_pads,
<a name="l00097"></a>00097                               <span class="keyword">const</span> <span class="keywordtype">int</span>* conv_strides,
<a name="l00098"></a>00098                               <span class="keywordtype">int</span> mini_batch_size,
<a name="l00099"></a>00099                               cudnn_manager* cudnn);
<a name="l00100"></a>00100     
<a name="l00102"></a>00102     ~cudnn_convolutional_layer();
<a name="l00103"></a>00103     
<a name="l00105"></a>00105     <span class="keywordtype">void</span> setup();
<a name="l00106"></a>00106 
<a name="l00108"></a>00108 
<a name="l00109"></a>00109     <span class="keywordtype">void</span> forward(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; src, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; filter, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; bias, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; dst);
<a name="l00110"></a>00110     
<a name="l00112"></a>00112 
<a name="l00113"></a>00113     <span class="keywordtype">void</span> backward(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; src, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; filter, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_dst,
<a name="l00114"></a>00114                   <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_filter, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_bias, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_src);
<a name="l00115"></a>00115 
<a name="l00116"></a>00116   <span class="keyword">public</span>:
<a name="l00117"></a>00117       
<a name="l00119"></a>00119     <span class="keyword">const</span> <span class="keywordtype">int</span> m_num_dims;
<a name="l00120"></a>00120 
<a name="l00122"></a>00122     <span class="keywordtype">int</span> m_src_size;
<a name="l00124"></a>00124     <span class="keywordtype">int</span> m_dst_size;
<a name="l00126"></a>00126     <span class="keywordtype">int</span> m_filter_size;
<a name="l00127"></a>00127 
<a name="l00129"></a>00129 
<a name="l00130"></a>00130     std::vector&lt;int&gt; m_src_dims;
<a name="l00132"></a>00132 
<a name="l00133"></a>00133     std::vector&lt;int&gt; m_dst_dims;
<a name="l00135"></a>00135 
<a name="l00136"></a>00136     std::vector&lt;int&gt; m_filter_dims;
<a name="l00137"></a>00137 
<a name="l00139"></a>00139     std::vector&lt;int&gt; m_conv_pads;
<a name="l00141"></a>00141     std::vector&lt;int&gt; m_conv_strides;
<a name="l00142"></a>00142   
<a name="l00143"></a>00143   <span class="keyword">private</span>:
<a name="l00144"></a>00144 
<a name="l00146"></a>00146     cudnn_manager* m_cudnn;
<a name="l00147"></a>00147 
<a name="l00149"></a>00149     <span class="keyword">const</span> cudnnDataType_t m_cudnn_data_type;
<a name="l00150"></a>00150 
<a name="l00152"></a>00152     cudnnTensorDescriptor_t m_src_desc;
<a name="l00154"></a>00154     cudnnTensorDescriptor_t m_dst_desc;
<a name="l00156"></a>00156     cudnnFilterDescriptor_t m_filter_desc;
<a name="l00158"></a>00158     cudnnConvolutionDescriptor_t m_conv_desc;
<a name="l00159"></a>00159 
<a name="l00161"></a>00161     cudnnConvolutionFwdAlgo_t m_forward_algo;
<a name="l00163"></a>00163     <span class="keywordtype">size_t</span> m_forward_work_space_size;
<a name="l00164"></a>00164 
<a name="l00166"></a>00166 
<a name="l00167"></a>00167     cudnnConvolutionBwdFilterAlgo_t m_backward_filter_algo;
<a name="l00169"></a>00169 
<a name="l00170"></a>00170     <span class="keywordtype">size_t</span> m_backward_filter_work_space_size;
<a name="l00171"></a>00171 
<a name="l00173"></a>00173 
<a name="l00174"></a>00174     cudnnConvolutionBwdDataAlgo_t m_backward_data_algo;
<a name="l00176"></a>00176 
<a name="l00177"></a>00177     <span class="keywordtype">size_t</span> m_backward_data_work_space_size;
<a name="l00178"></a>00178 
<a name="l00180"></a>00180     std::vector&lt;int&gt; m_src_strides;
<a name="l00182"></a>00182     std::vector&lt;int&gt; m_dst_strides;
<a name="l00183"></a>00183 
<a name="l00184"></a>00184   };
<a name="l00185"></a>00185 
<a name="l00187"></a>00187   <span class="keyword">class </span>cudnn_pooling_layer
<a name="l00188"></a>00188   {
<a name="l00189"></a>00189 
<a name="l00190"></a>00190   <span class="keyword">public</span>:
<a name="l00191"></a>00191 
<a name="l00193"></a>00193     cudnn_pooling_layer(<span class="keywordtype">int</span> num_dims,
<a name="l00194"></a>00194                         <span class="keywordtype">int</span> channels,
<a name="l00195"></a>00195                         <span class="keyword">const</span> <span class="keywordtype">int</span>* src_dims,
<a name="l00196"></a>00196                         <a class="code" href="lbann__base_8hpp.html#ac47a6ee5278a53898222a48639a2bf39" title="Pooling layer mode.">pool_mode</a> _pool_mode,
<a name="l00197"></a>00197                         <span class="keyword">const</span> <span class="keywordtype">int</span>* pool_dims,
<a name="l00198"></a>00198                         <span class="keyword">const</span> <span class="keywordtype">int</span>* pool_pads,
<a name="l00199"></a>00199                         <span class="keyword">const</span> <span class="keywordtype">int</span>* pool_strides,
<a name="l00200"></a>00200                         cudnn_manager* cudnn);
<a name="l00201"></a>00201     
<a name="l00203"></a>00203     ~cudnn_pooling_layer();
<a name="l00204"></a>00204     
<a name="l00206"></a>00206     <span class="keywordtype">void</span> setup();
<a name="l00207"></a>00207 
<a name="l00209"></a>00209     <span class="keywordtype">void</span> forward(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; src, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; dst);
<a name="l00210"></a>00210     
<a name="l00212"></a>00212     <span class="keywordtype">void</span> backward(<span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; src, <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; dst,
<a name="l00213"></a>00213                   <span class="keyword">const</span> <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_dst, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; grad_src);
<a name="l00214"></a>00214 
<a name="l00215"></a>00215   <span class="keyword">public</span>:
<a name="l00216"></a>00216       
<a name="l00218"></a>00218     <span class="keyword">const</span> <span class="keywordtype">int</span> m_num_dims;
<a name="l00219"></a>00219 
<a name="l00221"></a>00221     <span class="keywordtype">int</span> m_src_size;
<a name="l00223"></a>00223     <span class="keywordtype">int</span> m_dst_size;
<a name="l00224"></a>00224 
<a name="l00226"></a>00226 
<a name="l00227"></a>00227     std::vector&lt;int&gt; m_src_dims;
<a name="l00229"></a>00229 
<a name="l00230"></a>00230     std::vector&lt;int&gt; m_dst_dims;
<a name="l00231"></a>00231 
<a name="l00233"></a>00233     <span class="keyword">const</span> cudnnPoolingMode_t m_pool_mode;
<a name="l00234"></a>00234 
<a name="l00236"></a>00236 
<a name="l00237"></a>00237     std::vector&lt;int&gt; m_pool_dims;
<a name="l00239"></a>00239 
<a name="l00240"></a>00240     std::vector&lt;int&gt; m_pool_pads;
<a name="l00242"></a>00242 
<a name="l00243"></a>00243     std::vector&lt;int&gt; m_pool_strides;
<a name="l00244"></a>00244   
<a name="l00245"></a>00245   <span class="keyword">private</span>:
<a name="l00246"></a>00246 
<a name="l00248"></a>00248     cudnn_manager* m_cudnn;
<a name="l00249"></a>00249 
<a name="l00251"></a>00251     <span class="keyword">const</span> cudnnDataType_t m_cudnn_data_type;
<a name="l00252"></a>00252 
<a name="l00254"></a>00254     cudnnTensorDescriptor_t m_src_desc;
<a name="l00256"></a>00256     cudnnTensorDescriptor_t m_dst_desc;
<a name="l00258"></a>00258     cudnnPoolingDescriptor_t m_pool_desc;
<a name="l00259"></a>00259 
<a name="l00261"></a>00261     std::vector&lt;int&gt; m_src_strides;
<a name="l00263"></a>00263     std::vector&lt;int&gt; m_dst_strides;
<a name="l00264"></a>00264 
<a name="l00265"></a>00265   };
<a name="l00266"></a>00266 
<a name="l00267"></a>00267 }
<a name="l00268"></a>00268 
<a name="l00269"></a>00269 <span class="preprocessor">#else  // __LIB_CUDNN</span>
<a name="l00270"></a>00270 <span class="preprocessor"></span>
<a name="l00271"></a><a class="code" href="namespacecudnn.html">00271</a> <span class="keyword">namespace </span>cudnn
<a name="l00272"></a>00272 {
<a name="l00273"></a><a class="code" href="classcudnn_1_1cudnn__manager.html">00273</a>   <span class="keyword">class </span><a class="code" href="classcudnn_1_1cudnn__manager.html">cudnn_manager</a> {};
<a name="l00274"></a><a class="code" href="classcudnn_1_1cudnn__convolutional__layer.html">00274</a>   <span class="keyword">class </span><a class="code" href="classcudnn_1_1cudnn__convolutional__layer.html">cudnn_convolutional_layer</a> {};
<a name="l00275"></a><a class="code" href="classcudnn_1_1cudnn__pooling__layer.html">00275</a>   <span class="keyword">class </span><a class="code" href="classcudnn_1_1cudnn__pooling__layer.html">cudnn_pooling_layer</a> {};
<a name="l00276"></a>00276 }
<a name="l00277"></a>00277 
<a name="l00278"></a>00278 <span class="preprocessor">#endif  // __LIB_CUDNN</span>
<a name="l00279"></a>00279 <span class="preprocessor"></span>
<a name="l00280"></a>00280 <span class="preprocessor">#endif // CUDNN_WRAPPER_HPP_INCLUDED</span>
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
