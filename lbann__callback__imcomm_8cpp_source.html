<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>LBANN: src/callbacks/lbann_callback_imcomm.cpp Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.1 -->
<h1>src/callbacks/lbann_callback_imcomm.cpp</h1><a href="lbann__callback__imcomm_8cpp.html">Go to the documentation of this file.</a><div class="fragment"><pre class="fragment"><a name="l00001"></a>00001 
<a name="l00002"></a>00002 <span class="comment">// Copyright (c) 2014-2016, Lawrence Livermore National Security, LLC. </span>
<a name="l00003"></a>00003 <span class="comment">// Produced at the Lawrence Livermore National Laboratory. </span>
<a name="l00004"></a>00004 <span class="comment">// Written by the LBANN Research Team (B. Van Essen, et al.) listed in</span>
<a name="l00005"></a>00005 <span class="comment">// the CONTRIBUTORS file. &lt;lbann-dev@llnl.gov&gt;</span>
<a name="l00006"></a>00006 <span class="comment">//</span>
<a name="l00007"></a>00007 <span class="comment">// LLNL-CODE-697807.</span>
<a name="l00008"></a>00008 <span class="comment">// All rights reserved.</span>
<a name="l00009"></a>00009 <span class="comment">//</span>
<a name="l00010"></a>00010 <span class="comment">// This file is part of LBANN: Livermore Big Artificial Neural Network</span>
<a name="l00011"></a>00011 <span class="comment">// Toolkit. For details, see http://software.llnl.gov/LBANN or</span>
<a name="l00012"></a>00012 <span class="comment">// https://github.com/LLNL/LBANN. </span>
<a name="l00013"></a>00013 <span class="comment">//</span>
<a name="l00014"></a>00014 <span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;Licensee&quot;); you</span>
<a name="l00015"></a>00015 <span class="comment">// may not use this file except in compliance with the License.  You may</span>
<a name="l00016"></a>00016 <span class="comment">// obtain a copy of the License at:</span>
<a name="l00017"></a>00017 <span class="comment">//</span>
<a name="l00018"></a>00018 <span class="comment">// http://www.apache.org/licenses/LICENSE-2.0</span>
<a name="l00019"></a>00019 <span class="comment">//</span>
<a name="l00020"></a>00020 <span class="comment">// Unless required by applicable law or agreed to in writing, software</span>
<a name="l00021"></a>00021 <span class="comment">// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<a name="l00022"></a>00022 <span class="comment">// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or</span>
<a name="l00023"></a>00023 <span class="comment">// implied. See the License for the specific language governing</span>
<a name="l00024"></a>00024 <span class="comment">// permissions and limitations under the license.</span>
<a name="l00025"></a>00025 <span class="comment">//</span>
<a name="l00026"></a>00026 <span class="comment">// lbann_callback_imcomm .hpp .cpp - Send gradient updates between models</span>
<a name="l00028"></a>00028 <span class="comment"></span>
<a name="l00029"></a>00029 <span class="preprocessor">#include &quot;<a class="code" href="lbann__callback__imcomm_8hpp.html">lbann/callbacks/lbann_callback_imcomm.hpp</a>&quot;</span>
<a name="l00030"></a>00030 <span class="preprocessor">#include &quot;<a class="code" href="lbann__timer_8hpp.html">lbann/utils/lbann_timer.hpp</a>&quot;</span>
<a name="l00031"></a>00031 <span class="preprocessor">#include &quot;<a class="code" href="lbann__exception_8hpp.html">lbann/utils/lbann_exception.hpp</a>&quot;</span>
<a name="l00032"></a>00032 
<a name="l00033"></a>00033 <span class="keyword">namespace </span>lbann {
<a name="l00034"></a>00034 
<a name="l00035"></a><a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aef048c5bdeb5b36d7b5e0fdfddfb6a7a">00035</a> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aef048c5bdeb5b36d7b5e0fdfddfb6a7a">lbann_callback_imcomm::lbann_callback_imcomm</a>(<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6a">lbann_callback_imcomm::comm_type</a> ct,
<a name="l00036"></a>00036                                              <a class="code" href="classlbann_1_1lbann__summary.html">lbann_summary</a>* _summarizer) :
<a name="l00037"></a>00037   <a class="code" href="classlbann_1_1lbann__callback.html">lbann_callback</a>(1, _summarizer), ct(ct) {
<a name="l00038"></a>00038   
<a name="l00039"></a>00039 }
<a name="l00040"></a>00040 
<a name="l00041"></a><a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a84d47e38ad45417f88d32eb37d94ebbd">00041</a> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aef048c5bdeb5b36d7b5e0fdfddfb6a7a">lbann_callback_imcomm::lbann_callback_imcomm</a>(<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6a">lbann_callback_imcomm::comm_type</a> ct,
<a name="l00042"></a>00042                                              std::unordered_set&lt;uint&gt; _layers,
<a name="l00043"></a>00043                                              <a class="code" href="classlbann_1_1lbann__summary.html">lbann_summary</a>* _summarizer) :
<a name="l00044"></a>00044   <a class="code" href="classlbann_1_1lbann__callback.html">lbann_callback</a>(1, _summarizer), ct(ct), layer_indices(_layers) {
<a name="l00045"></a>00045 
<a name="l00046"></a>00046 }
<a name="l00047"></a>00047 
<a name="l00048"></a><a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a1cc160d368f1dd5bd30f1504c0df8003">00048</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a1cc160d368f1dd5bd30f1504c0df8003">lbann_callback_imcomm::setup</a>(<a class="code" href="classlbann_1_1model.html">model</a>* m) {
<a name="l00049"></a>00049   <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aa617c54b0bba0aaba9a916c0cda2cfba">ct</a> != <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aafa59156bc4d5bcbf6bd80918d062da03">NONE</a>) {
<a name="l00050"></a>00050     <span class="keywordtype">bool</span> add = <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.size() == 0;
<a name="l00051"></a>00051     std::vector&lt;Layer*&gt;&amp; layers = m-&gt;<a class="code" href="classlbann_1_1model.html#a45e75790d328ac2a85aac59faf35094a">get_layers</a>();
<a name="l00052"></a>00052     <span class="keywordflow">for</span> (<a class="code" href="classlbann_1_1Layer.html">Layer</a>* layer : layers) {
<a name="l00053"></a>00053       <a class="code" href="datatype_8hpp.html#a91ad9478d81a7aaf2593e8d9c3d06a14">uint</a> idx = layer-&gt;get_index();
<a name="l00054"></a>00054       <span class="keywordflow">if</span> (add || <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.find(idx) != <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.end()) {
<a name="l00055"></a>00055         <span class="comment">// Ensure index is present (overwrites if already there).</span>
<a name="l00056"></a>00056         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.insert(idx);
<a name="l00057"></a>00057         <span class="comment">// Update the layer&apos;s effective mini-batch size so it averages properly.</span>
<a name="l00058"></a>00058         layer-&gt;set_effective_minibatch_size(
<a name="l00059"></a>00059           layer-&gt;get_minibatch_size() * m-&gt;<a class="code" href="classlbann_1_1model.html#aa837a468e77991314053a93441d111ca">get_comm</a>()-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a54842b679a3756cf79b43baf46caf637">get_num_models</a>());
<a name="l00060"></a>00060         <span class="comment">// Skip adding matrices when we don&apos;t need to.</span>
<a name="l00061"></a>00061         <span class="keywordflow">if</span> (!<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ad3a9f43ceb08af462ce9d378e70bd76d">ct_does_quantization</a>()) <span class="keywordflow">continue</span>;
<a name="l00062"></a>00062         <span class="comment">// TODO: handle case where WB_D is in other matrix distribution</span>
<a name="l00063"></a>00063         <a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp; WB_D = (<a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp;) layer-&gt;get_weights_biases_gradient();
<a name="l00064"></a>00064         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>.emplace(idx, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>{});
<a name="l00065"></a>00065         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>.emplace(idx, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>{});
<a name="l00066"></a>00066         <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aa617c54b0bba0aaba9a916c0cda2cfba">ct</a> == <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aa06f19090efbd982638c20bcb8a3c7d33">ONEBIT_QUANTIZATION</a>) {
<a name="l00067"></a>00067           <span class="comment">// Set up gradient history and SGD optimizer for one-bit quantization.</span>
<a name="l00068"></a>00068           <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab10f1484a37c6e6085329796dc7ef7c4">gradhistories</a>.emplace(idx, <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>{});
<a name="l00069"></a>00069           <span class="keywordflow">if</span> (layer-&gt;optimizer != <span class="keyword">nullptr</span>) {
<a name="l00070"></a>00070             <span class="keywordflow">if</span> (<span class="keyword">typeid</span>(*(layer-&gt;optimizer)) != <span class="keyword">typeid</span>(<a class="code" href="classlbann_1_1Adagrad.html">Adagrad&lt;DistMat&gt;</a>)) {
<a name="l00071"></a>00071               <span class="keywordflow">throw</span> <a class="code" href="classlbann_1_1lbann__exception.html">lbann_exception</a>(
<a name="l00072"></a>00072                 <span class="stringliteral">&quot;lbann_callback_imcomm: Cannot do one-bit quantization for &quot;</span>
<a name="l00073"></a>00073                 <span class="stringliteral">&quot;layer that does not use Adagrad&quot;</span>);
<a name="l00074"></a>00074             }
<a name="l00075"></a>00075             <span class="comment">// TODO: This leaks the old optimizer.</span>
<a name="l00076"></a>00076             layer-&gt;optimizer = <span class="keyword">new</span> <a class="code" href="classlbann_1_1SGD.html">SGD&lt;DistMat&gt;</a>(
<a name="l00077"></a>00077               layer-&gt;comm, layer-&gt;optimizer-&gt;get_learning_rate(),
<a name="l00078"></a>00078               0.0f, 0.0f, <span class="keyword">false</span>);
<a name="l00079"></a>00079             layer-&gt;optimizer-&gt;setup(layer-&gt;WB-&gt;Width(), layer-&gt;WB-&gt;Height());
<a name="l00080"></a>00080           }
<a name="l00081"></a>00081         }
<a name="l00082"></a>00082       }
<a name="l00083"></a>00083     }
<a name="l00084"></a>00084   }
<a name="l00085"></a>00085 }
<a name="l00086"></a>00086 
<a name="l00087"></a><a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a9e409109c25b6173bc57108281e7aeb5">00087</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a9e409109c25b6173bc57108281e7aeb5">lbann_callback_imcomm::on_epoch_end</a>(<a class="code" href="classlbann_1_1model.html">model</a>* m) {
<a name="l00088"></a>00088   <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a> = m-&gt;<a class="code" href="classlbann_1_1model.html#aa837a468e77991314053a93441d111ca">get_comm</a>();
<a name="l00089"></a>00089   <span class="keywordflow">if</span> (comm-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a54842b679a3756cf79b43baf46caf637">get_num_models</a>() == 1 ||
<a name="l00090"></a>00090       m-&gt;<a class="code" href="classlbann_1_1model.html#a66c5ac5cb51cdc7dea79a475147bcd5b">get_execution_mode</a>() != <a class="code" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8aef839bdee87b9298d9be97d3f9c90469">execution_mode::training</a>) {
<a name="l00091"></a>00091     <span class="keywordflow">return</span>;  <span class="comment">// No point with only one model.</span>
<a name="l00092"></a>00092   }
<a name="l00093"></a>00093   <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ad3a9f43ceb08af462ce9d378e70bd76d">ct_does_quantization</a>()) {
<a name="l00094"></a>00094     std::vector&lt;Layer*&gt;&amp; layers = m-&gt;<a class="code" href="classlbann_1_1model.html#a45e75790d328ac2a85aac59faf35094a">get_layers</a>();
<a name="l00095"></a>00095     <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt; layers.size(); ++l) {
<a name="l00096"></a>00096       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.find(layers[l]-&gt;get_index()) == <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.end()) {
<a name="l00097"></a>00097         <span class="keywordflow">continue</span>;
<a name="l00098"></a>00098       }
<a name="l00099"></a>00099       comm-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a68b36ba64db34f33cb135bc64c4623e0">intermodel_sum_matrix</a>(<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l]);
<a name="l00100"></a>00100       <span class="comment">// TODO: handle case where WB_D is in other matrix distribution</span>
<a name="l00101"></a>00101       <a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp; WB_D = (<a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp;) layers[l]-&gt;get_weights_biases_gradient();
<a name="l00102"></a>00102       <a class="code" href="lbann__base_8hpp.html#a483ed30937584c6d3a4d76bff5215a34">Mat</a>&amp; local_mat = WB_D.Matrix();
<a name="l00103"></a>00103       local_mat = <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l];
<a name="l00104"></a>00104       <span class="comment">// Apply optimizer update again.</span>
<a name="l00105"></a>00105       layers[l]-&gt;update();
<a name="l00106"></a>00106       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l].Empty();
<a name="l00107"></a>00107     }
<a name="l00108"></a>00108   }
<a name="l00109"></a>00109 }
<a name="l00110"></a>00110 
<a name="l00111"></a><a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ace11211398e94728880476981f25fdc2">00111</a> <span class="keywordtype">void</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ace11211398e94728880476981f25fdc2">lbann_callback_imcomm::on_backward_prop_end</a>(<a class="code" href="classlbann_1_1model.html">model</a>* m) {
<a name="l00112"></a>00112   <a class="code" href="classlbann_1_1lbann__comm.html">lbann_comm</a>* <a class="code" href="lbann__file__io_8cpp.html#ab048c6f9fcbcfaa57ce68b00263dbebe">comm</a> = m-&gt;<a class="code" href="classlbann_1_1model.html#aa837a468e77991314053a93441d111ca">get_comm</a>();
<a name="l00113"></a>00113   <span class="keywordflow">if</span> (comm-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a54842b679a3756cf79b43baf46caf637">get_num_models</a>() == 1 ||
<a name="l00114"></a>00114       m-&gt;<a class="code" href="classlbann_1_1model.html#a66c5ac5cb51cdc7dea79a475147bcd5b">get_execution_mode</a>() != <a class="code" href="lbann__base_8hpp.html#a2781a159088df64ed7d47cc91c4dc0a8aef839bdee87b9298d9be97d3f9c90469">execution_mode::training</a>) {
<a name="l00115"></a>00115     <span class="keywordflow">return</span>;  <span class="comment">// No point with only one model.</span>
<a name="l00116"></a>00116   }
<a name="l00117"></a>00117   std::vector&lt;Layer*&gt;&amp; layers = m-&gt;<a class="code" href="classlbann_1_1model.html#a45e75790d328ac2a85aac59faf35094a">get_layers</a>();
<a name="l00118"></a>00118   <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> l = 0; l &lt; layers.size(); ++l) {
<a name="l00119"></a>00119     <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.find(layers[l]-&gt;get_index()) == <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a8a6db1ae85f466653f6d3b3bdef9f0e6">layer_indices</a>.end()) {
<a name="l00120"></a>00120       <span class="keywordflow">continue</span>;
<a name="l00121"></a>00121     }
<a name="l00122"></a>00122     <span class="keywordtype">double</span> start_time = <a class="code" href="namespacelbann.html#a478d36031ff0659893c4322cd856157f">get_time</a>();
<a name="l00123"></a>00123     <span class="comment">// TODO: handle case where WB_D is in other matrix distribution</span>
<a name="l00124"></a>00124     <a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp; WB_D = (<a class="code" href="lbann__base_8hpp.html#a270ddda44ad6a3abd3cfe8358cf581e6">DistMat</a>&amp;) layers[l]-&gt;get_weights_biases_gradient();
<a name="l00125"></a>00125     <span class="keywordflow">switch</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aa617c54b0bba0aaba9a916c0cda2cfba">ct</a>) {
<a name="l00126"></a>00126     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aafa59156bc4d5bcbf6bd80918d062da03">NONE</a>:
<a name="l00127"></a>00127       <span class="keywordflow">break</span>;
<a name="l00128"></a>00128     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aa5f19efb5bef79cea24be992a2137962e">NORMAL</a>:
<a name="l00129"></a>00129       comm-&gt;<a class="code" href="classlbann_1_1lbann__comm.html#a68b36ba64db34f33cb135bc64c4623e0">intermodel_sum_matrix</a>(WB_D);
<a name="l00130"></a>00130       <span class="keywordflow">break</span>;
<a name="l00131"></a>00131     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aa06f19090efbd982638c20bcb8a3c7d33">ONEBIT_QUANTIZATION</a>:
<a name="l00132"></a>00132       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a97db186341c0819c8d52e2f815deb2a7">intermodel_sum_quantized</a>(
<a name="l00133"></a>00133         comm, WB_D, <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l], <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>[l], <span class="keyword">true</span>,
<a name="l00134"></a>00134         &amp;(<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab10f1484a37c6e6085329796dc7ef7c4">gradhistories</a>[l]));
<a name="l00135"></a>00135       <span class="keywordflow">break</span>;
<a name="l00136"></a>00136     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aa76420a96a3df1d5b60140bab6bc32dc4">THRESH_QUANTIZATION</a>:
<a name="l00137"></a>00137       <span class="comment">// TODO: Don&apos;t hardcode thresholds.</span>
<a name="l00138"></a>00138       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a4cf9d4cd5262b21939e95fc34ad0a09f">intermodel_sum_threshold_quantized</a>(
<a name="l00139"></a>00139         comm, WB_D, <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l], 0.01f, -0.01f,
<a name="l00140"></a>00140         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>[l], <span class="keyword">false</span>);
<a name="l00141"></a>00141       <span class="keywordflow">break</span>;
<a name="l00142"></a>00142     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aac76623c2ad49262ce5beb14170fbda9f">COMPRESSED_THRESH_QUANTIZATION</a>:
<a name="l00143"></a>00143       <span class="comment">// TODO: Don&apos;t hardcode thresholds.</span>
<a name="l00144"></a>00144       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a4cf9d4cd5262b21939e95fc34ad0a09f">intermodel_sum_threshold_quantized</a>(
<a name="l00145"></a>00145         comm, WB_D, <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l], 0.01f, -0.01f,
<a name="l00146"></a>00146         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>[l], <span class="keyword">true</span>);
<a name="l00147"></a>00147       <span class="keywordflow">break</span>;
<a name="l00148"></a>00148     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aada44a49f242f680c41e65f80150d1712">ADAPTIVE_THRESH_QUANTIZATION</a>:
<a name="l00149"></a>00149       <span class="comment">// TODO: Don&apos;t hardcode proportion.</span>
<a name="l00150"></a>00150       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a28e74da8473ea1b475ff3976676898c4">intermodel_sum_adaptive_threshold_quantized</a>(
<a name="l00151"></a>00151         comm, WB_D, <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l], 64,
<a name="l00152"></a>00152         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>[l], <span class="keyword">false</span>);
<a name="l00153"></a>00153       <span class="keywordflow">break</span>;
<a name="l00154"></a>00154     <span class="keywordflow">case</span> <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aac3af83766cde0dfb183144d72f916f40">COMPRESSED_ADAPTIVE_THRESH_QUANTIZATION</a>:
<a name="l00155"></a>00155       <span class="comment">// TODO: Don&apos;t hardcode proportion.</span>
<a name="l00156"></a>00156       <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a28e74da8473ea1b475ff3976676898c4">intermodel_sum_adaptive_threshold_quantized</a>(
<a name="l00157"></a>00157         comm, WB_D, <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#a55de5c89215eb0b0ebc9186cf7a0f5e6">quantization_errors</a>[l], 64,
<a name="l00158"></a>00158         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ab4c3627c1cd73ca8fc994918a4adbe7a">im_quantization_errors</a>[l], <span class="keyword">true</span>);
<a name="l00159"></a>00159       <span class="keywordflow">break</span>;
<a name="l00160"></a>00160     }
<a name="l00161"></a>00161     <span class="keywordtype">double</span> im_time = <a class="code" href="namespacelbann.html#a478d36031ff0659893c4322cd856157f">get_time</a>() - start_time;
<a name="l00162"></a>00162     <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a> != <span class="keyword">nullptr</span> &amp;&amp; <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#aa617c54b0bba0aaba9a916c0cda2cfba">ct</a> != <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acf7e894b3381e7f9b71020dc73594d6aafa59156bc4d5bcbf6bd80918d062da03">NONE</a>) {
<a name="l00163"></a>00163       std::string prefix = <span class="stringliteral">&quot;layer&quot;</span> + std::to_string(
<a name="l00164"></a>00164         static_cast&lt;long long&gt;(layers[l]-&gt;get_index())) + <span class="stringliteral">&quot;/imcomm_&quot;</span>;
<a name="l00165"></a>00165       <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;time&quot;</span>,
<a name="l00166"></a>00166                                 im_time, m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00167"></a>00167       <span class="keywordtype">size_t</span> bytes_sent = 0;
<a name="l00168"></a>00168       <span class="keywordtype">size_t</span> bytes_received = 0;
<a name="l00169"></a>00169       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ad3a9f43ceb08af462ce9d378e70bd76d">ct_does_quantization</a>()) {
<a name="l00170"></a>00170         bytes_sent = <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#ad318aefe6f75c8d68363affce55f6190">get_bytes_sent</a>();
<a name="l00171"></a>00171         bytes_received = <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a9a029f692e679ac4475a51fa2ac8f7c1">get_bytes_received</a>();
<a name="l00172"></a>00172       } <span class="keywordflow">else</span> {
<a name="l00173"></a>00173         <span class="comment">// Use the same approximation the comm layer does.</span>
<a name="l00174"></a>00174         bytes_sent = <span class="keyword">sizeof</span>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>) * WB_D.LocalHeight() * WB_D.LocalWidth();
<a name="l00175"></a>00175         bytes_received = <span class="keyword">sizeof</span>(<a class="code" href="lbann__base_8hpp.html#a279b64f47fb2213ad73e59be937afcfa">DataType</a>) * WB_D.LocalHeight() * WB_D.LocalWidth();
<a name="l00176"></a>00176       }
<a name="l00177"></a>00177       <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;bytes_sent&quot;</span>,
<a name="l00178"></a>00178                                 bytes_sent, m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00179"></a>00179       <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;bytes_received&quot;</span>,
<a name="l00180"></a>00180                                 bytes_received, m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00181"></a>00181       <span class="keywordflow">if</span> (<a class="code" href="classlbann_1_1lbann__callback__imcomm.html#ad3a9f43ceb08af462ce9d378e70bd76d">ct_does_quantization</a>()) {
<a name="l00182"></a>00182         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;rs_bytes_sent&quot;</span>,
<a name="l00183"></a>00183                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a2c1b69b38cf93d43e9b4eca7d4c5e28f">get_rs_bytes_sent</a>(),
<a name="l00184"></a>00184                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00185"></a>00185         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;ag_bytes_sent&quot;</span>,
<a name="l00186"></a>00186                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a6c64c6960852ca25f81ba7bc80c05d2d">get_ag_bytes_sent</a>(),
<a name="l00187"></a>00187                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00188"></a>00188         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;rs_bytes_received&quot;</span>,
<a name="l00189"></a>00189                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#aeefaa02ea30dc89f58420e019950207f">get_rs_bytes_received</a>(),
<a name="l00190"></a>00190                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00191"></a>00191         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;ag_bytes_received&quot;</span>,
<a name="l00192"></a>00192                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#a9befb796840b21d1238e8169421005f9">get_ag_bytes_received</a>(),
<a name="l00193"></a>00193                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00194"></a>00194         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;rs_send_trans_time&quot;</span>,
<a name="l00195"></a>00195                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#aea9f348cd6f48b706870e1a5e48e8827">get_rs_send_trans_time</a>(),
<a name="l00196"></a>00196                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00197"></a>00197         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;rs_recv_trans_time&quot;</span>,
<a name="l00198"></a>00198                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#ae5f4f573c3ed285265e9d7834446b3a0">get_rs_recv_trans_time</a>(),
<a name="l00199"></a>00199                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00200"></a>00200         <a class="code" href="classlbann_1_1lbann__callback.html#ad48ff47a64f2dff3a12d8bd282f554cb">summarizer</a>-&gt;<a class="code" href="classlbann_1_1lbann__summary.html#aacd54e77d45bd1bd56df3a4d71c01ce8">reduce_scalar</a>(prefix + <span class="stringliteral">&quot;ag_recv_trans_time&quot;</span>,
<a name="l00201"></a>00201                                   <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#aebc22819c53ce8a836bd20e938f6c59e">get_ag_recv_trans_time</a>(),
<a name="l00202"></a>00202                                   m-&gt;<a class="code" href="classlbann_1_1model.html#a6fb1e6b55fe9f7ecb70759a9c50a20c5">get_cur_step</a>());
<a name="l00203"></a>00203         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#afa32b747b7ac0dbea8df3b47593d54b7">reset_bytes_counters</a>();
<a name="l00204"></a>00204         <a class="code" href="classlbann_1_1lbann__callback__imcomm.html#acb4f04304f91457885902812f354d9a7">quantizer</a>.<a class="code" href="classlbann_1_1lbann__quantizer.html#abdba3762c51a2820f70adba32169f57b">reset_time_counters</a>();
<a name="l00205"></a>00205       }
<a name="l00206"></a>00206     }
<a name="l00207"></a>00207   }
<a name="l00208"></a>00208 }
<a name="l00209"></a>00209 
<a name="l00210"></a>00210 }  <span class="comment">// namespace lbann</span>
</pre></div></div>
<hr size="1"/><address style="text-align: right;"><small>Generated on 21 Sep 2016 for LBANN by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.1 </small></address>
</body>
</html>
